{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xIYU2pqMn3WbMEzfs5GsEWo8iUH8MeDD","timestamp":1644609098344},{"file_id":"13aLb_dvWhy8cgjtkUsY63FFz9Nrj39vE","timestamp":1641762890771},{"file_id":"1HMNUAtNAj9VQIwM4AEdpsBH9rjTii3Yg","timestamp":1641749303952}],"mount_file_id":"1HMNUAtNAj9VQIwM4AEdpsBH9rjTii3Yg","authorship_tag":"ABX9TyMLDkDMXqyasXBxj35NRNLv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b1803206ae1443f181e9a5d0a53030d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7ded0401a3548f6aec161c32c1286e8","IPY_MODEL_1341e1bec246427b92a31c2b662a1967","IPY_MODEL_022c664a772a4a3eae13fdd6e2750983"],"layout":"IPY_MODEL_fc2afb5170824dec99ee81a7c6ef4bed"}},"b7ded0401a3548f6aec161c32c1286e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ae39b8bb2e14414aab4f4aad2fa01aa","placeholder":"​","style":"IPY_MODEL_7e9ba86283804a138a9f113e87e31c89","value":"spiece.model: 100%"}},"1341e1bec246427b92a31c2b662a1967":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc3c81b6c01c402ea67aa5814362660c","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21961151cf094c67a001215cb9559739","value":798011}},"022c664a772a4a3eae13fdd6e2750983":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98e0117fcef1480f90ffa785f53c5c8e","placeholder":"​","style":"IPY_MODEL_60fefa4f776c4bbc900da71303a4dfca","value":" 798k/798k [00:00&lt;00:00, 5.38MB/s]"}},"fc2afb5170824dec99ee81a7c6ef4bed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae39b8bb2e14414aab4f4aad2fa01aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e9ba86283804a138a9f113e87e31c89":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc3c81b6c01c402ea67aa5814362660c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21961151cf094c67a001215cb9559739":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98e0117fcef1480f90ffa785f53c5c8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60fefa4f776c4bbc900da71303a4dfca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c72632cfa6d9479d94f51b5587f9f262":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a0b49ad0120412fb1f5ba1b64ee89e4","IPY_MODEL_3ac644fe184443a1a7b908162fee759c","IPY_MODEL_f86f814603a74c7ba5dbd1aacdbf1e5e"],"layout":"IPY_MODEL_6da0abb7eb3440f6bf21b09d7cad6962"}},"8a0b49ad0120412fb1f5ba1b64ee89e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b3ea07f07b743088d92c4542d99e3bf","placeholder":"​","style":"IPY_MODEL_e7003877f6d94ba28b305253ab8f5256","value":"config.json: 100%"}},"3ac644fe184443a1a7b908162fee759c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2428415024194b94b4361651cb8dd2b8","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7b6bb1e0e084d2a8e57fae311c5ea06","value":760}},"f86f814603a74c7ba5dbd1aacdbf1e5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e121a32ffd1141e88cd1238a8bf2714b","placeholder":"​","style":"IPY_MODEL_686684e31613463abcd3b4cde670dba6","value":" 760/760 [00:00&lt;00:00, 10.9kB/s]"}},"6da0abb7eb3440f6bf21b09d7cad6962":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b3ea07f07b743088d92c4542d99e3bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7003877f6d94ba28b305253ab8f5256":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2428415024194b94b4361651cb8dd2b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7b6bb1e0e084d2a8e57fae311c5ea06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e121a32ffd1141e88cd1238a8bf2714b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"686684e31613463abcd3b4cde670dba6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a56f3b9f54ea42c4a293097196ca92d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6348c0331cf64338a673174526b9ac7d","IPY_MODEL_5a7299919c134781b8dce1992ff9af1e","IPY_MODEL_360a4368b79a463ea075316a7861c476"],"layout":"IPY_MODEL_4cf5f376c0e34d0cbc3cfcd59c5f3b5e"}},"6348c0331cf64338a673174526b9ac7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_385be4361ca545e8b4af6578ec7b35f6","placeholder":"​","style":"IPY_MODEL_abe29de4c68645ce93e6fd064f26b919","value":"tf_model.h5: 100%"}},"5a7299919c134781b8dce1992ff9af1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a57b70e4062c40aa895fac3576709259","max":565485600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_550f6dba51244e82bd31243ec8eb54d4","value":565485600}},"360a4368b79a463ea075316a7861c476":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8369f99e7ad84b35ad93ac911131ea9b","placeholder":"​","style":"IPY_MODEL_c79ae4aa86f7490d99f551150abcc84b","value":" 565M/565M [00:07&lt;00:00, 130MB/s]"}},"4cf5f376c0e34d0cbc3cfcd59c5f3b5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"385be4361ca545e8b4af6578ec7b35f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abe29de4c68645ce93e6fd064f26b919":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a57b70e4062c40aa895fac3576709259":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"550f6dba51244e82bd31243ec8eb54d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8369f99e7ad84b35ad93ac911131ea9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c79ae4aa86f7490d99f551150abcc84b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# Credit: https://www.kaggle.com/code/harshpraharaj98/text-classification-using-bert-and-xlnet/notebook\n","# CV credit: https://www.kaggle.com/code/ravi02516/bert-training-5-fold-cross-validation"],"metadata":{"id":"RqCazhwjuXKV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall -y transformers\n","!pip uninstall -y keras\n","!pip uninstall -y tensorflow\n","!pip install --upgrade keras==2.10.0\n","!pip install --upgrade tensorflow==2.10.0\n","!pip install --upgrade transformers==4.22.2\n","# !pip install --upgrade keras==2.6.0\n","# !pip install --upgrade tensorflow==2.6.0\n","# !pip install --upgrade transformers==4.16.2\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DUrpgdtvmgY0","executionInfo":{"status":"ok","timestamp":1703607730577,"user_tz":-60,"elapsed":208759,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"dda7b048-efde-487e-bdaa-d97609547162"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: transformers 4.35.2\n","Uninstalling transformers-4.35.2:\n","  Successfully uninstalled transformers-4.35.2\n","Found existing installation: keras 2.12.0\n","Uninstalling keras-2.12.0:\n","  Successfully uninstalled keras-2.12.0\n","Found existing installation: tensorflow 2.12.0\n","Uninstalling tensorflow-2.12.0:\n","  Successfully uninstalled tensorflow-2.12.0\n","Collecting keras==2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras\n","Successfully installed keras-2.10.0\n","Collecting tensorflow==2.10.0\n","  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.60.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.9.0)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n","Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.0)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (16.0.6)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.2)\n","Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.0)\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n","Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.0)\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.34.0)\n","Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.0)\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.14.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.31.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n","Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, tensorboard, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.2\n","    Uninstalling tensorboard-data-server-0.7.2:\n","      Successfully uninstalled tensorboard-data-server-0.7.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.0\n","    Uninstalling tensorboard-2.12.0:\n","      Successfully uninstalled tensorboard-2.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","orbax-checkpoint 0.4.4 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\n","pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n","tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.22.2\n","  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.22.2)\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.2) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.2) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (2023.11.17)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.15.0\n","    Uninstalling tokenizers-0.15.0:\n","      Successfully uninstalled tokenizers-0.15.0\n","Successfully installed tokenizers-0.12.1 transformers-4.22.2\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"05KBKr1FmWlU","executionInfo":{"status":"ok","timestamp":1703607755405,"user_tz":-60,"elapsed":14427,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import transformers #huggingface transformers library\n","from transformers import TFAutoModel, AutoTokenizer\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import sklearn\n","from sklearn.metrics import confusion_matrix\n","\n","import re\n","from datetime import datetime as dt\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score"]},{"cell_type":"code","source":["# Detect hardware, return appropriate distribution strategy\n","try:\n","    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","    # set: this is always the case on Kaggle.\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    #strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","    strategy = tf.distribute.get_strategy()\n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y65we5OEmk9i","executionInfo":{"status":"ok","timestamp":1703607773854,"user_tz":-60,"elapsed":18452,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"0f8861c4-e980-47b9-9c25-8c16c952c487"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU  grpc://10.75.47.114:8470\n","REPLICAS:  8\n"]}]},{"cell_type":"code","source":["# from google.colab import files\n","# import io\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","# drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qlq9f5tGmzRn","executionInfo":{"status":"ok","timestamp":1703607795295,"user_tz":-60,"elapsed":21463,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"b9d3223f-39ca-4258-cdef-dbc641bae9c2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["df_CoreCGT = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/CGTexpandedSMR_Data.csv', dtype='str', usecols=['TID', 'OrigTweet', 'InReplyTo'])\n","df_CoreGTr = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/GrounTruthBERT.csv', dtype='str', usecols=['TID', 'OrigTweet', 'InReplyTo'])\n","df_GTD_Rec1 = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/GTxM_Pass1/GTD_Pass1_RecID_Labels.csv', dtype='str')\n","df_GTD_Rec2 = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/GTxM_Pass2/GTD_Pass2_RecID_Labels.csv', dtype='str')\n","df_GTD_Rec = pd.concat([df_GTD_Rec1, df_GTD_Rec2], axis=0)\n"],"metadata":{"id":"HDE1yOAwqhNB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_Core = pd.concat([df_CoreGTr, df_CoreCGT], axis=0)\n","df_Core_Rec = df_Core[df_Core.InReplyTo.isna()]\n","df_Core_Sup = df_Core[df_Core.InReplyTo.notna()]"],"metadata":{"id":"Kbxr-YjEH1aZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_GTD_Rec.rename(columns={'RecID': 'TID'}, inplace=True)\n","df_Core_Rec = pd.merge(df_Core_Rec, df_GTD_Rec, on='TID')\n","\n","df_GTD_Rec.rename(columns={'TID': 'InReplyTo'}, inplace=True)\n","df_Core_Sup = pd.merge(df_Core_Sup, df_GTD_Rec, on='InReplyTo')\n","\n","df = pd.concat([df_Core_Rec, df_Core_Sup], axis=0)\n","df = df.sample(frac=1,axis=0,ignore_index=True)"],"metadata":{"id":"XbG8uXWUHzzK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove unlabelled data\n","df = df[df.Target.notna()]\n","len(df)"],"metadata":{"id":"XhX1zrzReodt","executionInfo":{"status":"ok","timestamp":1703529096078,"user_tz":-60,"elapsed":264,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"50c3d794-5ca5-4086-92af-f41c93241d50"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["173945"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# check the label distribution\n","df_RecTweets = df[df.InReplyTo.isna()]\n","df_RecTweets.groupby(['Label','Target']).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBlzfzmoJcp1","executionInfo":{"status":"ok","timestamp":1703529099674,"user_tz":-60,"elapsed":290,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"0cf405bb-b7c8-40db-8583-8abffd7f0f76"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label           Target\n","Business        1          75\n","Entertainment   2         153\n","Environmental   3          17\n","Health          4           4\n","Human Rights    5          83\n","Law and Order   7          12\n","Obituary        9         147\n","Politics        6         539\n","Social Stories  10         32\n","Sports          11         75\n","dtype: int64"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# convert Target to int - essential for Pandas .loc\n","df['Target'] = df['Target'].astype(int)"],"metadata":{"id":"3vcGLs0xyuoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove1stMent(text):\n","  if text[0] == '@':\n","      words = text.split()\n","      words = words[1:] # remove the @mention word\n","      text = \" \".join(words).lstrip()\n","  return(text)\n","\n","def removeSpecialChar(text):\n","  #old text = re.sub(r'\\W', ' ', text) #replace ALL non-word characters, including emojis with space\n","  # remove all non ASCII characters\n","\n","  # credit: https://stackoverflow.com/questions/2758921/regular-expression-that-finds-and-replaces-non-ascii-characters-with-python\n","  text = re.sub(r\"[\\u0080-\\uFFFF]\", \" \", text) #see ASCII list: https://www.asciitable.com/\n","  text = \" \".join(text.split()) # replace multiple spaces with a single space\n","  return(text)\n","\n","def removeDigits(text):\n","  text = re.sub(r'\\d', ' ', text) #replace digits with space\n","  return(text)\n","\n","def cleanColloquials(text):\n","  #replace this strange chars in the text with space\n","  text = text.replace(\"GCO\",\" \")\n","  text = text.replace(\"GY=n+\",\" \")\n","  text = text.replace(\"GCY\",\" \")\n","  text = text.replace(\"fcafc+\",\" \")\n","  text = text.replace(\"fAE+\",\" \")\n","  text = text.replace(\"#fAE\",\" \")\n","  text = text.replace(\"fnae\",\" \")\n","  text = text.replace(\"fye\",\" \")\n","\n","  #Replace common abbreviations and slangs\n","  text = text.replace(\" i m \",\" i am \")\n","  text = text.replace(\" i ve \",\" i have \")\n","  text = text.replace(\" i ll \",\" i will \")\n","  text = text.replace(\" i d \",\" i had \")\n","  text = text.replace(\" that s \",\" that is \")\n","  text = text.replace(\" isn t \",\" is not \")\n","  text = text.replace(\" it s \",\" it is \")\n","  text = text.replace(\" she s \",\" she is \")\n","  text = text.replace(\" he s \",\" he is \")\n","  text = text.replace(\" u \",\" you \")\n","  text = text.replace(\" ur \",\" your \")\n","  text = text.replace(\" b4 \",\" before \")\n","  text = text.replace(\" wasnt \",\" was not \")\n","  text = text.replace(\" wasn t \",\" was not \")\n","  text = text.replace(\" cant \",\" can not \")\n","  text = text.replace(\" can t \",\" can not \")\n","  text = text.replace(\" couldnt \",\" could not \")\n","  text = text.replace(\" couldn t \",\" could not \")\n","  text = text.replace(\" wouldnt \",\" would not \")\n","  text = text.replace(\" wouldn t \",\" would not \")\n","  text = text.replace(\" dont \",\" do not \")\n","  text = text.replace(\" don t \",\" do not \")\n","  text = text.replace(\" didnt \",\" did not \")\n","  text = text.replace(\" didn t \",\" did not \")\n","  text = text.replace(\" let s \",\" let us \")\n","  text = text.replace(\" i'm \",\" i am \")\n","  text = text.replace(\" i've \",\" i have \")\n","  text = text.replace(\" i'll \",\" i will \")\n","  text = text.replace(\" i'd \",\" i had \")\n","  text = text.replace(\" that's \",\" that is \")\n","  text = text.replace(\" isn't \",\" is not \")\n","  text = text.replace(\" it's \",\" it is \")\n","  text = text.replace(\" she's \",\" she is \")\n","  text = text.replace(\" he's \",\" he is \")\n","  text = text.replace(\" u \",\" you \")\n","  text = text.replace(\" ur \",\" your \")\n","  text = text.replace(\" b4 \",\" before \")\n","  text = text.replace(\" wasn't \",\" was not \")\n","  text = text.replace(\" can't \",\" can not \")\n","  text = text.replace(\" couldn't \",\" could not \")\n","  text = text.replace(\" wouldn't \",\" would not \")\n","  text = text.replace(\" don't \",\" do not \")\n","  text = text.replace(\" didn't \",\" did not \")\n","  text = text.replace(\" let's \",\" let us \")\n","  text = text.replace(\" luv \",\" love \")\n","  text = text.replace(\" true \",\" truth \")\n","  text = text.replace(\" ppl \",\" people \")\n","  text = text.replace(\" fb \",\" facebook \")\n","  text = text.replace(\" b day \",\" birthday \")\n","  text = text.replace(\" bday \",\" birthday \")\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeHashtags(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='#', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeMentions(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='@', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeHttpWeb(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='&', words)\n","  words = filter(lambda x:x[0:4]!='http', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n"],"metadata":{"id":"40ElLojg4bl0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CLEANUP FACTORY\n","def cleanup(text):\n","  #Scenario1:\n","  text = removeSpecialChar(text)\n","  text = remove1stMent(text)\n","  text = removeHttpWeb(text)\n","  text = cleanColloquials(text)\n","\n","  #Scenario2: remove1stMent, removeHttpWeb, removeSpecialChar, cleanColloquials\n","  #Scenario3: remove1stMent, removeHttpWeb, removeHashtags, removeSpecialChar, cleanColloquials\n","  return(text)"],"metadata":{"id":"IGIXmrPlBnyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#df['CleanTweet'] = df['OrigTweet'].apply(remove1stMentNoSpecChar)\n","#remove1stMentNoSpecChar('@MarkSZaidEsq @tko From the evidence and more to co')\n","df['CleanTweet'] = df['OrigTweet'].apply(cleanup)"],"metadata":{"id":"i8X6B0l0rxUA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"The dataset contains { df.Target.nunique() } unique categories\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9ROhaMftWNn","executionInfo":{"status":"ok","timestamp":1703529135614,"user_tz":-60,"elapsed":245,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"d0a78a4d-a309-4501-8e8a-27754f4782af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The dataset contains 10 unique categories\n"]}]},{"cell_type":"code","source":["# convert the tweets into lower case if uncased model.\n","#df['CleanTweet'] = df['CleanTweet'].apply(lambda x: str(x).lower())\n","# trim to 280 characters max\n","df['CleanTweet'] = df['CleanTweet'].str.slice(0,279)\n","# calculating the length of tweet\n","df['CleanTweet_len'] = df['CleanTweet'].apply(lambda x: len(str(x).split()))\n","# Remove tweets with less than 10 words\n","df = df.query('CleanTweet_len > 9')\n","len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1WFEkq8McZk","executionInfo":{"status":"ok","timestamp":1703529141375,"user_tz":-60,"elapsed":643,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"5efed873-5181-4299-c1c1-d794bd003dfa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["142697"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# check that the RecTweets are still all in the dataset after the cleansing\n","df_RecTweets = df[df.InReplyTo.isna()]\n","df_RecTweets.groupby(['Label','Target']).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5voRycn6oCp","executionInfo":{"status":"ok","timestamp":1703529145751,"user_tz":-60,"elapsed":242,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"622c713a-bda4-4840-851e-49a4e236cffc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label           Target\n","Business        1          67\n","Entertainment   2         139\n","Environmental   3          16\n","Health          4           4\n","Human Rights    5          79\n","Law and Order   7          12\n","Obituary        9         138\n","Politics        6         517\n","Social Stories  10         31\n","Sports          11         58\n","dtype: int64"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["#Serialize the Targets for the encoder\n","df.loc[(df.Target == 1), 'Target'] = 0 # Business\n","df.loc[(df.Target == 2), 'Target'] = 1 # Entertainment\n","df.loc[(df.Target == 3), 'Target'] = 2 # Environmental\n","df.loc[(df.Target == 4), 'Target'] = 3 # Health\n","df.loc[(df.Target == 5), 'Target'] = 4 # Human Rights\n","df.loc[(df.Target == 6), 'Target'] = 5 # Politics\n","df.loc[(df.Target == 7), 'Target'] = 6 # Law and Order\n","df.loc[(df.Target == 9), 'Target'] = 7 # Obituary\n","df.loc[(df.Target == 10), 'Target'] = 8 # Social Stories\n","df.loc[(df.Target == 11), 'Target'] = 9 # Sports"],"metadata":{"id":"RK3Z7_9LKarP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.groupby(['Target','Label']).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IgFu7nb-Nxcq","executionInfo":{"status":"ok","timestamp":1703529413724,"user_tz":-60,"elapsed":313,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"792c2f04-bf01-4242-8e19-e7d9f749d3d3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Target  Label         \n","0       Business           7407\n","1       Entertainment     16623\n","2       Environmental      2072\n","3       Health              512\n","4       Human Rights      11154\n","5       Politics          80563\n","6       Law and Order      1632\n","7       Obituary          11406\n","8       Social Stories     2445\n","9       Sports             8883\n","dtype: int64"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# set index to TID (used later in the Training/Test Series)\n","df.index = df['TID']\n","df.index.rename('gt_idx', inplace=True)\n","df.head(2)"],"metadata":{"id":"OYthw-qqtN5r","executionInfo":{"status":"ok","timestamp":1703529418801,"user_tz":-60,"elapsed":259,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"colab":{"base_uri":"https://localhost:8080/","height":178},"outputId":"585cbbb6-54f3-405f-9ecf-f837d1919eb1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                     TID  \\\n","gt_idx                                     \n","1202221009975291904  1202221009975291904   \n","1196783163063914496  1196783163063914496   \n","\n","                                                             OrigTweet  \\\n","gt_idx                                                                   \n","1202221009975291904  @samswey And this infighting is whatΓÇÖll help...   \n","1196783163063914496  @LeaveEUOfficial ΓÇ£hoist by his own petardΓÇ¥...   \n","\n","                               InReplyTo  Target     Label  \\\n","gt_idx                                                       \n","1202221009975291904  1202027294291677184       5  Politics   \n","1196783163063914496  1196748617312358400       5  Politics   \n","\n","                                                            CleanTweet  \\\n","gt_idx                                                                   \n","1202221009975291904  And this infighting is what ll help trump get ...   \n","1196783163063914496  hoist by his own petard Words from 400 years a...   \n","\n","                     CleanTweet_len  \n","gt_idx                               \n","1202221009975291904              42  \n","1196783163063914496              12  "],"text/html":["\n","  <div id=\"df-75259253-0017-4dc1-90df-0b412c7055ea\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TID</th>\n","      <th>OrigTweet</th>\n","      <th>InReplyTo</th>\n","      <th>Target</th>\n","      <th>Label</th>\n","      <th>CleanTweet</th>\n","      <th>CleanTweet_len</th>\n","    </tr>\n","    <tr>\n","      <th>gt_idx</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1202221009975291904</th>\n","      <td>1202221009975291904</td>\n","      <td>@samswey And this infighting is whatΓÇÖll help...</td>\n","      <td>1202027294291677184</td>\n","      <td>5</td>\n","      <td>Politics</td>\n","      <td>And this infighting is what ll help trump get ...</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>1196783163063914496</th>\n","      <td>1196783163063914496</td>\n","      <td>@LeaveEUOfficial ΓÇ£hoist by his own petardΓÇ¥...</td>\n","      <td>1196748617312358400</td>\n","      <td>5</td>\n","      <td>Politics</td>\n","      <td>hoist by his own petard Words from 400 years a...</td>\n","      <td>12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75259253-0017-4dc1-90df-0b412c7055ea')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-75259253-0017-4dc1-90df-0b412c7055ea button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-75259253-0017-4dc1-90df-0b412c7055ea');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-73b9facf-e6a0-4eda-b106-a7268e4c3553\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73b9facf-e6a0-4eda-b106-a7268e4c3553')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-73b9facf-e6a0-4eda-b106-a7268e4c3553 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["#use XLNet base cased pretrained tokenizer\n","tokenizer = transformers.XLNetTokenizer.from_pretrained('xlnet-base-cased')"],"metadata":{"id":"PJfSoFfpuTVJ","executionInfo":{"status":"ok","timestamp":1703529425150,"user_tz":-60,"elapsed":1488,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["b1803206ae1443f181e9a5d0a53030d4","b7ded0401a3548f6aec161c32c1286e8","1341e1bec246427b92a31c2b662a1967","022c664a772a4a3eae13fdd6e2750983","fc2afb5170824dec99ee81a7c6ef4bed","9ae39b8bb2e14414aab4f4aad2fa01aa","7e9ba86283804a138a9f113e87e31c89","bc3c81b6c01c402ea67aa5814362660c","21961151cf094c67a001215cb9559739","98e0117fcef1480f90ffa785f53c5c8e","60fefa4f776c4bbc900da71303a4dfca","c72632cfa6d9479d94f51b5587f9f262","8a0b49ad0120412fb1f5ba1b64ee89e4","3ac644fe184443a1a7b908162fee759c","f86f814603a74c7ba5dbd1aacdbf1e5e","6da0abb7eb3440f6bf21b09d7cad6962","6b3ea07f07b743088d92c4542d99e3bf","e7003877f6d94ba28b305253ab8f5256","2428415024194b94b4361651cb8dd2b8","c7b6bb1e0e084d2a8e57fae311c5ea06","e121a32ffd1141e88cd1238a8bf2714b","686684e31613463abcd3b4cde670dba6"]},"outputId":"07ab59ae-f747-451c-be28-e18594d50494"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1803206ae1443f181e9a5d0a53030d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c72632cfa6d9479d94f51b5587f9f262"}},"metadata":{}}]},{"cell_type":"code","source":["# NOTE: batch_encode_plus adds [CLS], [SEP] to the text\n","def regular_encode(texts, tokenizer, maxlen=512):\n","    enc_di = tokenizer.batch_encode_plus(\n","        texts,\n","        return_attention_mask=False,\n","        return_token_type_ids=False,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        padding='longest',\n","        max_length=maxlen\n","    )\n","    return np.array(enc_di['input_ids'])"],"metadata":{"id":"SccLStPwuAnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# BUILD THE MODEL\n","no_of_classes = 10\n","# seed for environmental stability\n","# tf.random.set_seed(0)"],"metadata":{"id":"0leihuY3u0WB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def build_model(transformer, loss='categorical_crossentropy', max_len=512):\n","    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    sequence_output = transformer(input_word_ids)[0]\n","    cls_token = sequence_output[:, 0, :]\n","    #adding dropout layer\n","    #x = tf.keras.layers.Dropout(0.3, seed=0)(cls_token)\n","    x = tf.keras.layers.Dropout(0.3, )(cls_token)\n","    #using a dense layer of 11 neurons as the number of unique categories is 11.\n","    #out = tf.keras.layers.Dense(11, activation='softmax')(x)\n","    out = tf.keras.layers.Dense(no_of_classes, activation='softmax')(x)\n","    model = tf.keras.Model(inputs=input_word_ids, outputs=out)\n","    #using categorical crossentropy as the loss as it is a multi-class classification problem\n","    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss=loss, metrics=['accuracy'])\n","    return model"],"metadata":{"id":"ZzmqJPxLu41m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#building the model on tpu\n","with strategy.scope():\n","    transformer_layer = transformers.TFXLNetModel.from_pretrained('xlnet-base-cased')\n","    model = build_model(transformer_layer, max_len=99)\n","model.summary()\n","# Save the initial Neural Net weights (to use for resetting the model in between cross validation runs)\n","init_weights = model.get_weights()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":850,"referenced_widgets":["a56f3b9f54ea42c4a293097196ca92d6","6348c0331cf64338a673174526b9ac7d","5a7299919c134781b8dce1992ff9af1e","360a4368b79a463ea075316a7861c476","4cf5f376c0e34d0cbc3cfcd59c5f3b5e","385be4361ca545e8b4af6578ec7b35f6","abe29de4c68645ce93e6fd064f26b919","a57b70e4062c40aa895fac3576709259","550f6dba51244e82bd31243ec8eb54d4","8369f99e7ad84b35ad93ac911131ea9b","c79ae4aa86f7490d99f551150abcc84b"]},"id":"aQm4LSYbz6KD","outputId":"e719fb83-4305-4119-c2c3-c0bc7389ffd6","executionInfo":{"status":"ok","timestamp":1703529533017,"user_tz":-60,"elapsed":71584,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["tf_model.h5:   0%|          | 0.00/565M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a56f3b9f54ea42c4a293097196ca92d6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n","Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n","- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_word_ids (InputLayer)  [(None, 99)]             0         \n","                                                                 \n"," tfxl_net_model (TFXLNetMode  TFXLNetModelOutput(last_  116718336\n"," l)                          hidden_state=(None, 99,             \n","                             768),                               \n","                              mems=((99, None, 768),             \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768)),                  \n","                              hidden_states=None, att            \n","                             entions=None)                       \n","                                                                 \n"," tf.__operators__.getitem (S  (None, 768)              0         \n"," licingOpLambda)                                                 \n","                                                                 \n"," dropout_37 (Dropout)        (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 10)                7690      \n","                                                                 \n","=================================================================\n","Total params: 116,726,026\n","Trainable params: 116,726,026\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["#X_train,X_test ,y_train,y_test = train_test_split(df['CleanTweet'], df['Target'], random_state = 1, stratify=df['Target'], test_size = 0.2)\n","X_train = df['CleanTweet']\n","y_train = df['Target']"],"metadata":{"id":"18ZS-jzjuO5U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["passID = 'Pass2'\n","DL_algo = 'XLNet__AllClasses'\n","runID = dt.today().strftime('%Y%m%d%H%M')"],"metadata":{"id":"FIL1O76SDqDO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 5-Fold Cross Validation\n","kf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n","# kf = StratifiedKFold(n_splits=5)\n","# kf = StratifiedKFold(n_splits=2, random_state=0, shuffle=True)\n","k=1\n","df_tr_hist = pd.DataFrame(columns=['RunID','RunTweak','Model','Loss','Accuracy'])\n","df_val_result = pd.DataFrame(columns=['ValID','ValType','Model','Accuracy','Precision','Recall','F1'])\n","for tr_idx, val_idx in kf.split(X_train, y_train):\n","  print(f\"\\nTraining for Cross Val: {k} \")\n","  print(f\"Indexes for tr {tr_idx} and val {val_idx}\")\n","  X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n","  y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n","  print(\"Encoding y_tr and y_val...\")\n","  ytr_encoded = tf.keras.utils.to_categorical(y_tr, num_classes=no_of_classes,dtype = 'int32')\n","  yval_encoded = tf.keras.utils.to_categorical(y_val, num_classes=no_of_classes,dtype = 'int32')\n","  print(\"Encoding X_tr and X_val...\")\n","  Xtr_encoded = regular_encode(X_tr.astype('str'), tokenizer, maxlen=99)\n","  Xval_encoded = regular_encode(X_val.astype('str'), tokenizer, maxlen=99)\n","  print(f\"Shapes for X_tr {Xtr_encoded.shape}, y_tr {ytr_encoded.shape}, X_val {Xval_encoded.shape} and y_val {yval_encoded.shape}\")\n","\n","  print(\"creating the tr and val datasets...\")\n","  BATCH_SIZE = 32*strategy.num_replicas_in_sync\n","  AUTO = tf.data.experimental.AUTOTUNE\n","  train_dataset = tf.data.Dataset.from_tensor_slices((Xtr_encoded, ytr_encoded))\n","  test_dataset = tf.data.Dataset.from_tensor_slices(Xval_encoded)\n","\n","  epochs_no = 10\n","  #creating the training and testing dataset.\n","  train_dataset = (\n","      tf.data.Dataset\n","      .from_tensor_slices((Xtr_encoded, ytr_encoded))\n","      .repeat()\n","      .shuffle(2048)\n","      .batch(BATCH_SIZE)\n","      .prefetch(AUTO)\n","  )\n","  test_dataset = (\n","      tf.data.Dataset\n","      .from_tensor_slices(Xval_encoded)\n","      .batch(BATCH_SIZE)\n","  )\n","\n","  #training for the epochs\n","  n_steps = Xtr_encoded.shape[0] // BATCH_SIZE\n","  train_history = model.fit(\n","      train_dataset,\n","      steps_per_epoch=n_steps,\n","      epochs=epochs_no\n","  )\n","\n","  #store the training history log\n","  df_tr_hist.loc[len(df_tr_hist)] = [runID, passID, DL_algo, train_history.history['loss'], train_history.history['accuracy']]\n","\n","  #Making predictions for val\n","  preds = model.predict(test_dataset,verbose = 1)\n","  pred_classes = np.argmax(preds, axis = 1)\n","\n","  #Mapping the encoded output to actual categories...\n","  # write result for decomposed SMR\n","  actual_category = np.argmax(yval_encoded, axis = 1)\n","  acc = sklearn.metrics.accuracy_score(actual_category,pred_classes)\n","  print(\"Generating decomposed SMR performance metrics ...\" )\n","  de_prec = precision_score(actual_category,pred_classes, average = 'weighted')\n","  de_recall = recall_score(actual_category,pred_classes, average = 'weighted')\n","  de_f1 = f1_score(actual_category,pred_classes, average = 'weighted')\n","\n","  print(f\"Decomposed SMR Acc: {acc*100}, Prec: {de_prec*100}, Recall: {de_recall*100}, F1 {de_f1*100}\")\n","  df_val_result.loc[len(df_val_result)] = [k, 'Decomposed', DL_algo, acc*100, de_prec*100, de_recall*100, de_f1*100]\n","\n","  # p_r_f1 = precision_recall_fscore_support(actual_category, pred_classes, average = 'weighted')\n","  # print(f\"Decomposed SMR Acc: {acc*100}, Prec: {p_r_f1[0]*100}, Recall: {p_r_f1[1]*100}, F1 {p_r_f1[2]*100}\")\n","  # df_val_result.loc[len(df_val_result)] = [k, 'Decomposed', 'XLNet', acc*100, p_r_f1[0]*100, p_r_f1[1]*100, p_r_f1[2]*100]\n","\n","  print(\"Generating recomposed SMR accuracy...\")\n","  list_X_val_idx = X_val.index.tolist()\n","  result_df = pd.DataFrame({'idx':list_X_val_idx, 'actual_category':actual_category, 'predicted_category':pred_classes})\n","  df_sup_result = result_df.merge(df, left_on='idx', right_on='TID')\n","  df_sup_agg_result = df_sup_result.groupby(['InReplyTo','predicted_category']).size().reset_index(name='counts').sort_values(['InReplyTo','counts'], ascending=[True,False])\n","  df_rec = df[df.InReplyTo.isna()]\n","\n","  # Recompose the SMR based on the count of aggregated supporting tweet predictions\n","  df_rec_result = pd.DataFrame(columns=['TID','Actual','Predicted'])\n","  for i in range(0,len(df_rec)):\n","    rec_TID = df_rec.iloc[i]['TID']\n","    rec_cat = int(df_rec.iloc[i]['Target'])\n","    df_temp = df_sup_agg_result[df_sup_agg_result.InReplyTo == rec_TID].sort_values('counts',ascending=False)\n","    if len(df_temp) > 0:\n","      rec_pred = int(df_temp[:1]['predicted_category'].values)\n","      df_rec_result.loc[len(df_rec_result)] = [rec_TID,rec_cat,rec_pred]\n","\n","  # write result for recomposed SMR\n","  rec_actual = df_rec_result['Actual'].to_numpy().astype(int)\n","  rec_pred = df_rec_result['Predicted'].to_numpy().astype(int)\n","  rec_acc = sklearn.metrics.accuracy_score(rec_actual, rec_pred)\n","  # rec_p_r_f1 = precision_recall_fscore_support(rec_actual, rec_pred, average = 'weighted')\n","  rec_prec = precision_score(rec_actual, rec_pred, average = 'weighted')\n","  rec_recall = recall_score(rec_actual, rec_pred, average = 'weighted')\n","  rec_f1 = f1_score(rec_actual, rec_pred, average = 'weighted')\n","\n","  print(f\"Recomposed SMR Acc: {rec_acc*100}, Prec: {rec_prec*100}, Recall: {rec_recall*100}, F1 {rec_f1*100}\")\n","  df_val_result.loc[len(df_val_result)] = [k, 'Recomposed', DL_algo, rec_acc*100, rec_prec*100, rec_recall*100, rec_f1*100]\n","\n","  # print(f\"Recomposed SMR Acc: {rec_acc*100}, Prec: {rec_p_r_f1[0]*100}, Recall: {rec_p_r_f1[1]*100}, F1 {rec_p_r_f1[2]*100}\")\n","  # df_val_result.loc[len(df_val_result)] = [k, 'Recomposed', 'XLNet', rec_acc*100, rec_p_r_f1[0]*100, rec_p_r_f1[1]*100, rec_p_r_f1[2]*100]\n","\n","  # Generate confusion matrix\n","  rec_cm = confusion_matrix(rec_actual, rec_pred)\n","  df_rec_cm = pd.DataFrame(rec_cm)\n","  df_rec_cm.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_CM_\" + str(k) + \" \" + runID +\".csv\")\n","\n","  # Reset the model by restoring the initital model weights to prevent overtraining\n","  model.set_weights(init_weights)\n","  k=k+1\n","\n","# Save the training history result\n","df_tr_hist.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_TrainHist_\" + runID +\".csv\")\n","\n","# Save the cross validation result\n","df_val_result = df_val_result.round(decimals=2)\n","df_val_result.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_CV_\" + runID +\".csv\")\n","\n","# Save RunID,Model,Accuracy,Precision,Recall,F1 for the Recomposed SMR\n","df_re_val_result = df_val_result[df_val_result.ValType=='Recomposed']\n","no_of_runs = len(df_re_val_result)\n","df_GTxM_Clf_CV_results = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_Clf_CV_results.csv\")\n","avg_Accuracy = np.sum(df_re_val_result['Accuracy']) / no_of_runs\n","avg_Precision = np.sum(df_re_val_result['Precision']) / no_of_runs\n","avg_Recall = np.sum(df_re_val_result['Recall']) / no_of_runs\n","avg_F1 = np.sum(df_re_val_result['F1']) / no_of_runs\n","df_GTxM_Clf_CV_results.loc[len(df_GTxM_Clf_CV_results)] = [runID, 'XLNet', avg_Accuracy, avg_Precision, avg_Recall, avg_F1]\n","df_GTxM_Clf_CV_results.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_Clf_CV_results.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkzVZhP3vEQ-","outputId":"a2fc3e32-4d6b-4b10-a16d-e2c307ee0459","executionInfo":{"status":"ok","timestamp":1703536744970,"user_tz":-60,"elapsed":620896,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","Training for Cross Val: 1 \n","Indexes for tr [     2      3      4 ... 142694 142695 142696] and val [     0      1      5 ... 142671 142673 142676]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (114157, 99), y_tr (114157, 10), X_val (28540, 99) and y_val (28540, 10)\n","creating the tr and val datasets...\n","Epoch 1/10\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["445/445 [==============================] - 213s 296ms/step - loss: 1.0613 - accuracy: 0.6880\n","Epoch 2/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.5818 - accuracy: 0.8220\n","Epoch 3/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.4607 - accuracy: 0.8560\n","Epoch 4/10\n","445/445 [==============================] - 132s 296ms/step - loss: 0.3803 - accuracy: 0.8805\n","Epoch 5/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.3177 - accuracy: 0.8990\n","Epoch 6/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.2598 - accuracy: 0.9162\n","Epoch 7/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.2068 - accuracy: 0.9335\n","Epoch 8/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.1662 - accuracy: 0.9454\n","Epoch 9/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.1288 - accuracy: 0.9568\n","Epoch 10/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.1013 - accuracy: 0.9664\n","112/112 [==============================] - 32s 243ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 87.5437981779958, Prec: 87.93165450024446, Recall: 87.5437981779958, F1 87.68011410252315\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 92.03109815354713, Prec: 92.07445145885436, Recall: 92.03109815354713, F1 91.93490102507006\n","\n","Training for Cross Val: 2 \n","Indexes for tr [     0      1      2 ... 142694 142695 142696] and val [     4      6     13 ... 142677 142679 142690]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (114157, 99), y_tr (114157, 10), X_val (28540, 99) and y_val (28540, 10)\n","creating the tr and val datasets...\n","Epoch 1/10\n","445/445 [==============================] - 131s 294ms/step - loss: 1.1026 - accuracy: 0.6782\n","Epoch 2/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.5783 - accuracy: 0.8210\n","Epoch 3/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.4578 - accuracy: 0.8568\n","Epoch 4/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.3769 - accuracy: 0.8816\n","Epoch 5/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.3129 - accuracy: 0.8999\n","Epoch 6/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.2569 - accuracy: 0.9169\n","Epoch 7/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.2059 - accuracy: 0.9331\n","Epoch 8/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.1620 - accuracy: 0.9469\n","Epoch 9/10\n","445/445 [==============================] - 132s 296ms/step - loss: 0.1275 - accuracy: 0.9576\n","Epoch 10/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.0999 - accuracy: 0.9673\n","112/112 [==============================] - 14s 113ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 87.86615276804484, Prec: 87.94860048474678, Recall: 87.86615276804484, F1 87.8603468842449\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 93.00291545189503, Prec: 93.15221419815248, Recall: 93.00291545189503, F1 92.79440293057183\n","\n","Training for Cross Val: 3 \n","Indexes for tr [     0      1      4 ... 142690 142692 142696] and val [     2      3      8 ... 142693 142694 142695]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (114158, 99), y_tr (114158, 10), X_val (28539, 99) and y_val (28539, 10)\n","creating the tr and val datasets...\n","Epoch 1/10\n","445/445 [==============================] - 131s 295ms/step - loss: 1.1346 - accuracy: 0.6678\n","Epoch 2/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.5940 - accuracy: 0.8171\n","Epoch 3/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.4714 - accuracy: 0.8535\n","Epoch 4/10\n","445/445 [==============================] - 132s 296ms/step - loss: 0.3931 - accuracy: 0.8761\n","Epoch 5/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.3317 - accuracy: 0.8949\n","Epoch 6/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.2748 - accuracy: 0.9121\n","Epoch 7/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.2228 - accuracy: 0.9284\n","Epoch 8/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.1790 - accuracy: 0.9420\n","Epoch 9/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.1456 - accuracy: 0.9521\n","Epoch 10/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.1129 - accuracy: 0.9625\n","112/112 [==============================] - 13s 111ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 87.44525035915764, Prec: 87.4174093937377, Recall: 87.44525035915764, F1 87.39887653355841\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 94.04296875, Prec: 94.018126116569, Recall: 94.04296875, F1 93.90342338173492\n","\n","Training for Cross Val: 4 \n","Indexes for tr [     0      1      2 ... 142694 142695 142696] and val [     7     14     20 ... 142682 142686 142688]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (114158, 99), y_tr (114158, 10), X_val (28539, 99) and y_val (28539, 10)\n","creating the tr and val datasets...\n","Epoch 1/10\n","445/445 [==============================] - 131s 295ms/step - loss: 1.1539 - accuracy: 0.6645\n","Epoch 2/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.5856 - accuracy: 0.8194\n","Epoch 3/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.4634 - accuracy: 0.8562\n","Epoch 4/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.3833 - accuracy: 0.8793\n","Epoch 5/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.3169 - accuracy: 0.8998\n","Epoch 6/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.2609 - accuracy: 0.9170\n","Epoch 7/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.2114 - accuracy: 0.9316\n","Epoch 8/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.1666 - accuracy: 0.9466\n","Epoch 9/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.1320 - accuracy: 0.9568\n","Epoch 10/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.1057 - accuracy: 0.9650\n","112/112 [==============================] - 13s 111ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 88.25466904937103, Prec: 88.12421172576566, Recall: 88.25466904937103, F1 88.10891672348623\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 92.89191820837391, Prec: 92.7327833225394, Recall: 92.89191820837391, F1 92.67930976949518\n","\n","Training for Cross Val: 5 \n","Indexes for tr [     0      1      2 ... 142693 142694 142695] and val [    18     25     26 ... 142687 142692 142696]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (114158, 99), y_tr (114158, 10), X_val (28539, 99) and y_val (28539, 10)\n","creating the tr and val datasets...\n","Epoch 1/10\n","445/445 [==============================] - 131s 294ms/step - loss: 1.0795 - accuracy: 0.6843\n","Epoch 2/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.5710 - accuracy: 0.8246\n","Epoch 3/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.4550 - accuracy: 0.8578\n","Epoch 4/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.3762 - accuracy: 0.8819\n","Epoch 5/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.3094 - accuracy: 0.9023\n","Epoch 6/10\n","445/445 [==============================] - 131s 294ms/step - loss: 0.2537 - accuracy: 0.9186\n","Epoch 7/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.2009 - accuracy: 0.9350\n","Epoch 8/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.1606 - accuracy: 0.9471\n","Epoch 9/10\n","445/445 [==============================] - 131s 295ms/step - loss: 0.1257 - accuracy: 0.9591\n","Epoch 10/10\n","445/445 [==============================] - 132s 296ms/step - loss: 0.0971 - accuracy: 0.9674\n","112/112 [==============================] - 13s 111ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 88.04092645152248, Prec: 87.90813950007696, Recall: 88.04092645152248, F1 87.94372590244573\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 92.73797841020608, Prec: 92.72377839968223, Recall: 92.73797841020608, F1 92.6045811642983\n"]}]},{"cell_type":"code","source":["df_rec_result.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_last_CV_rec_result_\" + runID +\".csv\")"],"metadata":{"id":"MAPsj_yfCRbP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model.save(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/SavedModels/XLNet_Model_\" + runID +\".h5\")"],"metadata":{"id":"qt-SWSSaMCrc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RUfeKrImmHuI"},"execution_count":null,"outputs":[]}]}