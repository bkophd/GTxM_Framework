{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xIYU2pqMn3WbMEzfs5GsEWo8iUH8MeDD","timestamp":1644609098344},{"file_id":"13aLb_dvWhy8cgjtkUsY63FFz9Nrj39vE","timestamp":1641762890771},{"file_id":"1HMNUAtNAj9VQIwM4AEdpsBH9rjTii3Yg","timestamp":1641749303952}],"mount_file_id":"1HMNUAtNAj9VQIwM4AEdpsBH9rjTii3Yg","authorship_tag":"ABX9TyO5gBrGyko7HzggHQML0YBX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"eed59e2a78714b27bd81dbc9d22c8732":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e384cf10114469a9994c9f45dfe2650","IPY_MODEL_74b45708763e4517af9f27fb7fe82d3d","IPY_MODEL_97692e7249cb46a5b1a31a632951600f"],"layout":"IPY_MODEL_5af520cd7a6c44d5bd59251fedfea769"}},"8e384cf10114469a9994c9f45dfe2650":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_033f3500f40d4a34991c4a00cd5a6346","placeholder":"​","style":"IPY_MODEL_8b3ef9eb92314992a9481eeeb33e037e","value":"Downloading (…)ve/main/spiece.model: 100%"}},"74b45708763e4517af9f27fb7fe82d3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3228c19388ec4060b5feba21213862dd","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ea273a968674d4098db0e6d51169e68","value":798011}},"97692e7249cb46a5b1a31a632951600f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dc43c4252e54de9a408b86801cf2dbf","placeholder":"​","style":"IPY_MODEL_b67d0afe0cc343bd87595e77f6937957","value":" 798k/798k [00:00&lt;00:00, 4.99MB/s]"}},"5af520cd7a6c44d5bd59251fedfea769":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"033f3500f40d4a34991c4a00cd5a6346":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b3ef9eb92314992a9481eeeb33e037e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3228c19388ec4060b5feba21213862dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ea273a968674d4098db0e6d51169e68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2dc43c4252e54de9a408b86801cf2dbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b67d0afe0cc343bd87595e77f6937957":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"434c12539322498a9b4319c257f7e54a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c34f56e925fc4150835ac2a777339980","IPY_MODEL_67c8fb7b28f24fdaab457365dae0ad7e","IPY_MODEL_6da15b636cb6453da16a0bf988801563"],"layout":"IPY_MODEL_305756790271414aae437332d5a3f85f"}},"c34f56e925fc4150835ac2a777339980":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf97c5d9095f44b18d1c39f929a39af9","placeholder":"​","style":"IPY_MODEL_5bfa7087b17d4acb94d2696fdb2fe4c1","value":"Downloading (…)lve/main/config.json: 100%"}},"67c8fb7b28f24fdaab457365dae0ad7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_445ed6f2bffb4e06ba95591548c8dbbe","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc3d72ee81f348478fb5d228520388ef","value":760}},"6da15b636cb6453da16a0bf988801563":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06cb9ad761a94356b42e1102c81cc040","placeholder":"​","style":"IPY_MODEL_2f3f51657d5b43f396f4f3e114f013e8","value":" 760/760 [00:00&lt;00:00, 19.0kB/s]"}},"305756790271414aae437332d5a3f85f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf97c5d9095f44b18d1c39f929a39af9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bfa7087b17d4acb94d2696fdb2fe4c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"445ed6f2bffb4e06ba95591548c8dbbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc3d72ee81f348478fb5d228520388ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06cb9ad761a94356b42e1102c81cc040":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f3f51657d5b43f396f4f3e114f013e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f661be7d83d4d3498a181a0470ef074":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_005e35ca2de94689852e8763396948fd","IPY_MODEL_f3f0901bfb8e42cda97b962226e7b6c7","IPY_MODEL_14f29ecc2ee94aa5aac6bd79dfaf3ada"],"layout":"IPY_MODEL_fa038f1b07a94ef9884ac06d87e62d36"}},"005e35ca2de94689852e8763396948fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11f227f7a78f4216a1dcb1fd01d58929","placeholder":"​","style":"IPY_MODEL_f9d13b2514f14897910dd23144d4e47e","value":"Downloading (…)&quot;tf_model.h5&quot;;: 100%"}},"f3f0901bfb8e42cda97b962226e7b6c7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e711292adf9e4464ac2b00bae8a730a1","max":565485600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f5de780168d4dc785bc3cd1818d1b31","value":565485600}},"14f29ecc2ee94aa5aac6bd79dfaf3ada":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd176420dc694dd29ffd423c6aeaf80b","placeholder":"​","style":"IPY_MODEL_3d4b1703876e4336963ae325321bf83f","value":" 565M/565M [00:04&lt;00:00, 119MB/s]"}},"fa038f1b07a94ef9884ac06d87e62d36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11f227f7a78f4216a1dcb1fd01d58929":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9d13b2514f14897910dd23144d4e47e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e711292adf9e4464ac2b00bae8a730a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f5de780168d4dc785bc3cd1818d1b31":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd176420dc694dd29ffd423c6aeaf80b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d4b1703876e4336963ae325321bf83f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# Credit: https://www.kaggle.com/code/harshpraharaj98/text-classification-using-bert-and-xlnet/notebook\n","# CV credit: https://www.kaggle.com/code/ravi02516/bert-training-5-fold-cross-validation"],"metadata":{"id":"RqCazhwjuXKV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall -y transformers\n","!pip uninstall -y keras\n","!pip uninstall -y tensorflow\n","!pip install --upgrade keras==2.10.0\n","!pip install --upgrade tensorflow==2.10.0\n","!pip install --upgrade transformers==4.22.2\n","# !pip install --upgrade keras==2.6.0\n","# !pip install --upgrade tensorflow==2.6.0\n","# !pip install --upgrade transformers==4.16.2\n","!pip install sentencepiece\n","!pip install unidecode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUrpgdtvmgY0","executionInfo":{"status":"ok","timestamp":1676744773443,"user_tz":-60,"elapsed":117289,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"d4993196-b592-4ce3-fb9a-ca79797f8a51"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: keras 2.11.0\n","Uninstalling keras-2.11.0:\n","  Successfully uninstalled keras-2.11.0\n","Found existing installation: tensorflow 2.11.0\n","Uninstalling tensorflow-2.11.0:\n","  Successfully uninstalled tensorflow-2.11.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras==2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras\n","Successfully installed keras-2.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.10.0\n","  Downloading tensorflow-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (0.30.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (4.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (23.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (0.2.0)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (2.10.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (3.3.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (1.6.3)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (3.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (57.4.0)\n","Collecting tensorflow-estimator<2.11,>=2.10.0\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (1.14.1)\n","Collecting keras-preprocessing>=1.1.1\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (23.1.21)\n","Collecting tensorboard<2.11,>=2.10\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (1.21.6)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (15.0.6.1)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (0.4.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (1.4.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (3.19.6)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (2.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.10.0) (1.51.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.38.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.25.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.16.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (6.0.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.13.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n","Installing collected packages: tensorflow-estimator, keras-preprocessing, tensorboard, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.11.0\n","    Uninstalling tensorflow-estimator-2.11.0:\n","      Successfully uninstalled tensorflow-estimator-2.11.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.11.2\n","    Uninstalling tensorboard-2.11.2:\n","      Successfully uninstalled tensorboard-2.11.2\n","Successfully installed keras-preprocessing-1.1.2 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.22.2\n","  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.22.2) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.22.2) (23.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.22.2) (4.64.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.22.2) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.22.2) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.22.2) (2.25.1)\n","Collecting huggingface-hub<1.0,>=0.9.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.22.2) (3.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.2) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.22.2) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.22.2) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.22.2) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.22.2) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.1 tokenizers-0.12.1 transformers-4.22.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting unidecode\n","  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.3.6\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"05KBKr1FmWlU","executionInfo":{"status":"ok","timestamp":1676744780327,"user_tz":-60,"elapsed":6905,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import transformers #huggingface transformers library\n","from transformers import TFAutoModel, AutoTokenizer\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import sklearn\n","from sklearn.metrics import confusion_matrix\n","\n","import re\n","from datetime import datetime as dt\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from unidecode import unidecode"]},{"cell_type":"code","source":["# Detect hardware, return appropriate distribution strategy\n","try:\n","    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","    # set: this is always the case on Kaggle.\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    #strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","    strategy = tf.distribute.get_strategy()\n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y65we5OEmk9i","executionInfo":{"status":"ok","timestamp":1676744797034,"user_tz":-60,"elapsed":16721,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"73b7ae44-7a46-4275-93b4-179b6c07fec0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU  grpc://10.29.210.202:8470\n","REPLICAS:  8\n"]}]},{"cell_type":"code","source":["# from google.colab import files\n","# import io\n","from google.colab import drive \n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","# drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qlq9f5tGmzRn","executionInfo":{"status":"ok","timestamp":1676744822079,"user_tz":-60,"elapsed":25058,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"35e51222-cfd7-4a78-e073-5220049d586b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/reGroundTruthBERT.csv', dtype='str')\n","#df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/CGT_ReGTR_BERT_Input.csv', dtype='str')\n","df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/GrounTruthBERT.csv', dtype='str', usecols=['TID', 'OrigTweet', 'InReplyTo', 'Target', 'Label'])\n","#df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/GrounTruthBERT.csv', dtype='str', usecols=['TID', 'CleanTweetNoHttp', 'InReplyTo', 'Target', 'Label'])\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"HDE1yOAwqhNB","executionInfo":{"status":"ok","timestamp":1676744830994,"user_tz":-60,"elapsed":3689,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"c32698e7-e10b-4eef-e876-32e2e7f61ef1"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   TID                                          OrigTweet  \\\n","0   826262311560216578  #coup has started. First of many steps. #rebel...   \n","1  1193437298303438858  @MarkSZaidEsq @jody_prichard Funny you want to...   \n","2  1194280882540036098  @MarkSZaidEsq at THAT time, the only \"stepping...   \n","3  1194635634960478208  @MarkSZaidEsq It's not a coup.  It's a Constit...   \n","4  1194636052096413696  @MarkSZaidEsq BTW, I've read your client HOSTE...   \n","\n","            InReplyTo Target     Label  \n","0                 NaN     10  Politics  \n","1  826262311560216578     10  Politics  \n","2  826262311560216578     10  Politics  \n","3  826262311560216578     10  Politics  \n","4  826262311560216578     10  Politics  "],"text/html":["\n","  <div id=\"df-5c6e6349-4a8e-4a69-a5f7-f94ade7152ae\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TID</th>\n","      <th>OrigTweet</th>\n","      <th>InReplyTo</th>\n","      <th>Target</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>826262311560216578</td>\n","      <td>#coup has started. First of many steps. #rebel...</td>\n","      <td>NaN</td>\n","      <td>10</td>\n","      <td>Politics</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1193437298303438858</td>\n","      <td>@MarkSZaidEsq @jody_prichard Funny you want to...</td>\n","      <td>826262311560216578</td>\n","      <td>10</td>\n","      <td>Politics</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1194280882540036098</td>\n","      <td>@MarkSZaidEsq at THAT time, the only \"stepping...</td>\n","      <td>826262311560216578</td>\n","      <td>10</td>\n","      <td>Politics</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1194635634960478208</td>\n","      <td>@MarkSZaidEsq It's not a coup.  It's a Constit...</td>\n","      <td>826262311560216578</td>\n","      <td>10</td>\n","      <td>Politics</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1194636052096413696</td>\n","      <td>@MarkSZaidEsq BTW, I've read your client HOSTE...</td>\n","      <td>826262311560216578</td>\n","      <td>10</td>\n","      <td>Politics</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c6e6349-4a8e-4a69-a5f7-f94ade7152ae')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5c6e6349-4a8e-4a69-a5f7-f94ade7152ae button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5c6e6349-4a8e-4a69-a5f7-f94ade7152ae');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Remove unlabelled data\n","df = df[df.Target.notna()]"],"metadata":{"id":"XhX1zrzReodt","executionInfo":{"status":"ok","timestamp":1676744831268,"user_tz":-60,"elapsed":6,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sj-gOhNk_APf","executionInfo":{"status":"ok","timestamp":1676744832981,"user_tz":-60,"elapsed":6,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"f1382668-0ef4-453d-b809-6658e24b480b"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["124977"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# convert some columns to int\n","#df['CountReplyTweets'] = df['CountReplyTweets'].astype(float)\n","#df['CountReplyWords'] = df['CountReplyWords'].astype(float)\n","#df['CountReplyChars'] = df['CountReplyChars'].astype(float)\n","df['Target'] = df['Target'].astype(int)"],"metadata":{"id":"3vcGLs0xyuoC","executionInfo":{"status":"ok","timestamp":1676744834794,"user_tz":-60,"elapsed":7,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def remove1stMent(text):\n","  if text[0] == '@':\n","      words = text.split()\n","      words = words[1:] # remove the @mention word\n","      text = \" \".join(words).lstrip()\n","  return(text)\n","\n","def removeSpecialChar(text):\n","  #old text = re.sub(r'\\W', ' ', text) #replace ALL non-word characters, including emojis with space\n","  # remove all non ASCII characters \n","\n","  # credit: https://stackoverflow.com/questions/2758921/regular-expression-that-finds-and-replaces-non-ascii-characters-with-python\n","  text = re.sub(r\"[\\u0080-\\uFFFF]\", \" \", text) #see ASCII list: https://www.asciitable.com/\n","  text = \" \".join(text.split()) # replace multiple spaces with a single space\n","  return(text)\n","\n","def removeDigits(text):\n","  text = re.sub(r'\\d', ' ', text) #replace digits with space\n","  return(text)\n","\n","def cleanColloquials(text):\n","  #Replace common abbreviations and slangs\n","  text = text.replace(\" i m \",\" i am \")\n","  text = text.replace(\" i ve \",\" i have \")\n","  text = text.replace(\" i ll \",\" i will \")\n","  text = text.replace(\" i d \",\" i had \")\n","  text = text.replace(\" that s \",\" that is \")\n","  text = text.replace(\" isn t \",\" is not \")\n","  text = text.replace(\" it s \",\" it is \")\n","  text = text.replace(\" she s \",\" she is \")\n","  text = text.replace(\" he s \",\" he is \")\n","  text = text.replace(\" u \",\" you \")\n","  text = text.replace(\" ur \",\" your \")\n","  text = text.replace(\" b4 \",\" before \")\n","  text = text.replace(\" wasnt \",\" was not \")\n","  text = text.replace(\" wasn t \",\" was not \")\n","  text = text.replace(\" cant \",\" can not \")\n","  text = text.replace(\" can t \",\" can not \")\n","  text = text.replace(\" couldnt \",\" could not \")\n","  text = text.replace(\" couldn t \",\" could not \")\n","  text = text.replace(\" wouldnt \",\" would not \")\n","  text = text.replace(\" wouldn t \",\" would not \")\n","  text = text.replace(\" dont \",\" do not \")\n","  text = text.replace(\" don t \",\" do not \")\n","  text = text.replace(\" didnt \",\" did not \")\n","  text = text.replace(\" didn t \",\" did not \")\n","  text = text.replace(\" let s \",\" let us \")\n","  text = text.replace(\" i'm \",\" i am \")\n","  text = text.replace(\" i've \",\" i have \")\n","  text = text.replace(\" i'll \",\" i will \")\n","  text = text.replace(\" i'd \",\" i had \")\n","  text = text.replace(\" that's \",\" that is \")\n","  text = text.replace(\" isn't \",\" is not \")\n","  text = text.replace(\" it's \",\" it is \")\n","  text = text.replace(\" she's \",\" she is \")\n","  text = text.replace(\" he's \",\" he is \")\n","  text = text.replace(\" u \",\" you \")\n","  text = text.replace(\" ur \",\" your \")\n","  text = text.replace(\" b4 \",\" before \")\n","  text = text.replace(\" wasn't \",\" was not \")\n","  text = text.replace(\" can't \",\" can not \")\n","  text = text.replace(\" couldn't \",\" could not \")\n","  text = text.replace(\" wouldn't \",\" would not \")\n","  text = text.replace(\" don't \",\" do not \")\n","  text = text.replace(\" didn't \",\" did not \")\n","  text = text.replace(\" let's \",\" let us \")\n","  text = text.replace(\" luv \",\" love \")\n","  text = text.replace(\" true \",\" truth \")\n","  text = text.replace(\" ppl \",\" people \")\n","  text = text.replace(\" fb \",\" facebook \")\n","  text = text.replace(\" b day \",\" birthday \")\n","  text = text.replace(\" bday \",\" birthday \")\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeHashtags(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='#', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeMentions(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='@', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeHttpWeb(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='&', words)\n","  words = filter(lambda x:x[0:4]!='http', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeUnicode(text):\n","  #convert unicode chars to ascii\n","  text = unidecode(text)\n","  return(text)\n"],"metadata":{"id":"40ElLojg4bl0","executionInfo":{"status":"ok","timestamp":1676744835644,"user_tz":-60,"elapsed":7,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# CLEANUP FACTORY\n","# remove1stMent\n","# removeSpecialChar\n","# removeDigits\n","# cleanColloquials\n","# removeHashtags\n","# removeMentions\n","# removeHttpWeb\n","# removeUnicode\n","\n","def cleanup(text):\n","  #Scenario1: \n","  text = removeUnicode(text)\n","  text = removeSpecialChar(text)\n","  text = remove1stMent(text)\n","  text = removeHttpWeb(text)\n","  text = cleanColloquials(text)\n","\n","  #Scenario2: remove1stMent, removeHttpWeb, removeSpecialChar, cleanColloquials\n","  #Scenario3: remove1stMent, removeHttpWeb, removeHashtags, removeSpecialChar, cleanColloquials\n","  return(text)"],"metadata":{"id":"IGIXmrPlBnyr","executionInfo":{"status":"ok","timestamp":1676744838080,"user_tz":-60,"elapsed":7,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#df['CleanTweet'] = df['OrigTweet'].apply(remove1stMentNoSpecChar)\n","#remove1stMentNoSpecChar('@MarkSZaidEsq @tko From the evidence and more to co')\n","df['CleanTweet'] = df['OrigTweet'].apply(cleanup)"],"metadata":{"id":"i8X6B0l0rxUA","executionInfo":{"status":"ok","timestamp":1676744848729,"user_tz":-60,"elapsed":8341,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["df.to_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/clean_for_dl.csv')"],"metadata":{"id":"uPEzVYiELzjR","executionInfo":{"status":"ok","timestamp":1676744853913,"user_tz":-60,"elapsed":3227,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["print(f\"The dataset contains { df.Target.nunique() } unique categories\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9ROhaMftWNn","executionInfo":{"status":"ok","timestamp":1676744855848,"user_tz":-60,"elapsed":262,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"fce846e8-9e92-4818-d276-cd7ec3f0bffd"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["The dataset contains 5 unique categories\n"]}]},{"cell_type":"code","source":["# convert the tweets into lower case if uncased model.\n","#df['CleanTweet'] = df['CleanTweet'].apply(lambda x: str(x).lower())\n","# trim to 280 characters max\n","df['CleanTweet'] = df['CleanTweet'].str.slice(0,279)\n","# calculating the length of tweet\n","df['CleanTweet_len'] = df['CleanTweet'].apply(lambda x: len(str(x).split()))\n","# Remove tweets with less than 10 words\n","df = df.query('CleanTweet_len > 9')\n","len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1WFEkq8McZk","executionInfo":{"status":"ok","timestamp":1676744858307,"user_tz":-60,"elapsed":442,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"c3cad778-6c60-42f5-ef31-d86808ac943d"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["101454"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["df['Label'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5voRycn6oCp","executionInfo":{"status":"ok","timestamp":1676744859080,"user_tz":-60,"elapsed":4,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"72b28d27-8cc9-4d3d-82f3-0656ef577333"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Politics', 'Entertainment', 'Business', 'Sports', 'Technology'],\n","      dtype=object)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["df['Target'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSJaAglDFSHB","executionInfo":{"status":"ok","timestamp":1676744860763,"user_tz":-60,"elapsed":3,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"f9a21d2f-5f25-4d08-a0c0-70c314ca045c"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([10,  6,  3, 11, 12])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["#For the initial Ground Truth:\n","df.loc[(df.Target == 10), 'Target'] = 0\n","df.loc[(df.Target == 6), 'Target'] = 1\n","df.loc[(df.Target == 3), 'Target'] = 2\n","df.loc[(df.Target == 11), 'Target'] = 3\n","df.loc[(df.Target == 12), 'Target'] = 4\n"],"metadata":{"id":"RK3Z7_9LKarP","executionInfo":{"status":"ok","timestamp":1676744862461,"user_tz":-60,"elapsed":6,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# set index to TID (used later in the Training/Test Series)\n","df.index = df['TID']\n","df.index.rename('gt_idx', inplace=True)"],"metadata":{"id":"OYthw-qqtN5r","executionInfo":{"status":"ok","timestamp":1676744864607,"user_tz":-60,"elapsed":5,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"T1pFK_qBtMSV","executionInfo":{"status":"ok","timestamp":1676744866838,"user_tz":-60,"elapsed":13,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"0d3fd69a-8e5b-4bfd-8b91-06a86f9f54de"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                     TID  \\\n","gt_idx                                     \n","826262311560216578    826262311560216578   \n","1193437298303438858  1193437298303438858   \n","1194280882540036098  1194280882540036098   \n","1194635634960478208  1194635634960478208   \n","1194636052096413696  1194636052096413696   \n","\n","                                                             OrigTweet  \\\n","gt_idx                                                                   \n","826262311560216578   #coup has started. First of many steps. #rebel...   \n","1193437298303438858  @MarkSZaidEsq @jody_prichard Funny you want to...   \n","1194280882540036098  @MarkSZaidEsq at THAT time, the only \"stepping...   \n","1194635634960478208  @MarkSZaidEsq It's not a coup.  It's a Constit...   \n","1194636052096413696  @MarkSZaidEsq BTW, I've read your client HOSTE...   \n","\n","                              InReplyTo  Target     Label  \\\n","gt_idx                                                      \n","826262311560216578                  NaN       0  Politics   \n","1193437298303438858  826262311560216578       0  Politics   \n","1194280882540036098  826262311560216578       0  Politics   \n","1194635634960478208  826262311560216578       0  Politics   \n","1194636052096413696  826262311560216578       0  Politics   \n","\n","                                                            CleanTweet  \\\n","gt_idx                                                                   \n","826262311560216578   #coup has started. First of many steps. #rebel...   \n","1193437298303438858  @jody_prichard Funny you want to discriminate ...   \n","1194280882540036098  at THAT time, the only \"stepping over the line...   \n","1194635634960478208  It's not a coup. It's a Constitutional procedu...   \n","1194636052096413696  BTW, I've read your client HOSTED (and was in)...   \n","\n","                     CleanTweet_len  \n","gt_idx                               \n","826262311560216578               13  \n","1193437298303438858              47  \n","1194280882540036098              54  \n","1194635634960478208              47  \n","1194636052096413696              45  "],"text/html":["\n","  <div id=\"df-ed143a95-2e2a-4d0b-9702-3be27d3f9dc1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TID</th>\n","      <th>OrigTweet</th>\n","      <th>InReplyTo</th>\n","      <th>Target</th>\n","      <th>Label</th>\n","      <th>CleanTweet</th>\n","      <th>CleanTweet_len</th>\n","    </tr>\n","    <tr>\n","      <th>gt_idx</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>826262311560216578</th>\n","      <td>826262311560216578</td>\n","      <td>#coup has started. First of many steps. #rebel...</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>Politics</td>\n","      <td>#coup has started. First of many steps. #rebel...</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>1193437298303438858</th>\n","      <td>1193437298303438858</td>\n","      <td>@MarkSZaidEsq @jody_prichard Funny you want to...</td>\n","      <td>826262311560216578</td>\n","      <td>0</td>\n","      <td>Politics</td>\n","      <td>@jody_prichard Funny you want to discriminate ...</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>1194280882540036098</th>\n","      <td>1194280882540036098</td>\n","      <td>@MarkSZaidEsq at THAT time, the only \"stepping...</td>\n","      <td>826262311560216578</td>\n","      <td>0</td>\n","      <td>Politics</td>\n","      <td>at THAT time, the only \"stepping over the line...</td>\n","      <td>54</td>\n","    </tr>\n","    <tr>\n","      <th>1194635634960478208</th>\n","      <td>1194635634960478208</td>\n","      <td>@MarkSZaidEsq It's not a coup.  It's a Constit...</td>\n","      <td>826262311560216578</td>\n","      <td>0</td>\n","      <td>Politics</td>\n","      <td>It's not a coup. It's a Constitutional procedu...</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>1194636052096413696</th>\n","      <td>1194636052096413696</td>\n","      <td>@MarkSZaidEsq BTW, I've read your client HOSTE...</td>\n","      <td>826262311560216578</td>\n","      <td>0</td>\n","      <td>Politics</td>\n","      <td>BTW, I've read your client HOSTED (and was in)...</td>\n","      <td>45</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed143a95-2e2a-4d0b-9702-3be27d3f9dc1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ed143a95-2e2a-4d0b-9702-3be27d3f9dc1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ed143a95-2e2a-4d0b-9702-3be27d3f9dc1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["#use XLNet base cased pretrained tokenizer\n","tokenizer = transformers.XLNetTokenizer.from_pretrained('xlnet-base-cased')"],"metadata":{"id":"PJfSoFfpuTVJ","executionInfo":{"status":"ok","timestamp":1676744871011,"user_tz":-60,"elapsed":1921,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["eed59e2a78714b27bd81dbc9d22c8732","8e384cf10114469a9994c9f45dfe2650","74b45708763e4517af9f27fb7fe82d3d","97692e7249cb46a5b1a31a632951600f","5af520cd7a6c44d5bd59251fedfea769","033f3500f40d4a34991c4a00cd5a6346","8b3ef9eb92314992a9481eeeb33e037e","3228c19388ec4060b5feba21213862dd","5ea273a968674d4098db0e6d51169e68","2dc43c4252e54de9a408b86801cf2dbf","b67d0afe0cc343bd87595e77f6937957","434c12539322498a9b4319c257f7e54a","c34f56e925fc4150835ac2a777339980","67c8fb7b28f24fdaab457365dae0ad7e","6da15b636cb6453da16a0bf988801563","305756790271414aae437332d5a3f85f","bf97c5d9095f44b18d1c39f929a39af9","5bfa7087b17d4acb94d2696fdb2fe4c1","445ed6f2bffb4e06ba95591548c8dbbe","fc3d72ee81f348478fb5d228520388ef","06cb9ad761a94356b42e1102c81cc040","2f3f51657d5b43f396f4f3e114f013e8"]},"outputId":"a27b51f5-6e2c-4d6e-de43-56c7c571d94e"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)ve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eed59e2a78714b27bd81dbc9d22c8732"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"434c12539322498a9b4319c257f7e54a"}},"metadata":{}}]},{"cell_type":"code","source":["# NOTE: batch_encode_plus adds [CLS], [SEP] to the text\n","def regular_encode(texts, tokenizer, maxlen=512):\n","    enc_di = tokenizer.batch_encode_plus(\n","        texts, \n","        return_attention_mask=False, \n","        return_token_type_ids=False,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        padding='longest',\n","        max_length=maxlen\n","    )\n","    return np.array(enc_di['input_ids'])"],"metadata":{"id":"SccLStPwuAnU","executionInfo":{"status":"ok","timestamp":1676744873753,"user_tz":-60,"elapsed":309,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# BUILD THE MODEL\n","no_of_classes = 5\n","# seed for environmental stability \n","# tf.random.set_seed(0) "],"metadata":{"id":"0leihuY3u0WB","executionInfo":{"status":"ok","timestamp":1676744875501,"user_tz":-60,"elapsed":4,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def build_model(transformer, loss='categorical_crossentropy', max_len=512):\n","    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    sequence_output = transformer(input_word_ids)[0]\n","    cls_token = sequence_output[:, 0, :]\n","    #adding dropout layer\n","    #x = tf.keras.layers.Dropout(0.3, seed=0)(cls_token)\n","    x = tf.keras.layers.Dropout(0.3, )(cls_token)\n","    #using a dense layer of 11 neurons as the number of unique categories is 11. \n","    #out = tf.keras.layers.Dense(11, activation='softmax')(x)\n","    out = tf.keras.layers.Dense(no_of_classes, activation='softmax')(x)\n","    model = tf.keras.Model(inputs=input_word_ids, outputs=out)\n","    #using categorical crossentropy as the loss as it is a multi-class classification problem\n","    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss=loss, metrics=['accuracy'])\n","    return model"],"metadata":{"id":"ZzmqJPxLu41m","executionInfo":{"status":"ok","timestamp":1676744877487,"user_tz":-60,"elapsed":7,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["#building the model on tpu\n","with strategy.scope():\n","    transformer_layer = transformers.TFXLNetModel.from_pretrained('xlnet-base-cased')\n","    model = build_model(transformer_layer, max_len=99)\n","model.summary()\n","# Save the initial Neural Net weights (to use for resetting the model in between cross validation runs)\n","init_weights = model.get_weights()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":850,"referenced_widgets":["2f661be7d83d4d3498a181a0470ef074","005e35ca2de94689852e8763396948fd","f3f0901bfb8e42cda97b962226e7b6c7","14f29ecc2ee94aa5aac6bd79dfaf3ada","fa038f1b07a94ef9884ac06d87e62d36","11f227f7a78f4216a1dcb1fd01d58929","f9d13b2514f14897910dd23144d4e47e","e711292adf9e4464ac2b00bae8a730a1","6f5de780168d4dc785bc3cd1818d1b31","dd176420dc694dd29ffd423c6aeaf80b","3d4b1703876e4336963ae325321bf83f"]},"id":"aQm4LSYbz6KD","outputId":"59b9e85f-3eec-46b2-ea24-df98ed5d484d","executionInfo":{"status":"ok","timestamp":1676744966735,"user_tz":-60,"elapsed":87094,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)\"tf_model.h5\";:   0%|          | 0.00/565M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f661be7d83d4d3498a181a0470ef074"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n","Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n","- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_word_ids (InputLayer)  [(None, 99)]             0         \n","                                                                 \n"," tfxl_net_model (TFXLNetMode  TFXLNetModelOutput(last_  116718336\n"," l)                          hidden_state=(None, 99,             \n","                             768),                               \n","                              mems=((99, None, 768),             \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768)),                  \n","                              hidden_states=None, att            \n","                             entions=None)                       \n","                                                                 \n"," tf.__operators__.getitem (S  (None, 768)              0         \n"," licingOpLambda)                                                 \n","                                                                 \n"," dropout_37 (Dropout)        (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 5)                 3845      \n","                                                                 \n","=================================================================\n","Total params: 116,722,181\n","Trainable params: 116,722,181\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#X_train,X_test ,y_train,y_test = train_test_split(df['CleanTweet'], df['Target'], random_state = 1, stratify=df['Target'], test_size = 0.2)\n","X_train = df['CleanTweet']\n","y_train = df['Target']"],"metadata":{"id":"18ZS-jzjuO5U","executionInfo":{"status":"ok","timestamp":1676744966736,"user_tz":-60,"elapsed":7,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["runTweak = \"Mini clean text - remove 1st mention\""],"metadata":{"id":"FIL1O76SDqDO","executionInfo":{"status":"ok","timestamp":1676744966975,"user_tz":-60,"elapsed":245,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["runID = dt.today().strftime('%Y%m%d%H%M')\n","# 5-Fold Cross Validation\n","kf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True) \n","# kf = StratifiedKFold(n_splits=5)\n","# kf = StratifiedKFold(n_splits=2, random_state=0, shuffle=True)\n","k=1\n","df_tr_hist = pd.DataFrame(columns=['RunID','RunTweak','Model','Loss','Accuracy'])\n","df_val_result = pd.DataFrame(columns=['ValID','ValType','Model','Accuracy','Precision','Recall','F1'])\n","for tr_idx, val_idx in kf.split(X_train, y_train):\n","  print(f\"\\nTraining for Cross Val: {k} \")\n","  print(f\"Indexes for tr {tr_idx} and val {val_idx}\")\n","  X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n","  y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n","  print(\"Encoding y_tr and y_val...\")\n","  ytr_encoded = tf.keras.utils.to_categorical(y_tr, num_classes=no_of_classes,dtype = 'int32')\n","  yval_encoded = tf.keras.utils.to_categorical(y_val, num_classes=no_of_classes,dtype = 'int32')\n","  print(\"Encoding X_tr and X_val...\")\n","  Xtr_encoded = regular_encode(X_tr.astype('str'), tokenizer, maxlen=99)\n","  Xval_encoded = regular_encode(X_val.astype('str'), tokenizer, maxlen=99)\n","  print(f\"Shapes for X_tr {Xtr_encoded.shape}, y_tr {ytr_encoded.shape}, X_val {Xval_encoded.shape} and y_val {yval_encoded.shape}\")\n","  \n","  print(\"creating the tr and val datasets...\")\n","  BATCH_SIZE = 32*strategy.num_replicas_in_sync\n","  AUTO = tf.data.experimental.AUTOTUNE \n","  train_dataset = tf.data.Dataset.from_tensor_slices((Xtr_encoded, ytr_encoded))\n","  test_dataset = tf.data.Dataset.from_tensor_slices(Xval_encoded)\n","\n","  epochs_no = 10\n","  #creating the training and testing dataset.\n","  train_dataset = (\n","      tf.data.Dataset\n","      .from_tensor_slices((Xtr_encoded, ytr_encoded))\n","      .repeat()\n","      .shuffle(2048)\n","      .batch(BATCH_SIZE)\n","      .prefetch(AUTO)\n","  )\n","  test_dataset = (\n","      tf.data.Dataset\n","      .from_tensor_slices(Xval_encoded)\n","      .batch(BATCH_SIZE)\n","  )\n","\n","  #training for the epochs\n","  n_steps = Xtr_encoded.shape[0] // BATCH_SIZE\n","  train_history = model.fit(\n","      train_dataset,\n","      steps_per_epoch=n_steps,\n","      epochs=epochs_no\n","  )\n","\n","  #store the training history log\n","  df_tr_hist.loc[len(df_tr_hist)] = [runID, runTweak, 'XLNet', train_history.history['loss'], train_history.history['accuracy']]\n","\n","  #Making predictions for val\n","  preds = model.predict(test_dataset,verbose = 1)\n","  pred_classes = np.argmax(preds, axis = 1)\n","  \n","  #Mapping the encoded output to actual categories...\n","  # write result for decomposed SMR\n","  actual_category = np.argmax(yval_encoded, axis = 1) \n","  acc = sklearn.metrics.accuracy_score(actual_category,pred_classes)\n","  print(\"Generating decomposed SMR performance metrics ...\" )\n","  de_prec = precision_score(actual_category,pred_classes, average = 'weighted')\n","  de_recall = recall_score(actual_category,pred_classes, average = 'weighted')\n","  de_f1 = f1_score(actual_category,pred_classes, average = 'weighted')\n","\n","  print(f\"Decomposed SMR Acc: {acc*100}, Prec: {de_prec*100}, Recall: {de_recall*100}, F1 {de_f1*100}\")\n","  df_val_result.loc[len(df_val_result)] = [k, 'Decomposed', 'XLNet', acc*100, de_prec*100, de_recall*100, de_f1*100]\n","\n","  # p_r_f1 = precision_recall_fscore_support(actual_category, pred_classes, average = 'weighted')\n","  # print(f\"Decomposed SMR Acc: {acc*100}, Prec: {p_r_f1[0]*100}, Recall: {p_r_f1[1]*100}, F1 {p_r_f1[2]*100}\")\n","  # df_val_result.loc[len(df_val_result)] = [k, 'Decomposed', 'XLNet', acc*100, p_r_f1[0]*100, p_r_f1[1]*100, p_r_f1[2]*100]\n","\n","  print(\"Generating recomposed SMR accuracy...\")\n","  list_X_val_idx = X_val.index.tolist()\n","  result_df = pd.DataFrame({'idx':list_X_val_idx, 'actual_category':actual_category, 'predicted_category':pred_classes})\n","  df_sup_result = result_df.merge(df, left_on='idx', right_on='TID')\n","  df_sup_agg_result = df_sup_result.groupby(['InReplyTo','predicted_category']).size().reset_index(name='counts').sort_values(['InReplyTo','counts'], ascending=[True,False])\n","  df_rec = df[df.InReplyTo.isna()]\n","\n","  # Recompose the SMR based on the count of aggregated supporting tweet predictions\n","  df_rec_result = pd.DataFrame(columns=['TID','Actual','Predicted'])\n","  for i in range(0,len(df_rec)):\n","    rec_TID = df_rec.iloc[i]['TID']\n","    rec_cat = int(df_rec.iloc[i]['Target'])\n","    df_temp = df_sup_agg_result[df_sup_agg_result.InReplyTo == rec_TID].sort_values('counts',ascending=False)\n","    if len(df_temp) > 0:\n","      rec_pred = int(df_temp[:1]['predicted_category'].values)\n","      df_rec_result.loc[len(df_rec_result)] = [rec_TID,rec_cat,rec_pred]\n","\n","  # write result for recomposed SMR\n","  rec_actual = df_rec_result['Actual'].to_numpy().astype(int)\n","  rec_pred = df_rec_result['Predicted'].to_numpy().astype(int)\n","  rec_acc = sklearn.metrics.accuracy_score(rec_actual, rec_pred)\n","  # rec_p_r_f1 = precision_recall_fscore_support(rec_actual, rec_pred, average = 'weighted')\n","  rec_prec = precision_score(rec_actual, rec_pred, average = 'weighted')\n","  rec_recall = recall_score(rec_actual, rec_pred, average = 'weighted')\n","  rec_f1 = f1_score(rec_actual, rec_pred, average = 'weighted')\n","\n","  print(f\"Recomposed SMR Acc: {rec_acc*100}, Prec: {rec_prec*100}, Recall: {rec_recall*100}, F1 {rec_f1*100}\")\n","  df_val_result.loc[len(df_val_result)] = [k, 'Recomposed', 'XLNet', rec_acc*100, rec_prec*100, rec_recall*100, rec_f1*100]\n","\n","  # print(f\"Recomposed SMR Acc: {rec_acc*100}, Prec: {rec_p_r_f1[0]*100}, Recall: {rec_p_r_f1[1]*100}, F1 {rec_p_r_f1[2]*100}\")\n","  # df_val_result.loc[len(df_val_result)] = [k, 'Recomposed', 'XLNet', rec_acc*100, rec_p_r_f1[0]*100, rec_p_r_f1[1]*100, rec_p_r_f1[2]*100]\n","\n","  # Generate confusion matrix\n","  rec_cm = confusion_matrix(rec_actual, rec_pred)\n","  df_rec_cm = pd.DataFrame(rec_cm)\n","  df_rec_cm.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/XLNet_GTr_CM_\" + str(k) + \" \" + runID +\".csv\")\n","\n","  # Reset the model by restoring the initital model weights to prevent overtraining\n","  model.set_weights(init_weights)\n","  k=k+1\n","\n","# Save the training history result\n","df_tr_hist.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/XLNet_GTr_TrainHist_\" + runID +\".csv\")\n","\n","# Save the cross validation result\n","df_val_result = df_val_result.round(decimals=2)\n","df_val_result.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/XLNet_GTr_CV_\" + runID +\".csv\")\n","\n","# Save RunID,Model,Accuracy,Precision,Recall,F1 for the Recomposed SMR\n","df_re_val_result = df_val_result[df_val_result.ValType=='Recomposed']\n","no_of_runs = len(df_re_val_result)\n","df_GTxM_Clf_CV_results = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_Clf_CV_results.csv\")\n","avg_Accuracy = np.sum(df_re_val_result['Accuracy']) / no_of_runs\n","avg_Precision = np.sum(df_re_val_result['Precision']) / no_of_runs\n","avg_Recall = np.sum(df_re_val_result['Recall']) / no_of_runs\n","avg_F1 = np.sum(df_re_val_result['F1']) / no_of_runs\n","df_GTxM_Clf_CV_results.loc[len(df_GTxM_Clf_CV_results)] = [runID, 'XLNet', avg_Accuracy, avg_Precision, avg_Recall, avg_F1]\n","df_GTxM_Clf_CV_results.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_Clf_CV_results.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkzVZhP3vEQ-","outputId":"7b0e642e-ec61-4303-c1bd-ddc248f3261a","executionInfo":{"status":"ok","timestamp":1676750792315,"user_tz":-60,"elapsed":5350390,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training for Cross Val: 1 \n","Indexes for tr [     0      1      2 ... 101450 101451 101452] and val [     4      8     10 ... 101427 101429 101453]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (81163, 99), y_tr (81163, 5), X_val (20291, 99) and y_val (20291, 5)\n","creating the tr and val datasets...\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["317/317 [==============================] - 195s 304ms/step - loss: 1.1556 - accuracy: 0.6024\n","Epoch 2/10\n","317/317 [==============================] - 96s 301ms/step - loss: 0.7077 - accuracy: 0.7631\n","Epoch 3/10\n","317/317 [==============================] - 94s 296ms/step - loss: 0.5591 - accuracy: 0.8170\n","Epoch 4/10\n","317/317 [==============================] - 93s 294ms/step - loss: 0.4577 - accuracy: 0.8504\n","Epoch 5/10\n","317/317 [==============================] - 94s 295ms/step - loss: 0.3903 - accuracy: 0.8725\n","Epoch 6/10\n","317/317 [==============================] - 95s 299ms/step - loss: 0.3372 - accuracy: 0.8908\n","Epoch 7/10\n","317/317 [==============================] - 95s 300ms/step - loss: 0.2938 - accuracy: 0.9055\n","Epoch 8/10\n","317/317 [==============================] - 95s 299ms/step - loss: 0.2580 - accuracy: 0.9166\n","Epoch 9/10\n","317/317 [==============================] - 97s 305ms/step - loss: 0.2204 - accuracy: 0.9293\n","Epoch 10/10\n","317/317 [==============================] - 97s 305ms/step - loss: 0.1916 - accuracy: 0.9384\n","80/80 [==============================] - 27s 278ms/step\n","Generating decomposed SMR performance metrics ...\n","Recomposed SMR Acc: 86.39298211029521, Prec: 87.12402600301424, Recall: 86.39298211029521, F1 86.10134703475273\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 89.71354166666666, Prec: 90.4096938649203, Recall: 89.71354166666666, F1 89.19001717716743\n","\n","Training for Cross Val: 2 \n","Indexes for tr [     0      1      2 ... 101451 101452 101453] and val [    11     12     25 ... 101439 101442 101443]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (81163, 99), y_tr (81163, 5), X_val (20291, 99) and y_val (20291, 5)\n","creating the tr and val datasets...\n","Epoch 1/10\n","317/317 [==============================] - 99s 311ms/step - loss: 1.2652 - accuracy: 0.5515\n","Epoch 2/10\n","317/317 [==============================] - 99s 312ms/step - loss: 0.7452 - accuracy: 0.7491\n","Epoch 3/10\n","317/317 [==============================] - 100s 315ms/step - loss: 0.5780 - accuracy: 0.8101\n","Epoch 4/10\n","317/317 [==============================] - 102s 321ms/step - loss: 0.4779 - accuracy: 0.8437\n","Epoch 5/10\n","317/317 [==============================] - 100s 316ms/step - loss: 0.4086 - accuracy: 0.8678\n","Epoch 6/10\n","317/317 [==============================] - 100s 316ms/step - loss: 0.3551 - accuracy: 0.8845\n","Epoch 7/10\n","317/317 [==============================] - 97s 306ms/step - loss: 0.3087 - accuracy: 0.9005\n","Epoch 8/10\n","317/317 [==============================] - 95s 300ms/step - loss: 0.2659 - accuracy: 0.9145\n","Epoch 9/10\n","317/317 [==============================] - 95s 299ms/step - loss: 0.2270 - accuracy: 0.9273\n","Epoch 10/10\n","317/317 [==============================] - 95s 300ms/step - loss: 0.2015 - accuracy: 0.9349\n","80/80 [==============================] - 11s 115ms/step\n","Generating decomposed SMR performance metrics ...\n","Recomposed SMR Acc: 87.00409048346557, Prec: 87.78915452635766, Recall: 87.00409048346557, F1 86.85017715952912\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 91.87096774193549, Prec: 92.44647478512393, Recall: 91.87096774193549, F1 91.30384681946043\n","\n","Training for Cross Val: 3 \n","Indexes for tr [     0      1      3 ... 101451 101452 101453] and val [     2      6      7 ... 101434 101445 101449]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (81163, 99), y_tr (81163, 5), X_val (20291, 99) and y_val (20291, 5)\n","creating the tr and val datasets...\n","Epoch 1/10\n","317/317 [==============================] - 95s 300ms/step - loss: 1.3515 - accuracy: 0.5150\n","Epoch 2/10\n","317/317 [==============================] - 94s 297ms/step - loss: 0.7587 - accuracy: 0.7406\n","Epoch 3/10\n","317/317 [==============================] - 94s 297ms/step - loss: 0.5823 - accuracy: 0.8077\n","Epoch 4/10\n","317/317 [==============================] - 94s 297ms/step - loss: 0.4772 - accuracy: 0.8431\n","Epoch 5/10\n","317/317 [==============================] - 94s 297ms/step - loss: 0.4042 - accuracy: 0.8677\n","Epoch 6/10\n","317/317 [==============================] - 95s 299ms/step - loss: 0.3555 - accuracy: 0.8847\n","Epoch 7/10\n","317/317 [==============================] - 94s 297ms/step - loss: 0.3066 - accuracy: 0.8997\n","Epoch 8/10\n","317/317 [==============================] - 93s 295ms/step - loss: 0.2613 - accuracy: 0.9153\n","Epoch 9/10\n","317/317 [==============================] - 93s 295ms/step - loss: 0.2293 - accuracy: 0.9254\n","Epoch 10/10\n","317/317 [==============================] - 94s 295ms/step - loss: 0.1978 - accuracy: 0.9357\n","80/80 [==============================] - 10s 111ms/step\n","Generating decomposed SMR performance metrics ...\n","Recomposed SMR Acc: 86.40776699029125, Prec: 87.48640929588993, Recall: 86.40776699029125, F1 86.24924343878898\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 90.86229086229086, Prec: 91.71645279892702, Recall: 90.86229086229086, F1 90.39190717043658\n","\n","Training for Cross Val: 4 \n","Indexes for tr [     2      3      4 ... 101451 101452 101453] and val [     0      1     14 ... 101440 101447 101448]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (81163, 99), y_tr (81163, 5), X_val (20291, 99) and y_val (20291, 5)\n","creating the tr and val datasets...\n","Epoch 1/10\n","317/317 [==============================] - 93s 295ms/step - loss: 1.2573 - accuracy: 0.5561\n","Epoch 2/10\n","317/317 [==============================] - 94s 296ms/step - loss: 0.7549 - accuracy: 0.7417\n","Epoch 3/10\n","317/317 [==============================] - 93s 294ms/step - loss: 0.5798 - accuracy: 0.8072\n","Epoch 4/10\n","317/317 [==============================] - 93s 293ms/step - loss: 0.4786 - accuracy: 0.8425\n","Epoch 5/10\n","317/317 [==============================] - 93s 293ms/step - loss: 0.4132 - accuracy: 0.8651\n","Epoch 6/10\n","317/317 [==============================] - 93s 294ms/step - loss: 0.3588 - accuracy: 0.8824\n","Epoch 7/10\n","317/317 [==============================] - 93s 293ms/step - loss: 0.3111 - accuracy: 0.8981\n","Epoch 8/10\n","317/317 [==============================] - 93s 294ms/step - loss: 0.2771 - accuracy: 0.9105\n","Epoch 9/10\n","317/317 [==============================] - 93s 294ms/step - loss: 0.2392 - accuracy: 0.9230\n","Epoch 10/10\n","317/317 [==============================] - 93s 293ms/step - loss: 0.2049 - accuracy: 0.9345\n","80/80 [==============================] - 10s 111ms/step\n","Generating decomposed SMR performance metrics ...\n","Recomposed SMR Acc: 85.99379035040165, Prec: 86.8552475095069, Recall: 85.99379035040165, F1 85.69349844916941\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 90.19354838709678, Prec: 90.6540097159407, Recall: 90.19354838709678, F1 89.49169202171419\n","\n","Training for Cross Val: 5 \n","Indexes for tr [     0      1      2 ... 101448 101449 101453] and val [     3      5      9 ... 101450 101451 101452]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (81164, 99), y_tr (81164, 5), X_val (20290, 99) and y_val (20290, 5)\n","creating the tr and val datasets...\n","Epoch 1/10\n","317/317 [==============================] - 93s 294ms/step - loss: 1.2760 - accuracy: 0.5497\n","Epoch 2/10\n","317/317 [==============================] - 93s 293ms/step - loss: 0.7497 - accuracy: 0.7433\n","Epoch 3/10\n","317/317 [==============================] - 93s 294ms/step - loss: 0.5839 - accuracy: 0.8059\n","Epoch 4/10\n","317/317 [==============================] - 93s 293ms/step - loss: 0.4839 - accuracy: 0.8410\n","Epoch 5/10\n","317/317 [==============================] - 93s 294ms/step - loss: 0.4087 - accuracy: 0.8666\n","Epoch 6/10\n","317/317 [==============================] - 93s 293ms/step - loss: 0.3610 - accuracy: 0.8832\n","Epoch 7/10\n","317/317 [==============================] - 93s 294ms/step - loss: 0.3081 - accuracy: 0.9000\n","Epoch 8/10\n","317/317 [==============================] - 93s 294ms/step - loss: 0.2710 - accuracy: 0.9117\n","Epoch 9/10\n","317/317 [==============================] - 93s 294ms/step - loss: 0.2318 - accuracy: 0.9242\n","Epoch 10/10\n","317/317 [==============================] - 93s 294ms/step - loss: 0.1996 - accuracy: 0.9349\n","80/80 [==============================] - 10s 110ms/step\n","Generating decomposed SMR performance metrics ...\n","Recomposed SMR Acc: 86.5105963528832, Prec: 87.24266868335194, Recall: 86.5105963528832, F1 86.29022802788501\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 91.07142857142857, Prec: 91.39208757467352, Recall: 91.07142857142857, F1 90.53806377675264\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"MAPsj_yfCRbP"},"execution_count":null,"outputs":[]}]}