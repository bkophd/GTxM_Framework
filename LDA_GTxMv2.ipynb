{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4dd10fe-8199-44fc-a88d-a2e4901da9dc",
   "metadata": {},
   "source": [
    "Latent Dirichlet Allocation Tutorial at:\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea86612-f691-4a9d-9d24-03cfcc4914f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim for topic modeling functions\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4d3c9e-1e3a-44fd-af3f-e005f9ab18b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kazeem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\kazeem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kazeem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# libraries to tokenize, clean up and calculate word counts\n",
    "import nltk\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "\n",
    "wordlist = nltk.corpus.words.words()\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "wordlist = [stemmer.stem(lemmatizer.lemmatize(word)) for word in wordlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28705759-4996-41b4-8173-63da630fd40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_csv('D:/KOPro/PhD/Implementation/SourceCode/py38/GTxM/data/MasterTokens_10to260SupTw_Not_GTr.csv')\n",
    "#df = pd.read_csv('D:/KOPro/PhD/TechDelivery/SourceCode/py38/GTxM/data/GroundTruthTokens.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14aecc3-84c5-47bc-9b02-a1c9b66240e6",
   "metadata": {},
   "source": [
    "<b>Available corpus fields:</b><br>\n",
    "smrHashtags<br>smrMentions<br>smrNER<br>smrNouns<br>smrVerbs<br>smrAdverbs<br>smrAdjectives<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7633b34-fe09-458c-8f71-e33c6d37679f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1512"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['RecDoc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4f42d1-48a3-45e4-85bd-13415587d803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowid</th>\n",
       "      <th>RecID</th>\n",
       "      <th>PubTitle</th>\n",
       "      <th>RecDoc</th>\n",
       "      <th>countSupTweets</th>\n",
       "      <th>smrHashtags</th>\n",
       "      <th>smrMentions</th>\n",
       "      <th>smrNER</th>\n",
       "      <th>smrNouns</th>\n",
       "      <th>smrVerbs</th>\n",
       "      <th>smrAdverbs</th>\n",
       "      <th>smrAdjectives</th>\n",
       "      <th>smrTopText</th>\n",
       "      <th>smrSummary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>155</td>\n",
       "      <td>1057291398880391170</td>\n",
       "      <td>Could fireworks be restricted at Scottish homes?</td>\n",
       "      <td>This is the effect fireworks can have on a dog...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>banfireworks fireworks</td>\n",
       "      <td>neilmackay gamesshed didriksoderlind bbcradios...</td>\n",
       "      <td>juli timmi uk last night daili bob marley ub j...</td>\n",
       "      <td>effect firework dog juli hors goat lot firewor...</td>\n",
       "      <td>stand comfort reli built hear held purchas des...</td>\n",
       "      <td>outsid long care fairli ahead exactli seemingl...</td>\n",
       "      <td>gener licens wide gener last daili big loud so...</td>\n",
       "      <td>This is the effect fireworks can have on a dog...</td>\n",
       "      <td>This is the effect fireworks can have on a dog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>258</td>\n",
       "      <td>1124056098925944832</td>\n",
       "      <td>Sonic movie: New trailer shows redesigned hedg...</td>\n",
       "      <td>Thank you for the support. And the criticism. ...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>sonicmovie gottafixfast</td>\n",
       "      <td>fowltown</td>\n",
       "      <td>paramount sega sonic hollywood sonic jeff</td>\n",
       "      <td>support critic messag design chang paramount s...</td>\n",
       "      <td>happen care watch show listen handl learn wait...</td>\n",
       "      <td>fulli total definit actual</td>\n",
       "      <td>loud clear happi commit hard massiv awesom gla...</td>\n",
       "      <td>Thank you for the support. And the criticism. ...</td>\n",
       "      <td>Thank you for the support. And the criticism. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>285</td>\n",
       "      <td>1135851552495865857</td>\n",
       "      <td>'I Don't Know Prince Andrew,' Trump Says. Phot...</td>\n",
       "      <td>????????On Day 2 of the #USStateVisit, The Duk...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>trump2020 usstatevisit realtalk liarinchief pe...</td>\n",
       "      <td>10downingstreet teram323tere fox5atlanta thedu...</td>\n",
       "      <td>duke york donald trump st jame palac uk us tru...</td>\n",
       "      <td>duke york prime minist presid donald trump st ...</td>\n",
       "      <td>clarifi surpris jump hear rememb mean swear fi...</td>\n",
       "      <td>usual besid cours anymor though enough clearli...</td>\n",
       "      <td>person dumber truth proud profession polit hug...</td>\n",
       "      <td>????????On Day 2 of the #USStateVisit, The Duk...</td>\n",
       "      <td>????????On Day 2 of the The Duke of York Prime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>334</td>\n",
       "      <td>1151389038781390848</td>\n",
       "      <td>Naga Munchetty, BBC News Anchor, Has Reprimand...</td>\n",
       "      <td>\"I've been told as a woman of colour to 'go ho...</td>\n",
       "      <td>260.0</td>\n",
       "      <td>racist britains istandwithnaga trump2020 faken...</td>\n",
       "      <td>bbcworld foxnew washingtonpost jam99percent sp...</td>\n",
       "      <td>trump truth welldon speak faeifa fiffaeifa fif...</td>\n",
       "      <td>woman colour experi reaction comment presid tr...</td>\n",
       "      <td>share discu suppress speak experi listen trump...</td>\n",
       "      <td>home probabl freeli everytim regularli total s...</td>\n",
       "      <td>faeifaei anti trump fals sad bad vile pervert ...</td>\n",
       "      <td>\"I've been told as a woman of colour to 'go ho...</td>\n",
       "      <td>\"I've been told as a woman of colour to 'go ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>374</td>\n",
       "      <td>1165822705037217792</td>\n",
       "      <td>Cars Are Death Machines. Self-Driving Tech Won...</td>\n",
       "      <td>Please RT if you, or someone you know, has bee...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aarieff realdonaldtrump ttmitch</td>\n",
       "      <td>yard hoboken nj washington yanke stadium long ...</td>\n",
       "      <td>car experi mobil panel daughter car yard aspha...</td>\n",
       "      <td>hit hit thrown end broken land save pass place...</td>\n",
       "      <td>badli recent straight right nearli nearli slow...</td>\n",
       "      <td>littl upcom catastroph oncom danger high small...</td>\n",
       "      <td>Please RT if you, or someone you know, has bee...</td>\n",
       "      <td>Please RT if you, or someone you know, has bee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rowid                RecID  \\\n",
       "0    155  1057291398880391170   \n",
       "1    258  1124056098925944832   \n",
       "2    285  1135851552495865857   \n",
       "3    334  1151389038781390848   \n",
       "4    374  1165822705037217792   \n",
       "\n",
       "                                            PubTitle  \\\n",
       "0   Could fireworks be restricted at Scottish homes?   \n",
       "1  Sonic movie: New trailer shows redesigned hedg...   \n",
       "2  'I Don't Know Prince Andrew,' Trump Says. Phot...   \n",
       "3  Naga Munchetty, BBC News Anchor, Has Reprimand...   \n",
       "4  Cars Are Death Machines. Self-Driving Tech Won...   \n",
       "\n",
       "                                              RecDoc  countSupTweets  \\\n",
       "0  This is the effect fireworks can have on a dog...            45.0   \n",
       "1  Thank you for the support. And the criticism. ...            18.0   \n",
       "2  ????????On Day 2 of the #USStateVisit, The Duk...           115.0   \n",
       "3  \"I've been told as a woman of colour to 'go ho...           260.0   \n",
       "4  Please RT if you, or someone you know, has bee...            17.0   \n",
       "\n",
       "                                         smrHashtags  \\\n",
       "0                             banfireworks fireworks   \n",
       "1                            sonicmovie gottafixfast   \n",
       "2  trump2020 usstatevisit realtalk liarinchief pe...   \n",
       "3  racist britains istandwithnaga trump2020 faken...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                         smrMentions  \\\n",
       "0  neilmackay gamesshed didriksoderlind bbcradios...   \n",
       "1                                           fowltown   \n",
       "2  10downingstreet teram323tere fox5atlanta thedu...   \n",
       "3  bbcworld foxnew washingtonpost jam99percent sp...   \n",
       "4                    aarieff realdonaldtrump ttmitch   \n",
       "\n",
       "                                              smrNER  \\\n",
       "0  juli timmi uk last night daili bob marley ub j...   \n",
       "1          paramount sega sonic hollywood sonic jeff   \n",
       "2  duke york donald trump st jame palac uk us tru...   \n",
       "3  trump truth welldon speak faeifa fiffaeifa fif...   \n",
       "4  yard hoboken nj washington yanke stadium long ...   \n",
       "\n",
       "                                            smrNouns  \\\n",
       "0  effect firework dog juli hors goat lot firewor...   \n",
       "1  support critic messag design chang paramount s...   \n",
       "2  duke york prime minist presid donald trump st ...   \n",
       "3  woman colour experi reaction comment presid tr...   \n",
       "4  car experi mobil panel daughter car yard aspha...   \n",
       "\n",
       "                                            smrVerbs  \\\n",
       "0  stand comfort reli built hear held purchas des...   \n",
       "1  happen care watch show listen handl learn wait...   \n",
       "2  clarifi surpris jump hear rememb mean swear fi...   \n",
       "3  share discu suppress speak experi listen trump...   \n",
       "4  hit hit thrown end broken land save pass place...   \n",
       "\n",
       "                                          smrAdverbs  \\\n",
       "0  outsid long care fairli ahead exactli seemingl...   \n",
       "1                         fulli total definit actual   \n",
       "2  usual besid cours anymor though enough clearli...   \n",
       "3  home probabl freeli everytim regularli total s...   \n",
       "4  badli recent straight right nearli nearli slow...   \n",
       "\n",
       "                                       smrAdjectives  \\\n",
       "0  gener licens wide gener last daili big loud so...   \n",
       "1  loud clear happi commit hard massiv awesom gla...   \n",
       "2  person dumber truth proud profession polit hug...   \n",
       "3  faeifaei anti trump fals sad bad vile pervert ...   \n",
       "4  littl upcom catastroph oncom danger high small...   \n",
       "\n",
       "                                          smrTopText  \\\n",
       "0  This is the effect fireworks can have on a dog...   \n",
       "1  Thank you for the support. And the criticism. ...   \n",
       "2  ????????On Day 2 of the #USStateVisit, The Duk...   \n",
       "3  \"I've been told as a woman of colour to 'go ho...   \n",
       "4  Please RT if you, or someone you know, has bee...   \n",
       "\n",
       "                                          smrSummary  \n",
       "0  This is the effect fireworks can have on a dog...  \n",
       "1  Thank you for the support. And the criticism. ...  \n",
       "2  ????????On Day 2 of the The Duke of York Prime...  \n",
       "3  \"I've been told as a woman of colour to 'go ho...  \n",
       "4  Please RT if you, or someone you know, has bee...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7c6e15-5775-480a-8589-aac50bc39a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1512"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f49272ed-16bf-4781-9df4-405e3d029a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token list created successfully.\n"
     ]
    }
   ],
   "source": [
    "ExpName = \"CGTNounAdv\"\n",
    "# df2 = df['smrNER'].fillna(value='') + df['smrAdverbs'].fillna(value='')\n",
    "# df2 = df['smrNouns'].fillna(value='') + df['smrAdjectives'].fillna(value='')\n",
    "# df2 = df['smrNouns'].fillna(value='') + df['smrAdverbs'].fillna(value='') + df['smrAdjectives'].fillna(value='')\n",
    "df2 = df['smrNouns'].fillna(value='') + df['smrAdverbs'].fillna(value='')\n",
    "# df2 = df['smrMentions'].fillna(value='') + df['smrNouns'].fillna(value='') + df['smrAdverbs'].fillna(value='')\n",
    "# df2 = df['smrHashtags'].fillna(value='') + df['smrNouns'].fillna(value='') + df['smrNER'].fillna(value='')\n",
    "# df2 = df['smrHashtags'].fillna(value='') + df['smrNouns'].fillna(value='') + df['smrNER'].fillna(value='')\n",
    "# df2 = df['smrHashtags'].fillna(value='') + df['smrMentions'].fillna(value='') + df['smrNER'].fillna(value='')\n",
    "# df2 = df['smrHashtags'].fillna(value='') + df['smrMentions'].fillna(value='') + df['smrNouns'].fillna(value='')\n",
    "# df2 = df['smrHashtags'].fillna(value='') + df['smrNER'].fillna(value='')\n",
    "# df2 = df['smrHashtags'].fillna(value='') + df['smrNouns'].fillna(value='') + df['smrVerbs'].fillna(value='')\n",
    "# df2 = df['smrHashtags'].fillna(value='') + df['smrNER'].fillna(value='')\n",
    "# df2 = df['smrMentions'].fillna(value='') + df['smrNouns'].fillna(value='') + df['smrVerbs'].fillna(value='')\n",
    "# df2 = df['smrMentions'].fillna(value='') + df['smrNER'].fillna(value='')\n",
    "# df2 = df['smrNouns'].fillna(value='') + df['smrVerbs'].fillna(value='')\n",
    "# df2 = df['smrMentions'].fillna(value='') + df['smrNouns'].fillna(value='') \n",
    "# df2.index = df[\"RecID\"]\n",
    "data = df2.str.split()\n",
    "data_words = data.values.tolist()\n",
    "print('Token list created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383d050e-d972-46e3-a7cb-594b0e457648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_words[0]\n",
    "#data.iloc[1]\n",
    "#data.index\n",
    "\n",
    "df_docs = df['RecID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80019aa-6f5f-4dfd-b7a7-95ad87e37dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word dictionary created successfully.\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_words)\n",
    "print('Word dictionary created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d141b63-ea61-4dfe-a30b-57e1457d9d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-Doc-Frequency created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Term Document Frequency\n",
    "texts = data_words\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "print('Term-Doc-Frequency created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ccb300b-883c-4259-8b87-9211f2a6c3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69112e5b-727f-46f6-b080-b1b50d807e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LDA model...\n",
      "LDA model created successfully.\n",
      "[(0,\n",
      "  '0.043*\"famili\" + 0.023*\"love\" + 0.022*\"fy\" + 0.021*\"gy\" + 0.019*\"servic\" + '\n",
      "  '0.018*\"friend\" + 0.018*\"retir\" + 0.018*\"life\" + 0.015*\"god\" + '\n",
      "  '0.014*\"heart\"'),\n",
      " (1,\n",
      "  '0.042*\"peopl\" + 0.030*\"countri\" + 0.015*\"hate\" + 0.014*\"africa\" + '\n",
      "  '0.012*\"child\" + 0.012*\"jew\" + 0.011*\"christian\" + 0.011*\"jesu\" + '\n",
      "  '0.011*\"israel\" + 0.011*\"canada\"'),\n",
      " (2,\n",
      "  '0.022*\"peopl\" + 0.022*\"space\" + 0.013*\"forc\" + 0.010*\"flight\" + '\n",
      "  '0.008*\"money\" + 0.008*\"fire\" + 0.007*\"uniform\" + 0.007*\"air\" + '\n",
      "  '0.007*\"dongcot\" + 0.007*\"world\"'),\n",
      " (3,\n",
      "  '0.000*\"plsfnofyefy\" + 0.000*\"outland\" + 0.000*\"saucepan\" + 0.000*\"rua\" + '\n",
      "  '0.000*\"puffin\" + 0.000*\"primev\" + 0.000*\"pressi\" + 0.000*\"shetland\" + '\n",
      "  '0.000*\"perez\" + 0.000*\"murdersfno\"'),\n",
      " (4,\n",
      "  '0.176*\"anc\" + 0.092*\"anoan\" + 0.073*\"anian\" + 0.057*\"ancan\" + 0.056*\"anaan\" '\n",
      "  '+ 0.052*\"anuan\" + 0.044*\"ane\" + 0.039*\"anean\" + 0.034*\"anpsan\" + '\n",
      "  '0.028*\"annan\"'),\n",
      " (5,\n",
      "  '0.026*\"eu\" + 0.022*\"uk\" + 0.019*\"parti\" + 0.016*\"peopl\" + 0.014*\"brexit\" + '\n",
      "  '0.014*\"countri\" + 0.010*\"tori\" + 0.009*\"leader\" + 0.009*\"bori\" + '\n",
      "  '0.009*\"labour\"'),\n",
      " (6,\n",
      "  '0.030*\"peopl\" + 0.029*\"polic\" + 0.028*\"law\" + 0.014*\"offic\" + 0.013*\"crime\" '\n",
      "  '+ 0.011*\"right\" + 0.011*\"citi\" + 0.010*\"gun\" + 0.010*\"countri\" + '\n",
      "  '0.010*\"court\"'),\n",
      " (7,\n",
      "  '0.027*\"facebook\" + 0.012*\"fb\" + 0.008*\"spacex\" + 0.007*\"zuckerberg\" + '\n",
      "  '0.002*\"mark\" + 0.001*\"cesspool\" + 0.000*\"pravda\" + 0.000*\"satellit\" + '\n",
      "  '0.000*\"starlink\" + 0.000*\"zuck\"'),\n",
      " (8,\n",
      "  '0.026*\"mla\" + 0.020*\"jackson\" + 0.016*\"buhari\" + 0.007*\"rori\" + '\n",
      "  '0.003*\"castl\" + 0.002*\"naija\" + 0.001*\"blade\" + 0.000*\"abuja\" + '\n",
      "  '0.000*\"sowor\" + 0.000*\"dss\"'),\n",
      " (9,\n",
      "  '0.037*\"peopl\" + 0.021*\"woman\" + 0.014*\"person\" + 0.013*\"man\" + '\n",
      "  '0.011*\"dongcot\" + 0.009*\"medium\" + 0.008*\"tweet\" + 0.008*\"fact\" + '\n",
      "  '0.008*\"life\" + 0.008*\"igcom\"'),\n",
      " (10,\n",
      "  '0.232*\"au\" + 0.154*\"auo\" + 0.091*\"scotland\" + 0.072*\"auu\" + 0.052*\"fa\" + '\n",
      "  '0.032*\"independ\" + 0.028*\"england\" + 0.021*\"snp\" + 0.020*\"union\" + '\n",
      "  '0.015*\"scot\"'),\n",
      " (11,\n",
      "  '0.017*\"bound\" + 0.007*\"favorit\" + 0.004*\"turtl\" + 0.003*\"elain\" + '\n",
      "  '0.000*\"zac\" + 0.000*\"peerag\" + 0.000*\"marc\" + 0.000*\"apparatchik\" + '\n",
      "  '0.000*\"kamala\" + 0.000*\"goldsmith\"'),\n",
      " (12,\n",
      "  '0.570*\"agps\" + 0.002*\"altitud\" + 0.001*\"arkansa\" + 0.000*\"afeigps\" + '\n",
      "  '0.000*\"gua\" + 0.000*\"medicaid\" + 0.000*\"ryan\" + 0.000*\"voucher\" + '\n",
      "  '0.000*\"inflat\" + 0.000*\"socsec\"'),\n",
      " (13,\n",
      "  '0.001*\"manual\" + 0.000*\"ua\" + 0.000*\"landlord\" + 0.000*\"nasa\" + '\n",
      "  '0.000*\"vikram\" + 0.000*\"isro\" + 0.000*\"lander\" + 0.000*\"thermostat\" + '\n",
      "  '0.000*\"debri\" + 0.000*\"temperatur\"'),\n",
      " (14,\n",
      "  '0.204*\"ae\" + 0.119*\"china\" + 0.022*\"us\" + 0.019*\"pakistan\" + 0.019*\"world\" '\n",
      "  '+ 0.018*\"peopl\" + 0.016*\"ccp\" + 0.015*\"right\" + 0.013*\"freedom\" + '\n",
      "  '0.013*\"ph\"'),\n",
      " (15,\n",
      "  '0.031*\"berni\" + 0.021*\"warren\" + 0.021*\"candid\" + 0.020*\"peopl\" + '\n",
      "  '0.020*\"campaign\" + 0.017*\"presid\" + 0.016*\"trump\" + 0.015*\"joe\" + '\n",
      "  '0.014*\"democrat\" + 0.013*\"vote\"'),\n",
      " (16,\n",
      "  '0.075*\"firework\" + 0.000*\"rf\" + 0.000*\"nsw\" + 0.000*\"firefight\" + '\n",
      "  '0.000*\"bushfir\" + 0.000*\"nye\" + 0.000*\"clover\" + 0.000*\"harbour\" + '\n",
      "  '0.000*\"tourism\" + 0.000*\"firi\"'),\n",
      " (17,\n",
      "  '0.022*\"book\" + 0.018*\"viru\" + 0.014*\"movi\" + 0.013*\"christma\" + '\n",
      "  '0.011*\"anim\" + 0.009*\"art\" + 0.009*\"song\" + 0.008*\"player\" + 0.008*\"chees\" '\n",
      "  '+ 0.008*\"game\"'),\n",
      " (18,\n",
      "  '0.334*\"fc\" + 0.066*\"fn\" + 0.023*\"que\" + 0.015*\"congratul\" + 0.013*\"de\" + '\n",
      "  '0.013*\"la\" + 0.012*\"world\" + 0.011*\"countri\" + 0.010*\"lo\" + 0.009*\"faeafa\"'),\n",
      " (19,\n",
      "  '0.050*\"trump\" + 0.020*\"presid\" + 0.015*\"senat\" + 0.013*\"iran\" + '\n",
      "  '0.013*\"countri\" + 0.011*\"us\" + 0.010*\"impeach\" + 0.009*\"american\" + '\n",
      "  '0.009*\"america\" + 0.009*\"hous\"')]\n"
     ]
    }
   ],
   "source": [
    "# Build LDA model\n",
    "print('Building LDA model...')\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           #num_topics=5,     \n",
    "                                           num_topics=20,\n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "# Print the Keyword in the 20 topics\n",
    "print('LDA model created successfully.')\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bdbfe61-7370-47b9-a5de-4695e9347afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating performance scores for CGTNounAdv\n",
      "\n",
      "Perplexity: -10.84\n",
      "\n",
      "Coherence Score: 0.54\n"
     ]
    }
   ],
   "source": [
    "print('Generating performance scores for '+ExpName)\n",
    "# Compute Perplexity\n",
    "perplex_lda = lda_model.log_perplexity(corpus)\n",
    "print('\\nPerplexity: {:.2f}'.format(perplex_lda))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: {:.2f}'.format(coherence_lda))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628dae25-d527-4165-a5cd-cd2ed77c7cd4",
   "metadata": {},
   "source": [
    "<b>Performance scores:</b><br>\n",
    "0. GTrNounAdv<br>\n",
    "Perplexity: -8.00<br>\n",
    "Coherence Score: 0.51<br>\n",
    "14. NounAdj<br>\n",
    "Perplexity: -10.66<br>\n",
    "Coherence Score: 0.50<br>\n",
    "13. NERAdverb<br>\n",
    "Perplexity: -12.22<br>\n",
    "Coherence Score: 0.57<br>\n",
    "12. NounAdverbAdj<br>\n",
    "Perplexity: -10.60<br>\n",
    "Coherence Score: 0.52<br>\n",
    "11. NounAdverb<br>\n",
    "Perplexity: -10.84<br>\n",
    "Coherence Score: 0.54<br>\n",
    "10. MentNounAdverb<br>\n",
    "......Perplexity:  -11.335431089830974<br>\n",
    "......Coherence Score:  0.5172917836343668<br>\n",
    "9. Hashtags+Nouns+NER<br>\n",
    "......Perplexity:  -11.389471096607<br>\n",
    "......Coherence Score:  0.5580963360366651<br>\n",
    "8. Hashtags+Mentions+NER<br>\n",
    "......Perplexity:  -15.337374736555555<br>\n",
    "......Coherence Score:  0.5550375566450458<br>\n",
    "7. Hashtags+Mentions+Nouns<br>\n",
    "......Perplexity:  -11.66981087109629<br>\n",
    "......Coherence Score:  0.5480562627150661<br>\n",
    "6. Hashtags+NER<br>\n",
    "......Perplexity:  -15.117791431322871<br>\n",
    "......Coherence Score:  0.4584529220486597<br>\n",
    "5. Hashtags+Nouns+Verbs<br>\n",
    "......Perplexity:  -10.764463686408684<br>\n",
    "......Coherence Score:  0.48532559600503405<br>\n",
    "4. Mentions+Nouns+Verbs<br>\n",
    "......Perplexity:  -10.9279676838438<br>\n",
    "......Coherence Score:  0.43582162664144775<br>\n",
    "3. Mentions+NER<br>\n",
    "......Perplexity:  -15.548485846134131<br>\n",
    "......Coherence Score:  0.4594905858493948<br>\n",
    "2. Nouns+Verbs<br>\n",
    "......Perplexity:  -10.495273547798948<br>\n",
    "......Coherence Score:  0.42574474436248205<br>\n",
    "1. Mentions+Nouns<br>\n",
    "......Perplexity:  -11.390487661937238<br>\n",
    "......Coherence Score:  0.48191581854479937<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd4dee9-f0b5-408e-be8f-46645557bac4",
   "metadata": {},
   "source": [
    "<b>pyLDAvis Visualizations</b><br>\n",
    "https://stackoverflow.com/questions/50923430/what-does-the-parameter-mds-mean-in-the-pyldavis-sklearn-prepare-function<br>\n",
    "pcoa:Principal Coordinate Analysis(aka Classical Multidimensional Scaling)<br>\n",
    "mmds:Metric Multidimensional Scaling<br>\n",
    "tsne:t-distributed Stochastic Neighbor Embedding<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0050c570-5677-47a1-8d23-b95a8ef96baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kazeem\\anaconda3\\envs\\py38\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "C:\\Users\\kazeem\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:691: FutureWarning: 'square_distances' has been introduced in 0.24 to help phase out legacy squaring behavior. The 'legacy' setting will be removed in 1.1 (renaming of 0.26), and the default setting will be changed to True. In 1.3, 'square_distances' will be removed altogether, and distances will be squared by default. Set 'square_distances'=True to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#-- use sort_topics=False -- https://stackoverflow.com/questions/59322409/pyldavis-visualisation-does-not-align-with-generated-topics\n",
    "vis2 = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds='tsne', sort_topics=False)\n",
    "pyLDAvis.save_html(vis2, 'lda_tsne_'+ExpName+'_sortFalse_v2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1665092e-805a-42b7-9685-14d8116c717a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kazeem\\anaconda3\\envs\\py38\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n",
      "C:\\Users\\kazeem\\anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:691: FutureWarning: 'square_distances' has been introduced in 0.24 to help phase out legacy squaring behavior. The 'legacy' setting will be removed in 1.1 (renaming of 0.26), and the default setting will be changed to True. In 1.3, 'square_distances' will be removed altogether, and distances will be squared by default. Set 'square_distances'=True to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vis2 = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds='tsne', sort_topics=True)\n",
    "pyLDAvis.save_html(vis2, 'lda_tsne_'+ExpName+'_sortTrue_v2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1eaa410-59e8-4b22-b856-58c5f68e0b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds='mmds', sort_topics=False)\n",
    "#pyLDAvis.save_html(vis, 'lda.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0784726-8b9b-4e87-97f0-58d5c3a1625e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate Document-Topic lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ff930bb-6542-403a-b60b-3d62994e713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic = lda_model.get_document_topics(corpus, minimum_probability=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ab3fa2d-e2eb-48fc-9e23-43f1f428164b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 0.13442786), (14, 0.5890485)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "043f43ac-0bd8-44f8-b1af-53e2030b56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approach: for loop comprehension\n",
    "#topics = [ [entry[0] for entry in doc] for doc in doc_topic ]\n",
    "#topics[0]\n",
    "#scores = [ [entry[1] for entry in doc] for doc in doc_topic ]\n",
    "#scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad753f50-4b80-4bfc-baa3-7b372fced58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative approach: get dominant topics based on scores\n",
    "#df_doc_topic = pd.DataFrame(columns=['RecID', 'TopicID', 'TopicScore'])\n",
    "#max(df_doc_topic['TopicScore'][1])\n",
    "#for i in range(len(df_docs)):\n",
    "#    max_idx = np.argmax(df_doc_topic['TopicScore'][i])\n",
    "#    print(df_docs[i], df_doc_topic['TopicID'][i][max_idx], df_doc_topic['TopicScore'][i][max_idx])\n",
    "#    df_doc_topic_dominant.loc[i] = [df_docs[i].astype(str), df_doc_topic['TopicID'][i][max_idx], df_doc_topic['TopicScore'][i][max_idx]]\n",
    "#    if i>5:\n",
    "#        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5ac37cc-1589-4fde-a271-0816c31bc82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "docs=[]\n",
    "topics=[]\n",
    "scores=[]\n",
    "for doc in doc_topic:\n",
    "    doc_id = df_docs.iloc[i]\n",
    "    i = i+1\n",
    "    #if i>5: break\n",
    "    for topic_id, score in doc:\n",
    "        #print(doc_id, topic_id, score)\n",
    "        scores.append(score)\n",
    "        topics.append(topic_id)\n",
    "        docs.append(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5551a24-1ec8-4b21-a5b1-1329f582fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results below are the old values based on this code (which stopped working):\n",
    "df_doc_topic = pd.DataFrame({'RecID': docs, 'TopicID': topics, 'TopicScore': scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fc79420-2bf3-4365-a5f2-e65f955d26e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecID</th>\n",
       "      <th>TopicID</th>\n",
       "      <th>TopicScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1057291398880391170</td>\n",
       "      <td>2</td>\n",
       "      <td>0.546937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1057291398880391170</td>\n",
       "      <td>5</td>\n",
       "      <td>0.138392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1124056098925944832</td>\n",
       "      <td>0</td>\n",
       "      <td>0.484139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1124056098925944832</td>\n",
       "      <td>2</td>\n",
       "      <td>0.171029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1124056098925944832</td>\n",
       "      <td>9</td>\n",
       "      <td>0.158561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>1223365339494453248</td>\n",
       "      <td>5</td>\n",
       "      <td>0.554148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>1223365339494453248</td>\n",
       "      <td>18</td>\n",
       "      <td>0.244555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249</th>\n",
       "      <td>222818213392678912</td>\n",
       "      <td>5</td>\n",
       "      <td>0.728429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4250</th>\n",
       "      <td>222818213392678912</td>\n",
       "      <td>9</td>\n",
       "      <td>0.200785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>833502973204459520</td>\n",
       "      <td>0</td>\n",
       "      <td>0.884053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4252 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RecID  TopicID  TopicScore\n",
       "0     1057291398880391170        2    0.546937\n",
       "1     1057291398880391170        5    0.138392\n",
       "2     1124056098925944832        0    0.484139\n",
       "3     1124056098925944832        2    0.171029\n",
       "4     1124056098925944832        9    0.158561\n",
       "...                   ...      ...         ...\n",
       "4247  1223365339494453248        5    0.554148\n",
       "4248  1223365339494453248       18    0.244555\n",
       "4249   222818213392678912        5    0.728429\n",
       "4250   222818213392678912        9    0.200785\n",
       "4251   833502973204459520        0    0.884053\n",
       "\n",
       "[4252 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09f228f9-fcf8-4e12-ba57-e4a11c901427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecID</th>\n",
       "      <th>TopicScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TopicID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>828</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>453</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>862</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>217</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>487</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RecID  TopicScore\n",
       "TopicID                   \n",
       "0          461         461\n",
       "1          161         161\n",
       "2          828         828\n",
       "4           45          45\n",
       "5          453         453\n",
       "6          324         324\n",
       "7            4           4\n",
       "9          862         862\n",
       "10          22          22\n",
       "12           1           1\n",
       "14          75          75\n",
       "15         214         214\n",
       "17         217         217\n",
       "18          98          98\n",
       "19         487         487"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc_topic.groupby(by='TopicID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be806d3d-76eb-4252-acfc-e58c81a15bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_topic.to_csv('lda_doc_topic_all_'+ExpName+'_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7010111e-0804-4933-ae24-fa359ddd9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_topic_nodup = df_doc_topic.sort_values(['TopicScore'], ascending=(False)).drop_duplicates(['RecID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9654216-f276-46d6-9652-2e9338e83488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1512"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_doc_topic_nodup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56366603-778c-45b5-8652-f99cf89f833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_topic_nodup.to_csv('lda_doc_dominant_topic_'+ExpName+'_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "716326d1-8677-48be-a05a-d9b9a4e53479",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_ndarray = df_doc_topic_nodup.TopicID.unique()\n",
    "topic_list =sorted(topics_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d545924-97e6-4f0f-94ed-139cb69fbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "listTopicID = list(set(df_doc_topic_nodup['TopicID'].tolist())) # get the unique list of Topic IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "70ffec79-d587-4e1d-8ecc-b0058a9029d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 4, 5, 6, 9, 10, 12, 14, 15, 17, 18, 19]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listTopicID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e82be2-1a32-45aa-9f9a-254ad169f821",
   "metadata": {},
   "source": [
    "## Select top 20%, upto 20 items max of each Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71f09be1-4c4e-4cda-90d8-345bae1db761",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 186 20\n",
      "1 20 4\n",
      "2 310 20\n",
      "3 25 5\n",
      "4 198 20\n",
      "5 84 17\n",
      "6 243 20\n",
      "7 3 1\n",
      "8 1 0\n",
      "9 31 6\n",
      "10 85 17\n",
      "11 38 8\n",
      "12 28 6\n",
      "13 260 20\n"
     ]
    }
   ],
   "source": [
    "df_doc_topic_top20pcent = pd.DataFrame(columns=['RecID', 'TopicID', 'TopicScore'])\n",
    "i=0\n",
    "for i in range(len(listTopicID)):\n",
    "    df_temp = df_doc_topic_nodup[(df_doc_topic_nodup.TopicID == listTopicID[i])]\n",
    "    topic_items = len(df_temp)\n",
    "    #if len(df_temp) > 9:\n",
    "    topic20pc_items = round(len(df_temp)/5)\n",
    "    if topic20pc_items > 20: #max 20 items\n",
    "        topic20pc_items = 20\n",
    "    df_temp = df_temp.head(topic20pc_items)\n",
    "    df_doc_topic_top20pcent = pd.concat([df_doc_topic_top20pcent, df_temp])\n",
    "    print(i, topic_items, topic20pc_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f69b157-01c6-42a3-9c8b-ce68ff9ff3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecID</th>\n",
       "      <th>TopicID</th>\n",
       "      <th>TopicScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1184501980313636864</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>1191372018500980736</td>\n",
       "      <td>0</td>\n",
       "      <td>0.912929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1180775281067462658</td>\n",
       "      <td>0</td>\n",
       "      <td>0.902320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>1201730618955948032</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1181111461306867713</td>\n",
       "      <td>0</td>\n",
       "      <td>0.886614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3106</th>\n",
       "      <td>1213913877135712258</td>\n",
       "      <td>19</td>\n",
       "      <td>0.758603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1181203256774664192</td>\n",
       "      <td>19</td>\n",
       "      <td>0.752758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>1221822472292634625</td>\n",
       "      <td>19</td>\n",
       "      <td>0.751133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>1206218767480438784</td>\n",
       "      <td>19</td>\n",
       "      <td>0.749127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>1214723617868660737</td>\n",
       "      <td>19</td>\n",
       "      <td>0.743303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RecID TopicID  TopicScore\n",
       "665   1184501980313636864       0    0.930105\n",
       "1328  1191372018500980736       0    0.912929\n",
       "168   1180775281067462658       0    0.902320\n",
       "2286  1201730618955948032       0    0.899565\n",
       "189   1181111461306867713       0    0.886614\n",
       "...                   ...     ...         ...\n",
       "3106  1213913877135712258      19    0.758603\n",
       "203   1181203256774664192      19    0.752758\n",
       "4131  1221822472292634625      19    0.751133\n",
       "2627  1206218767480438784      19    0.749127\n",
       "3175  1214723617868660737      19    0.743303\n",
       "\n",
       "[164 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc_topic_top20pcent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dba80a0-619b-47e6-858e-e94e1639bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_topic_top20pcent.to_csv('lda_doc_topic_top20pct_'+ExpName+'_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11678b5d-922b-410f-8337-bb4aa85cd3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecID</th>\n",
       "      <th>TopicScore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TopicID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RecID  TopicScore\n",
       "TopicID                   \n",
       "0           20          20\n",
       "1            4           4\n",
       "2           20          20\n",
       "4            5           5\n",
       "5           20          20\n",
       "6           17          17\n",
       "9           20          20\n",
       "10           1           1\n",
       "14           6           6\n",
       "15          17          17\n",
       "17           8           8\n",
       "18           6           6\n",
       "19          20          20"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc_topic_top20pcent.groupby(by='TopicID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "937bcf45-8dbd-48bc-8322-a9dc9bdfd063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_doc_topic_top20pcent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55475bdc-d60c-4f66-b7fb-dd300acc934b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
