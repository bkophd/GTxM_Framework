{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xIYU2pqMn3WbMEzfs5GsEWo8iUH8MeDD","timestamp":1644609098344},{"file_id":"13aLb_dvWhy8cgjtkUsY63FFz9Nrj39vE","timestamp":1641762890771},{"file_id":"1HMNUAtNAj9VQIwM4AEdpsBH9rjTii3Yg","timestamp":1641749303952}],"mount_file_id":"1HMNUAtNAj9VQIwM4AEdpsBH9rjTii3Yg","authorship_tag":"ABX9TyOq4M2PJUx3LDtJ5In6K1hK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"789995de0bf949fdb8da63b0f203f1da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68575df1085841679c0dc257170eb3ab","IPY_MODEL_ab5c7ac33e8d49aab26fa00e2af2bfe0","IPY_MODEL_dcc65f3f187c4c6cb09d5ce61995c464"],"layout":"IPY_MODEL_65e54e0ed1fb4d40aa5d5382369ea5e8"}},"68575df1085841679c0dc257170eb3ab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64149f9418b142589031a0efff3a4d8a","placeholder":"​","style":"IPY_MODEL_e1036f501fe74a72b8a7df2f90af3e97","value":"(…)face.co/t5-base/resolve/main/config.json: 100%"}},"ab5c7ac33e8d49aab26fa00e2af2bfe0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aac9b5a8c86546b0a0aed012ced5be2f","max":1208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b85c9d7e98248ec9359e3080aa2ad37","value":1208}},"dcc65f3f187c4c6cb09d5ce61995c464":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eda81f36eaee49e1bfc2dd06847b6877","placeholder":"​","style":"IPY_MODEL_8a2d5948a4404ed79b755703dcfdb862","value":" 1.21k/1.21k [00:00&lt;00:00, 38.0kB/s]"}},"65e54e0ed1fb4d40aa5d5382369ea5e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64149f9418b142589031a0efff3a4d8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1036f501fe74a72b8a7df2f90af3e97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aac9b5a8c86546b0a0aed012ced5be2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b85c9d7e98248ec9359e3080aa2ad37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eda81f36eaee49e1bfc2dd06847b6877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a2d5948a4404ed79b755703dcfdb862":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9b8a92d0bd14a529df11e7121f55b10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b2216eb0776240d2b342435bf871bc9c","IPY_MODEL_02597516739145d2bd66a027c45555dd","IPY_MODEL_0aa9457e5662438aa6459d4d030b5b77"],"layout":"IPY_MODEL_cd41e27cd21249ee8ef16af161341f4e"}},"b2216eb0776240d2b342435bf871bc9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d9c2c330a474292bb56cfb51d199a00","placeholder":"​","style":"IPY_MODEL_2080c0806b5848a7a9116fa50b1a4e2e","value":"(…)ace.co/t5-base/resolve/main/spiece.model: 100%"}},"02597516739145d2bd66a027c45555dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_176ca0a0f29049bea3415af2a5efe550","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd0a950b943c4a7a8e520c597162b656","value":791656}},"0aa9457e5662438aa6459d4d030b5b77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00f5599435964930b5007c445eb58daf","placeholder":"​","style":"IPY_MODEL_30959689eccf45f0a66e6c04b8235033","value":" 792k/792k [00:00&lt;00:00, 5.63MB/s]"}},"cd41e27cd21249ee8ef16af161341f4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d9c2c330a474292bb56cfb51d199a00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2080c0806b5848a7a9116fa50b1a4e2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"176ca0a0f29049bea3415af2a5efe550":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd0a950b943c4a7a8e520c597162b656":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00f5599435964930b5007c445eb58daf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30959689eccf45f0a66e6c04b8235033":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"951f7daef9d04202916edfcaee08d106":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_711c4cf517874539a3252ba63f79ec20","IPY_MODEL_042cba347d8d4870b235e75fd4ac1c03","IPY_MODEL_54a7dccaf126424d8158a84f5a0bbc5c"],"layout":"IPY_MODEL_e01a843d1a5147fa836f3c7c7a8ff124"}},"711c4cf517874539a3252ba63f79ec20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc41198d663e47b19cb4dae18ee6a7ec","placeholder":"​","style":"IPY_MODEL_2d0596d07de44edf8e4ca15201a490f6","value":"tf_model.h5: 100%"}},"042cba347d8d4870b235e75fd4ac1c03":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7651c3f979d445d84b24bf90f49d980","max":892146080,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63aec517f49c4230aa023cc165451ce8","value":892146080}},"54a7dccaf126424d8158a84f5a0bbc5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cae3cd58cb18425397af319c13e5a76c","placeholder":"​","style":"IPY_MODEL_eae266ee60094f68b94f8e29b9bf30d1","value":" 892M/892M [00:51&lt;00:00, 15.4MB/s]"}},"e01a843d1a5147fa836f3c7c7a8ff124":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc41198d663e47b19cb4dae18ee6a7ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d0596d07de44edf8e4ca15201a490f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7651c3f979d445d84b24bf90f49d980":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63aec517f49c4230aa023cc165451ce8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cae3cd58cb18425397af319c13e5a76c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eae266ee60094f68b94f8e29b9bf30d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# 2nd Run: to capture the detailed prediction per SMR for each of 5-Fold CV runs (1st run only saved for the last CV run)"],"metadata":{"id":"il-_0sUvDACM","executionInfo":{"status":"ok","timestamp":1699898969458,"user_tz":-60,"elapsed":632,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Credit: https://www.kaggle.com/code/harshpraharaj98/text-classification-using-bert-and-xlnet/notebook\n","# CV credit: https://www.kaggle.com/code/ravi02516/bert-training-5-fold-cross-validation"],"metadata":{"id":"RqCazhwjuXKV","executionInfo":{"status":"ok","timestamp":1699898969940,"user_tz":-60,"elapsed":3,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip uninstall -y transformers\n","!pip uninstall -y keras\n","!pip uninstall -y tensorflow\n","!pip install --upgrade keras==2.10.0\n","!pip install --upgrade tensorflow==2.10.0\n","!pip install --upgrade transformers==4.22.2\n","!pip install sentencepiece==0.1.97"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DUrpgdtvmgY0","executionInfo":{"status":"ok","timestamp":1699899076944,"user_tz":-60,"elapsed":106336,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"9dd5b707-2b56-41a4-fe50-72bdd2fd740c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: keras 2.12.0\n","Uninstalling keras-2.12.0:\n","  Successfully uninstalled keras-2.12.0\n","Found existing installation: tensorflow 2.12.0\n","Uninstalling tensorflow-2.12.0:\n","  Successfully uninstalled tensorflow-2.12.0\n","Collecting keras==2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras\n","Successfully installed keras-2.10.0\n","Collecting tensorflow==2.10.0\n","  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.59.2)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.9.0)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n","Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.0)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (16.0.6)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.2)\n","Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.0)\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n","Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.0)\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.34.0)\n","Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.0)\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.14.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.41.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.31.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n","Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, tensorboard, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.2\n","    Uninstalling tensorboard-data-server-0.7.2:\n","      Successfully uninstalled tensorboard-data-server-0.7.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.0\n","    Uninstalling tensorboard-2.12.0:\n","      Successfully uninstalled tensorboard-2.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","orbax-checkpoint 0.4.2 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\n","tensorflow-datasets 4.9.3 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.22.2\n","  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (3.13.1)\n","Collecting huggingface-hub<1.0,>=0.9.0 (from transformers==4.22.2)\n","  Downloading huggingface_hub-0.19.1-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.1/311.1 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.22.2)\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.2) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.2) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (2023.7.22)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.19.1 tokenizers-0.12.1 transformers-4.22.2\n","Collecting sentencepiece==0.1.97\n","  Downloading sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"05KBKr1FmWlU","executionInfo":{"status":"ok","timestamp":1699899084463,"user_tz":-60,"elapsed":7558,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import transformers #huggingface transformers library\n","from transformers import TFAutoModel, AutoTokenizer\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import sklearn\n","from sklearn.metrics import confusion_matrix\n","\n","import re\n","from datetime import datetime as dt\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score"]},{"cell_type":"code","source":["# Detect hardware, return appropriate distribution strategy\n","try:\n","    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","    # set: this is always the case on Kaggle.\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    #strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","    strategy = tf.distribute.get_strategy()\n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y65we5OEmk9i","executionInfo":{"status":"ok","timestamp":1699899100630,"user_tz":-60,"elapsed":15048,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"9f6c2495-3529-4280-90e5-9104ff9a5a39"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU  grpc://10.87.22.170:8470\n","REPLICAS:  8\n"]}]},{"cell_type":"code","source":["# from google.colab import files\n","# import io\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","# drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qlq9f5tGmzRn","executionInfo":{"status":"ok","timestamp":1699899138076,"user_tz":-60,"elapsed":37457,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"e1eddf7b-d2a3-45f4-f8ee-c1be63951241"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["df_CoreCGT = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/CGTexpandedSMR_Data.csv', dtype='str', usecols=['TID', 'OrigTweet', 'InReplyTo'])\n","df_CoreGTr = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/GrounTruthBERT.csv', dtype='str', usecols=['TID', 'OrigTweet', 'InReplyTo'])\n","df_GTD_Rec = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/GTxM_Pass4/GTxM_Pass4_GTD_UpTodate.csv', dtype='str')\n"],"metadata":{"id":"HDE1yOAwqhNB","executionInfo":{"status":"ok","timestamp":1699899152311,"user_tz":-60,"elapsed":9078,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["df_Core = pd.concat([df_CoreGTr, df_CoreCGT], axis=0)\n","df_Core_Rec = df_Core[df_Core.InReplyTo.isna()]\n","df_Core_Sup = df_Core[df_Core.InReplyTo.notna()]"],"metadata":{"id":"Kbxr-YjEH1aZ","executionInfo":{"status":"ok","timestamp":1699899152545,"user_tz":-60,"elapsed":236,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["df_GTD_Rec.rename(columns={'RecID': 'TID'}, inplace=True)\n","df_Core_Rec = pd.merge(df_Core_Rec, df_GTD_Rec, on='TID')\n","\n","df_GTD_Rec.rename(columns={'TID': 'InReplyTo'}, inplace=True)\n","df_Core_Sup = pd.merge(df_Core_Sup, df_GTD_Rec, on='InReplyTo')\n","\n","df = pd.concat([df_Core_Rec, df_Core_Sup], axis=0)\n","df = df.sample(frac=1,axis=0,ignore_index=True)"],"metadata":{"id":"XbG8uXWUHzzK","executionInfo":{"status":"ok","timestamp":1699899152856,"user_tz":-60,"elapsed":315,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Remove unlabelled data\n","df = df[df.Target.notna()]\n","len(df)"],"metadata":{"id":"XhX1zrzReodt","executionInfo":{"status":"ok","timestamp":1699899153342,"user_tz":-60,"elapsed":493,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6474a5d-fe9b-401c-cc8a-973acc085e92"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["213998"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# check the label distribution\n","df_RecTweets = df[df.InReplyTo.isna()]\n","df_RecTweets.groupby(['Label','Target']).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBlzfzmoJcp1","executionInfo":{"status":"ok","timestamp":1699899153343,"user_tz":-60,"elapsed":18,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"f0172f74-14fc-4d6f-dac3-446dd3bc2b5d"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label           Target\n","Business        1          75\n","Entertainment   2         176\n","Environmental   3          55\n","Health          4          17\n","Human Rights    5         115\n","Law and Order   7          17\n","Obituary        9         148\n","Politics        6         608\n","Social Stories  10         59\n","Sports          11         84\n","dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Remove Label with low SMR counts and 'World Politics'\n","# df = df[df.Label != 'Social Stories']\n","df = df[df.Label != 'Law and Order']\n","# df = df[df.Label != 'Environmental']\n","df = df[df.Label != 'Health']\n","df = df[df.Label != 'World Politics']\n","len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9I4OmHOJWdD","executionInfo":{"status":"ok","timestamp":1699899153699,"user_tz":-60,"elapsed":367,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"d76782c6-e145-4d77-d365-30e0a277a612"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["208727"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# convert Target to int - essential for Pandas .loc\n","df['Target'] = df['Target'].astype(int)"],"metadata":{"id":"3vcGLs0xyuoC","executionInfo":{"status":"ok","timestamp":1699899153700,"user_tz":-60,"elapsed":10,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def remove1stMent(text):\n","  if text[0] == '@':\n","      words = text.split()\n","      words = words[1:] # remove the @mention word\n","      text = \" \".join(words).lstrip()\n","  return(text)\n","\n","def removeSpecialChar(text):\n","  #old text = re.sub(r'\\W', ' ', text) #replace ALL non-word characters, including emojis with space\n","  # remove all non ASCII characters\n","\n","  # credit: https://stackoverflow.com/questions/2758921/regular-expression-that-finds-and-replaces-non-ascii-characters-with-python\n","  text = re.sub(r\"[\\u0080-\\uFFFF]\", \" \", text) #see ASCII list: https://www.asciitable.com/\n","  text = \" \".join(text.split()) # replace multiple spaces with a single space\n","  return(text)\n","\n","def removeDigits(text):\n","  text = re.sub(r'\\d', ' ', text) #replace digits with space\n","  return(text)\n","\n","def cleanColloquials(text):\n","  #replace this strange chars in the text with space\n","  text = text.replace(\"GCO\",\" \")\n","  text = text.replace(\"GY=n+\",\" \")\n","  text = text.replace(\"GCY\",\" \")\n","  text = text.replace(\"fcafc+\",\" \")\n","  text = text.replace(\"fAE+\",\" \")\n","  text = text.replace(\"#fAE\",\" \")\n","  text = text.replace(\"fnae\",\" \")\n","  text = text.replace(\"fye\",\" \")\n","\n","  #Replace common abbreviations and slangs\n","  text = text.replace(\" i m \",\" i am \")\n","  text = text.replace(\" i ve \",\" i have \")\n","  text = text.replace(\" i ll \",\" i will \")\n","  text = text.replace(\" i d \",\" i had \")\n","  text = text.replace(\" that s \",\" that is \")\n","  text = text.replace(\" isn t \",\" is not \")\n","  text = text.replace(\" it s \",\" it is \")\n","  text = text.replace(\" she s \",\" she is \")\n","  text = text.replace(\" he s \",\" he is \")\n","  text = text.replace(\" u \",\" you \")\n","  text = text.replace(\" ur \",\" your \")\n","  text = text.replace(\" b4 \",\" before \")\n","  text = text.replace(\" wasnt \",\" was not \")\n","  text = text.replace(\" wasn t \",\" was not \")\n","  text = text.replace(\" cant \",\" can not \")\n","  text = text.replace(\" can t \",\" can not \")\n","  text = text.replace(\" couldnt \",\" could not \")\n","  text = text.replace(\" couldn t \",\" could not \")\n","  text = text.replace(\" wouldnt \",\" would not \")\n","  text = text.replace(\" wouldn t \",\" would not \")\n","  text = text.replace(\" dont \",\" do not \")\n","  text = text.replace(\" don t \",\" do not \")\n","  text = text.replace(\" didnt \",\" did not \")\n","  text = text.replace(\" didn t \",\" did not \")\n","  text = text.replace(\" let s \",\" let us \")\n","  text = text.replace(\" i'm \",\" i am \")\n","  text = text.replace(\" i've \",\" i have \")\n","  text = text.replace(\" i'll \",\" i will \")\n","  text = text.replace(\" i'd \",\" i had \")\n","  text = text.replace(\" that's \",\" that is \")\n","  text = text.replace(\" isn't \",\" is not \")\n","  text = text.replace(\" it's \",\" it is \")\n","  text = text.replace(\" she's \",\" she is \")\n","  text = text.replace(\" he's \",\" he is \")\n","  text = text.replace(\" u \",\" you \")\n","  text = text.replace(\" ur \",\" your \")\n","  text = text.replace(\" b4 \",\" before \")\n","  text = text.replace(\" wasn't \",\" was not \")\n","  text = text.replace(\" can't \",\" can not \")\n","  text = text.replace(\" couldn't \",\" could not \")\n","  text = text.replace(\" wouldn't \",\" would not \")\n","  text = text.replace(\" don't \",\" do not \")\n","  text = text.replace(\" didn't \",\" did not \")\n","  text = text.replace(\" let's \",\" let us \")\n","  text = text.replace(\" luv \",\" love \")\n","  text = text.replace(\" true \",\" truth \")\n","  text = text.replace(\" ppl \",\" people \")\n","  text = text.replace(\" fb \",\" facebook \")\n","  text = text.replace(\" b day \",\" birthday \")\n","  text = text.replace(\" bday \",\" birthday \")\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeHashtags(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='#', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeMentions(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='@', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeHttpWeb(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='&', words)\n","  words = filter(lambda x:x[0:4]!='http', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n"],"metadata":{"id":"40ElLojg4bl0","executionInfo":{"status":"ok","timestamp":1699899154544,"user_tz":-60,"elapsed":6,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# CLEANUP FACTORY\n","def cleanup(text):\n","  #Scenario1:\n","  text = removeSpecialChar(text)\n","  text = remove1stMent(text)\n","  text = removeHttpWeb(text)\n","  text = cleanColloquials(text)\n","\n","  #Scenario2: remove1stMent, removeHttpWeb, removeSpecialChar, cleanColloquials\n","  #Scenario3: remove1stMent, removeHttpWeb, removeHashtags, removeSpecialChar, cleanColloquials\n","  return(text)"],"metadata":{"id":"IGIXmrPlBnyr","executionInfo":{"status":"ok","timestamp":1699899155507,"user_tz":-60,"elapsed":6,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["#df['CleanTweet'] = df['OrigTweet'].apply(remove1stMentNoSpecChar)\n","#remove1stMentNoSpecChar('@MarkSZaidEsq @tko From the evidence and more to co')\n","df['CleanTweet'] = df['OrigTweet'].apply(cleanup)"],"metadata":{"id":"i8X6B0l0rxUA","executionInfo":{"status":"ok","timestamp":1699899169293,"user_tz":-60,"elapsed":12453,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# check the label distribution\n","df_RecTweets = df[df.InReplyTo.isna()]\n","df_RecTweets.groupby(['Label','Target']).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YyhtX056Pevs","executionInfo":{"status":"ok","timestamp":1699899169898,"user_tz":-60,"elapsed":293,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"64524555-ac21-421d-a0b3-f6d2f89ac692"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label           Target\n","Business        1          75\n","Entertainment   2         176\n","Environmental   3          55\n","Human Rights    5         115\n","Obituary        9         148\n","Politics        6         608\n","Social Stories  10         59\n","Sports          11         84\n","dtype: int64"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["print(f\"The dataset contains { df.Target.nunique() } unique categories\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9ROhaMftWNn","executionInfo":{"status":"ok","timestamp":1699899171851,"user_tz":-60,"elapsed":235,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"86e3d506-01b5-4ed1-cb6d-3baa3874a50d"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["The dataset contains 8 unique categories\n"]}]},{"cell_type":"code","source":["# convert the tweets into lower case if uncased model.\n","#df['CleanTweet'] = df['CleanTweet'].apply(lambda x: str(x).lower())\n","# trim to 280 characters max\n","df['CleanTweet'] = df['CleanTweet'].str.slice(0,279)\n","# calculating the length of tweet\n","df['CleanTweet_len'] = df['CleanTweet'].apply(lambda x: len(str(x).split()))\n","# Remove tweets with less than 10 words\n","df = df.query('CleanTweet_len > 9')\n","len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1WFEkq8McZk","executionInfo":{"status":"ok","timestamp":1699899174190,"user_tz":-60,"elapsed":637,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"869813af-c986-4e95-8ac5-0e775990e14a"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["172877"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# check that the RecTweets are still all in the dataset after the cleansing\n","df_RecTweets = df[df.InReplyTo.isna()]\n","df_RecTweets.groupby(['Label','Target']).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5voRycn6oCp","executionInfo":{"status":"ok","timestamp":1699899176532,"user_tz":-60,"elapsed":371,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"ca3655f2-d38d-4470-db06-3f0474c3bca7"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label           Target\n","Business        1          67\n","Entertainment   2         160\n","Environmental   3          49\n","Human Rights    5         111\n","Obituary        9         139\n","Politics        6         583\n","Social Stories  10         54\n","Sports          11         66\n","dtype: int64"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["#Serialize the Targets for the encoder\n","df.loc[(df.Target == 1), 'Target'] = 0 # Business\n","df.loc[(df.Target == 2), 'Target'] = 1 # Entertainment\n","df.loc[(df.Target == 3), 'Target'] = 2 # Environmental\n","df.loc[(df.Target == 5), 'Target'] = 3 # Human Rights\n","df.loc[(df.Target == 6), 'Target'] = 4 # Politics\n","df.loc[(df.Target == 9), 'Target'] = 5 # Obituary\n","df.loc[(df.Target == 10), 'Target'] = 6 # Social Stories\n","df.loc[(df.Target == 11), 'Target'] = 7 # Sports"],"metadata":{"id":"RK3Z7_9LKarP","executionInfo":{"status":"ok","timestamp":1699899178323,"user_tz":-60,"elapsed":268,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# set index to TID (used later in the Training/Test Series)\n","df.index = df['TID']\n","df.index.rename('gt_idx', inplace=True)\n","df.head(2)"],"metadata":{"id":"OYthw-qqtN5r","executionInfo":{"status":"ok","timestamp":1699899180272,"user_tz":-60,"elapsed":244,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"colab":{"base_uri":"https://localhost:8080/","height":178},"outputId":"e57114b1-a51d-4f64-86ea-8c49b0af7755"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                     TID  \\\n","gt_idx                                     \n","1216916305460310016  1216916305460310016   \n","1193896116489723912  1193896116489723912   \n","\n","                                                             OrigTweet  \\\n","gt_idx                                                                   \n","1216916305460310016  @KristenOrthman Yes and Sanders marched for ci...   \n","1193896116489723912  @peterdaou @SenSchumer schumer is a politician...   \n","\n","                               InReplyTo     Label  Target  \\\n","gt_idx                                                       \n","1216916305460310016  1216879913078329344  Politics       4   \n","1193896116489723912  1193891167362002946  Politics       4   \n","\n","                                                            CleanTweet  \\\n","gt_idx                                                                   \n","1216916305460310016  Yes and Sanders marched for civil rights and W...   \n","1193896116489723912  @SenSchumer schumer is a politician thru and t...   \n","\n","                     CleanTweet_len  \n","gt_idx                               \n","1216916305460310016              52  \n","1193896116489723912              13  "],"text/html":["\n","  <div id=\"df-d4cdce3c-c39d-41e0-9ef2-3867fd7cf8e5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TID</th>\n","      <th>OrigTweet</th>\n","      <th>InReplyTo</th>\n","      <th>Label</th>\n","      <th>Target</th>\n","      <th>CleanTweet</th>\n","      <th>CleanTweet_len</th>\n","    </tr>\n","    <tr>\n","      <th>gt_idx</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1216916305460310016</th>\n","      <td>1216916305460310016</td>\n","      <td>@KristenOrthman Yes and Sanders marched for ci...</td>\n","      <td>1216879913078329344</td>\n","      <td>Politics</td>\n","      <td>4</td>\n","      <td>Yes and Sanders marched for civil rights and W...</td>\n","      <td>52</td>\n","    </tr>\n","    <tr>\n","      <th>1193896116489723912</th>\n","      <td>1193896116489723912</td>\n","      <td>@peterdaou @SenSchumer schumer is a politician...</td>\n","      <td>1193891167362002946</td>\n","      <td>Politics</td>\n","      <td>4</td>\n","      <td>@SenSchumer schumer is a politician thru and t...</td>\n","      <td>13</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4cdce3c-c39d-41e0-9ef2-3867fd7cf8e5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d4cdce3c-c39d-41e0-9ef2-3867fd7cf8e5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d4cdce3c-c39d-41e0-9ef2-3867fd7cf8e5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c986af18-d890-4065-bd86-d0b1aacf9f38\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c986af18-d890-4065-bd86-d0b1aacf9f38')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c986af18-d890-4065-bd86-d0b1aacf9f38 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["#use T5 base cased pretrained tokenizer\n","tokenizer = transformers.AutoTokenizer.from_pretrained('t5-base',add_prefix_space=True, use_fast=False)"],"metadata":{"id":"PJfSoFfpuTVJ","executionInfo":{"status":"ok","timestamp":1699899183078,"user_tz":-60,"elapsed":1042,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"colab":{"base_uri":"https://localhost:8080/","height":205,"referenced_widgets":["789995de0bf949fdb8da63b0f203f1da","68575df1085841679c0dc257170eb3ab","ab5c7ac33e8d49aab26fa00e2af2bfe0","dcc65f3f187c4c6cb09d5ce61995c464","65e54e0ed1fb4d40aa5d5382369ea5e8","64149f9418b142589031a0efff3a4d8a","e1036f501fe74a72b8a7df2f90af3e97","aac9b5a8c86546b0a0aed012ced5be2f","2b85c9d7e98248ec9359e3080aa2ad37","eda81f36eaee49e1bfc2dd06847b6877","8a2d5948a4404ed79b755703dcfdb862","b9b8a92d0bd14a529df11e7121f55b10","b2216eb0776240d2b342435bf871bc9c","02597516739145d2bd66a027c45555dd","0aa9457e5662438aa6459d4d030b5b77","cd41e27cd21249ee8ef16af161341f4e","0d9c2c330a474292bb56cfb51d199a00","2080c0806b5848a7a9116fa50b1a4e2e","176ca0a0f29049bea3415af2a5efe550","fd0a950b943c4a7a8e520c597162b656","00f5599435964930b5007c445eb58daf","30959689eccf45f0a66e6c04b8235033"]},"outputId":"72c80b60-de3d-4ca5-82d7-4921934175d7"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["(…)face.co/t5-base/resolve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"789995de0bf949fdb8da63b0f203f1da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(…)ace.co/t5-base/resolve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9b8a92d0bd14a529df11e7121f55b10"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:164: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n","For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n","- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n","- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n","- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# NOTE: batch_encode_plus adds [CLS], [SEP] to the text\n","def regular_encode(texts, tokenizer, maxlen=512):\n","    enc_di = tokenizer.batch_encode_plus(\n","        texts,\n","        return_attention_mask=False,\n","        return_token_type_ids=False,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        padding='longest',\n","        return_tensors='tf',\n","        max_length=maxlen\n","    )\n","    return np.array(enc_di['input_ids'])"],"metadata":{"id":"SccLStPwuAnU","executionInfo":{"status":"ok","timestamp":1699899199740,"user_tz":-60,"elapsed":273,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# BUILD THE MODEL\n","no_of_classes = 8\n","# seed for environmental stability\n","# tf.random.set_seed(0)"],"metadata":{"id":"0leihuY3u0WB","executionInfo":{"status":"ok","timestamp":1699899201685,"user_tz":-60,"elapsed":231,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def build_model(transformer, loss='categorical_crossentropy', max_len=512):\n","    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    sequence_output = transformer(input_word_ids)[0]\n","    cls_token = sequence_output[:, 0, :]\n","    #adding dropout layer\n","    #x = tf.keras.layers.Dropout(0.3, seed=0)(cls_token)\n","    x = tf.keras.layers.Dropout(0.3, )(cls_token)\n","    #using a dense layer of 11 neurons as the number of unique categories is 11.\n","    #out = tf.keras.layers.Dense(11, activation='softmax')(x)\n","    out = tf.keras.layers.Dense(no_of_classes, activation='softmax')(x)\n","    model = tf.keras.Model(inputs=input_word_ids, outputs=out)\n","    #using categorical crossentropy as the loss as it is a multi-class classification problem\n","    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss=loss, metrics=['accuracy'])\n","    return model"],"metadata":{"id":"ZzmqJPxLu41m","executionInfo":{"status":"ok","timestamp":1699899202844,"user_tz":-60,"elapsed":5,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["#building the model on tpu\n","with strategy.scope():\n","    transformer_layer = transformers.TFT5EncoderModel.from_pretrained('t5-base')\n","    model = build_model(transformer_layer, max_len=99)\n","model.summary()\n","# Save the initial Neural Net weights (to use for resetting the model in between cross validation runs)\n","init_weights = model.get_weights()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607,"referenced_widgets":["951f7daef9d04202916edfcaee08d106","711c4cf517874539a3252ba63f79ec20","042cba347d8d4870b235e75fd4ac1c03","54a7dccaf126424d8158a84f5a0bbc5c","e01a843d1a5147fa836f3c7c7a8ff124","cc41198d663e47b19cb4dae18ee6a7ec","2d0596d07de44edf8e4ca15201a490f6","e7651c3f979d445d84b24bf90f49d980","63aec517f49c4230aa023cc165451ce8","cae3cd58cb18425397af319c13e5a76c","eae266ee60094f68b94f8e29b9bf30d1"]},"id":"aQm4LSYbz6KD","outputId":"ab50ca07-2937-49ef-abd9-cde1ee50ea7f","executionInfo":{"status":"ok","timestamp":1699899313837,"user_tz":-60,"elapsed":109134,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["tf_model.h5:   0%|          | 0.00/892M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"951f7daef9d04202916edfcaee08d106"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at t5-base were not used when initializing TFT5EncoderModel: ['decoder']\n","- This IS expected if you are initializing TFT5EncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFT5EncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFT5EncoderModel were initialized from the model checkpoint at t5-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5EncoderModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_word_ids (InputLayer)  [(None, 99)]             0         \n","                                                                 \n"," tft5_encoder_model (TFT5Enc  TFBaseModelOutput(last_h  109628544\n"," oderModel)                  idden_state=(None, 99, 7            \n","                             68),                                \n","                              hidden_states=None, att            \n","                             entions=None)                       \n","                                                                 \n"," tf.__operators__.getitem (S  (None, 768)              0         \n"," licingOpLambda)                                                 \n","                                                                 \n"," dropout_49 (Dropout)        (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 8)                 6152      \n","                                                                 \n","=================================================================\n","Total params: 109,634,696\n","Trainable params: 109,634,696\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})"],"metadata":{"id":"ZdyIR0kbRPgS","executionInfo":{"status":"ok","timestamp":1699899320340,"user_tz":-60,"elapsed":257,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["#X_train,X_test ,y_train,y_test = train_test_split(df['CleanTweet'], df['Target'], random_state = 1, stratify=df['Target'], test_size = 0.2)\n","X_train = df['CleanTweet']\n","y_train = df['Target']"],"metadata":{"id":"18ZS-jzjuO5U","executionInfo":{"status":"ok","timestamp":1699899322082,"user_tz":-60,"elapsed":251,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# KO 12Nov23\n","passID = 'Pass4'\n","DL_algo = 'T5_CV_2ndRun'\n","runID = dt.today().strftime('%Y%m%d%H%M')"],"metadata":{"id":"FIL1O76SDqDO","executionInfo":{"status":"ok","timestamp":1699899324248,"user_tz":-60,"elapsed":333,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["runID = dt.today().strftime('%Y%m%d%H%M')\n","# 5-Fold Cross Validation\n","kf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n","# kf = StratifiedKFold(n_splits=5)\n","# kf = StratifiedKFold(n_splits=2, random_state=0, shuffle=True)\n","k=1\n","df_tr_hist = pd.DataFrame(columns=['RunID','PassID','Model','Loss','Accuracy'])\n","df_val_result = pd.DataFrame(columns=['ValID','ValType','Model','Accuracy','Precision','Recall','F1'])\n","for tr_idx, val_idx in kf.split(X_train, y_train):\n","  print(f\"\\nTraining for Cross Val: {k} \")\n","  print(f\"Indexes for tr {tr_idx} and val {val_idx}\")\n","  X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n","  y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n","  print(\"Encoding y_tr and y_val...\")\n","  ytr_encoded = tf.keras.utils.to_categorical(y_tr, num_classes=no_of_classes,dtype = 'int32')\n","  yval_encoded = tf.keras.utils.to_categorical(y_val, num_classes=no_of_classes,dtype = 'int32')\n","  print(\"Encoding X_tr and X_val...\")\n","  Xtr_encoded = regular_encode(X_tr.astype('str'), tokenizer, maxlen=99)\n","  Xval_encoded = regular_encode(X_val.astype('str'), tokenizer, maxlen=99)\n","  print(f\"Shapes for X_tr {Xtr_encoded.shape}, y_tr {ytr_encoded.shape}, X_val {Xval_encoded.shape} and y_val {yval_encoded.shape}\")\n","\n","  print(\"creating the tr and val datasets...\")\n","  BATCH_SIZE = 32*strategy.num_replicas_in_sync\n","  AUTO = tf.data.experimental.AUTOTUNE\n","  train_dataset = tf.data.Dataset.from_tensor_slices((Xtr_encoded, ytr_encoded))\n","  test_dataset = tf.data.Dataset.from_tensor_slices(Xval_encoded)\n","\n","  epochs_no = 10\n","  #creating the training and testing dataset.\n","  train_dataset = (\n","      tf.data.Dataset\n","      .from_tensor_slices((Xtr_encoded, ytr_encoded))\n","      .repeat()\n","      .shuffle(2048)\n","      .batch(BATCH_SIZE)\n","      .prefetch(AUTO)\n","  )\n","  test_dataset = (\n","      tf.data.Dataset\n","      .from_tensor_slices(Xval_encoded)\n","      .batch(BATCH_SIZE)\n","  )\n","\n","  #training for the epochs\n","  n_steps = Xtr_encoded.shape[0] // BATCH_SIZE\n","  train_history = model.fit(\n","      train_dataset,\n","      steps_per_epoch=n_steps,\n","      epochs=epochs_no\n","  )\n","\n","  #store the training history log\n","  df_tr_hist.loc[len(df_tr_hist)] = [runID, passID, DL_algo, train_history.history['loss'], train_history.history['accuracy']]\n","\n","  #Making predictions for val\n","  preds = model.predict(test_dataset,verbose = 1)\n","  pred_classes = np.argmax(preds, axis = 1)\n","\n","  #Mapping the encoded output to actual categories...\n","  # write result for decomposed SMR\n","  actual_category = np.argmax(yval_encoded, axis = 1)\n","  acc = sklearn.metrics.accuracy_score(actual_category,pred_classes)\n","  print(\"Generating decomposed SMR performance metrics ...\" )\n","  de_prec = precision_score(actual_category,pred_classes, average = 'weighted')\n","  de_recall = recall_score(actual_category,pred_classes, average = 'weighted')\n","  de_f1 = f1_score(actual_category,pred_classes, average = 'weighted')\n","\n","  print(f\"Decomposed SMR Acc: {acc*100}, Prec: {de_prec*100}, Recall: {de_recall*100}, F1 {de_f1*100}\")\n","  df_val_result.loc[len(df_val_result)] = [k, 'Decomposed', 'XLNet', acc*100, de_prec*100, de_recall*100, de_f1*100]\n","\n","  # p_r_f1 = precision_recall_fscore_support(actual_category, pred_classes, average = 'weighted')\n","  # print(f\"Decomposed SMR Acc: {acc*100}, Prec: {p_r_f1[0]*100}, Recall: {p_r_f1[1]*100}, F1 {p_r_f1[2]*100}\")\n","  # df_val_result.loc[len(df_val_result)] = [k, 'Decomposed', 'XLNet', acc*100, p_r_f1[0]*100, p_r_f1[1]*100, p_r_f1[2]*100]\n","\n","  print(\"Generating recomposed SMR accuracy...\")\n","  list_X_val_idx = X_val.index.tolist()\n","  result_df = pd.DataFrame({'idx':list_X_val_idx, 'actual_category':actual_category, 'predicted_category':pred_classes})\n","  df_sup_result = result_df.merge(df, left_on='idx', right_on='TID')\n","  df_sup_agg_result = df_sup_result.groupby(['InReplyTo','predicted_category']).size().reset_index(name='counts').sort_values(['InReplyTo','counts'], ascending=[True,False])\n","  df_rec = df[df.InReplyTo.isna()]\n","\n","  # Recompose the SMR based on the count of aggregated supporting tweet predictions\n","  df_rec_result = pd.DataFrame(columns=['TID','Actual','Predicted'])\n","  for i in range(0,len(df_rec)):\n","    rec_TID = df_rec.iloc[i]['TID']\n","    rec_cat = int(df_rec.iloc[i]['Target'])\n","    df_temp = df_sup_agg_result[df_sup_agg_result.InReplyTo == rec_TID].sort_values('counts',ascending=False)\n","    if len(df_temp) > 0:\n","      rec_pred = int(np.squeeze(df_temp[:1]['predicted_category'].values)) # np.squeeze to resolve the Conversion of an array with ndim > 0 to a scalar is deprecated error warning\n","      df_rec_result.loc[len(df_rec_result)] = [rec_TID,rec_cat,rec_pred]\n","\n","  # write result for recomposed SMR\n","  rec_actual = df_rec_result['Actual'].to_numpy().astype(int)\n","  rec_pred = df_rec_result['Predicted'].to_numpy().astype(int)\n","  rec_acc = sklearn.metrics.accuracy_score(rec_actual, rec_pred)\n","  rec_prec = precision_score(rec_actual, rec_pred, average = 'weighted')\n","  rec_recall = recall_score(rec_actual, rec_pred, average = 'weighted')\n","  rec_f1 = f1_score(rec_actual, rec_pred, average = 'weighted')\n","\n","  print(f\"Recomposed SMR Acc: {rec_acc*100}, Prec: {rec_prec*100}, Recall: {rec_recall*100}, F1 {rec_f1*100}\")\n","  df_val_result.loc[len(df_val_result)] = [k, 'Recomposed', 'XLNet', rec_acc*100, rec_prec*100, rec_recall*100, rec_f1*100]\n","\n","  # print(f\"Recomposed SMR Acc: {rec_acc*100}, Prec: {rec_p_r_f1[0]*100}, Recall: {rec_p_r_f1[1]*100}, F1 {rec_p_r_f1[2]*100}\")\n","  # df_val_result.loc[len(df_val_result)] = [k, 'Recomposed', 'XLNet', rec_acc*100, rec_p_r_f1[0]*100, rec_p_r_f1[1]*100, rec_p_r_f1[2]*100]\n","\n","  # Generate confusion matrix\n","  rec_cm = confusion_matrix(rec_actual, rec_pred)\n","  df_rec_cm = pd.DataFrame(rec_cm)\n","  df_rec_cm.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_CM_\" + str(k) + \" \" + runID +\".csv\")\n","\n","  #KO 12Nov23\n","  # Save the verbose actual and pred for each SMR, for each CV run\n","  df_rec_result.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_CV_\"  + str(k) + \"_rec_result_\" + runID +\".csv\")\n","\n","  # Reset the model by restoring the initital model weights to prevent overtraining\n","  model.set_weights(init_weights)\n","  k=k+1\n","\n","# Save the training history result\n","# df_tr_hist.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/XLNet_GTr_TrainHist_\" + runID +\".csv\")\n","\n","# Save the cross validation result\n","df_val_result = df_val_result.round(decimals=2)\n","df_val_result.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_CV_\" + runID +\".csv\")\n","\n","# Save RunID,Model,Accuracy,Precision,Recall,F1 for the Recomposed SMR\n","df_re_val_result = df_val_result[df_val_result.ValType=='Recomposed']\n","no_of_runs = len(df_re_val_result)\n","df_GTxM_Clf_CV_results = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_Clf_CV_results.csv\")\n","avg_Accuracy = np.sum(df_re_val_result['Accuracy']) / no_of_runs\n","avg_Precision = np.sum(df_re_val_result['Precision']) / no_of_runs\n","avg_Recall = np.sum(df_re_val_result['Recall']) / no_of_runs\n","avg_F1 = np.sum(df_re_val_result['F1']) / no_of_runs\n","\n","#KO 12Nov23\n","df_GTxM_Clf_CV_results.loc[len(df_GTxM_Clf_CV_results)] = [runID, passID+\" \"+DL_algo, avg_Accuracy, avg_Precision, avg_Recall, avg_F1]\n","df_GTxM_Clf_CV_results.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_Clf_CV_results.csv\", index=False)"],"metadata":{"id":"dkzVZhP3vEQ-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699904768762,"user_tz":-60,"elapsed":5371771,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"abd60fb4-584e-4b88-f77c-1ca91204b6b1"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training for Cross Val: 1 \n","Indexes for tr [     0      1      3 ... 172873 172874 172876] and val [     2     15     17 ... 172861 172870 172875]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (138301, 99), y_tr (138301, 8), X_val (34576, 99) and y_val (34576, 8)\n","creating the tr and val datasets...\n","Epoch 1/10\n","540/540 [==============================] - 156s 176ms/step - loss: 1.3566 - accuracy: 0.5654\n","Epoch 2/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.9461 - accuracy: 0.7036\n","Epoch 3/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.7523 - accuracy: 0.7682\n","Epoch 4/10\n","540/540 [==============================] - 96s 177ms/step - loss: 0.6577 - accuracy: 0.7990\n","Epoch 5/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.6049 - accuracy: 0.8136\n","Epoch 6/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5668 - accuracy: 0.8258\n","Epoch 7/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5373 - accuracy: 0.8343\n","Epoch 8/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5096 - accuracy: 0.8430\n","Epoch 9/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.4866 - accuracy: 0.8484\n","Epoch 10/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.4650 - accuracy: 0.8553\n","136/136 [==============================] - 22s 132ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 84.65409532623785, Prec: 84.43962674255275, Recall: 84.65409532623785, F1 84.45454211681204\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 89.9581589958159, Prec: 89.89380478464656, Recall: 89.9581589958159, F1 89.66172699055703\n","\n","Training for Cross Val: 2 \n","Indexes for tr [     2      4      5 ... 172874 172875 172876] and val [     0      1      3 ... 172849 172863 172866]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (138301, 99), y_tr (138301, 8), X_val (34576, 99) and y_val (34576, 8)\n","creating the tr and val datasets...\n","Epoch 1/10\n","540/540 [==============================] - 95s 176ms/step - loss: 1.4145 - accuracy: 0.5536\n","Epoch 2/10\n","540/540 [==============================] - 95s 176ms/step - loss: 1.0203 - accuracy: 0.6745\n","Epoch 3/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.8081 - accuracy: 0.7513\n","Epoch 4/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.6878 - accuracy: 0.7902\n","Epoch 5/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.6288 - accuracy: 0.8075\n","Epoch 6/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5851 - accuracy: 0.8207\n","Epoch 7/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5533 - accuracy: 0.8291\n","Epoch 8/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5276 - accuracy: 0.8372\n","Epoch 9/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5010 - accuracy: 0.8445\n","Epoch 10/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.4815 - accuracy: 0.8507\n","136/136 [==============================] - 11s 68ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 84.66566404442388, Prec: 84.34119211535983, Recall: 84.66566404442388, F1 84.40029091668404\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 90.59613769941225, Prec: 90.62278623318886, Recall: 90.59613769941225, F1 90.29846756883066\n","\n","Training for Cross Val: 3 \n","Indexes for tr [     0      1      2 ... 172874 172875 172876] and val [     5      8     13 ... 172868 172869 172871]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (138302, 99), y_tr (138302, 8), X_val (34575, 99) and y_val (34575, 8)\n","creating the tr and val datasets...\n","Epoch 1/10\n","540/540 [==============================] - 95s 176ms/step - loss: 1.4214 - accuracy: 0.5510\n","Epoch 2/10\n","540/540 [==============================] - 95s 176ms/step - loss: 1.0230 - accuracy: 0.6740\n","Epoch 3/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.8047 - accuracy: 0.7518\n","Epoch 4/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.6846 - accuracy: 0.7913\n","Epoch 5/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.6210 - accuracy: 0.8098\n","Epoch 6/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5799 - accuracy: 0.8219\n","Epoch 7/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5440 - accuracy: 0.8317\n","Epoch 8/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5165 - accuracy: 0.8408\n","Epoch 9/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.4918 - accuracy: 0.8472\n","Epoch 10/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.4675 - accuracy: 0.8546\n","136/136 [==============================] - 10s 68ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 84.38467100506146, Prec: 84.02268837650453, Recall: 84.38467100506146, F1 84.13072633096543\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 89.89048020219039, Prec: 89.79877721874303, Recall: 89.89048020219039, F1 89.60512142321487\n","\n","Training for Cross Val: 4 \n","Indexes for tr [     0      1      2 ... 172872 172873 172875] and val [    11     12     14 ... 172852 172874 172876]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (138302, 99), y_tr (138302, 8), X_val (34575, 99) and y_val (34575, 8)\n","creating the tr and val datasets...\n","Epoch 1/10\n","540/540 [==============================] - 95s 176ms/step - loss: 1.4059 - accuracy: 0.5559\n","Epoch 2/10\n","540/540 [==============================] - 95s 176ms/step - loss: 1.0123 - accuracy: 0.6776\n","Epoch 3/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.8057 - accuracy: 0.7533\n","Epoch 4/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.6847 - accuracy: 0.7913\n","Epoch 5/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.6239 - accuracy: 0.8093\n","Epoch 6/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5818 - accuracy: 0.8214\n","Epoch 7/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5475 - accuracy: 0.8314\n","Epoch 8/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5199 - accuracy: 0.8397\n","Epoch 9/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.4940 - accuracy: 0.8479\n","Epoch 10/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.4722 - accuracy: 0.8537\n","136/136 [==============================] - 10s 68ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 84.75198843094721, Prec: 84.50771720744748, Recall: 84.75198843094721, F1 84.57228233431228\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 90.17485428809326, Prec: 90.27642036445494, Recall: 90.17485428809326, F1 89.91826830488469\n","\n","Training for Cross Val: 5 \n","Indexes for tr [     0      1      2 ... 172874 172875 172876] and val [     4      6      7 ... 172864 172872 172873]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (138302, 99), y_tr (138302, 8), X_val (34575, 99) and y_val (34575, 8)\n","creating the tr and val datasets...\n","Epoch 1/10\n","540/540 [==============================] - 95s 176ms/step - loss: 1.4023 - accuracy: 0.5552\n","Epoch 2/10\n","540/540 [==============================] - 95s 176ms/step - loss: 1.0156 - accuracy: 0.6771\n","Epoch 3/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.8106 - accuracy: 0.7505\n","Epoch 4/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.6851 - accuracy: 0.7908\n","Epoch 5/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.6236 - accuracy: 0.8083\n","Epoch 6/10\n","540/540 [==============================] - 95s 175ms/step - loss: 0.5811 - accuracy: 0.8213\n","Epoch 7/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5468 - accuracy: 0.8313\n","Epoch 8/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.5184 - accuracy: 0.8395\n","Epoch 9/10\n","540/540 [==============================] - 95s 176ms/step - loss: 0.4928 - accuracy: 0.8466\n","Epoch 10/10\n","540/540 [==============================] - 96s 177ms/step - loss: 0.4685 - accuracy: 0.8549\n","136/136 [==============================] - 10s 67ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 84.93420101229212, Prec: 84.57763267638255, Recall: 84.93420101229212, F1 84.6050174342765\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 91.87604690117253, Prec: 92.0097318565924, Recall: 91.87604690117253, F1 91.56226199587225\n"]}]},{"cell_type":"code","source":["# df_rec_result.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_last_CV_rec_result_\" + runID +\".csv\")"],"metadata":{"id":"MAPsj_yfCRbP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model.save(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/SavedModels/XLNet_Model_\" + runID +\".h5\")"],"metadata":{"id":"qt-SWSSaMCrc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RUfeKrImmHuI"},"execution_count":null,"outputs":[]}]}