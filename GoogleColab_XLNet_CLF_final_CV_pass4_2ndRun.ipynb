{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xIYU2pqMn3WbMEzfs5GsEWo8iUH8MeDD","timestamp":1644609098344},{"file_id":"13aLb_dvWhy8cgjtkUsY63FFz9Nrj39vE","timestamp":1641762890771},{"file_id":"1HMNUAtNAj9VQIwM4AEdpsBH9rjTii3Yg","timestamp":1641749303952}],"mount_file_id":"1HMNUAtNAj9VQIwM4AEdpsBH9rjTii3Yg","authorship_tag":"ABX9TyP6Y99oGAfKA0v/EqWrNvSu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"defe0dc3f81f44079cb83f174ab92933":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f7ed67e2add46c6bd07455b11c17479","IPY_MODEL_e61f841c849543c29670342810dcf871","IPY_MODEL_52b675663ac249d68c4941fc33955e95"],"layout":"IPY_MODEL_96a4043214d342aab2e526170e3ad1bc"}},"5f7ed67e2add46c6bd07455b11c17479":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9efc60aea09143ce8fc3d38105a71fd6","placeholder":"​","style":"IPY_MODEL_6ed4dc68f8fa44ac9f637ba5f2225eb2","value":"(…)net-base-cased/resolve/main/spiece.model: 100%"}},"e61f841c849543c29670342810dcf871":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_704f61975a5f466e87a2c7ac12197aa9","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_904b298e58a149b8b9d78cc0f23eafb0","value":798011}},"52b675663ac249d68c4941fc33955e95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c25110fd46d49b693dec97d230d8252","placeholder":"​","style":"IPY_MODEL_869ea5ff5dcf408aa9b7c7a0bef93a0c","value":" 798k/798k [00:00&lt;00:00, 11.4MB/s]"}},"96a4043214d342aab2e526170e3ad1bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9efc60aea09143ce8fc3d38105a71fd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ed4dc68f8fa44ac9f637ba5f2225eb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"704f61975a5f466e87a2c7ac12197aa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"904b298e58a149b8b9d78cc0f23eafb0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c25110fd46d49b693dec97d230d8252":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869ea5ff5dcf408aa9b7c7a0bef93a0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc6c804d39bc4e1ca9e6dff3def8dedc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6da4cfe6e480426d9b06ed23183c9a77","IPY_MODEL_7230944f9cf740e7b5bd38df19caa9b1","IPY_MODEL_e6bd47551d254f6ea4d2ca5bec6c47e3"],"layout":"IPY_MODEL_bcd4770a2e26486fae47670c2d02d4ff"}},"6da4cfe6e480426d9b06ed23183c9a77":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_252b2f272e17413da9ed5307c5659255","placeholder":"​","style":"IPY_MODEL_8be9c279453443a3a3a0735087d0a186","value":"(…)lnet-base-cased/resolve/main/config.json: 100%"}},"7230944f9cf740e7b5bd38df19caa9b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c709121824cf4257a60ec39348a12442","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7d5b6db09c64f83a0ac2bb629fb4f0d","value":760}},"e6bd47551d254f6ea4d2ca5bec6c47e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6287b0cda1a842ab8eaabe3b5c642c22","placeholder":"​","style":"IPY_MODEL_1352b5e828544341b0790e2210cbbead","value":" 760/760 [00:00&lt;00:00, 41.9kB/s]"}},"bcd4770a2e26486fae47670c2d02d4ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"252b2f272e17413da9ed5307c5659255":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8be9c279453443a3a3a0735087d0a186":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c709121824cf4257a60ec39348a12442":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7d5b6db09c64f83a0ac2bb629fb4f0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6287b0cda1a842ab8eaabe3b5c642c22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1352b5e828544341b0790e2210cbbead":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39a520a23f45439dae02d008f0fb06f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a22d1844c39e431ca9c475fc4a2ceda3","IPY_MODEL_5abecde0467441fa9673b12eddb92d0e","IPY_MODEL_a5e1834b33744bd7a5498b2602bd1cc0"],"layout":"IPY_MODEL_eddd1c95fa53420a95959dc88fb13c1b"}},"a22d1844c39e431ca9c475fc4a2ceda3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e4f070abe3c47fd94ed700f419f0878","placeholder":"​","style":"IPY_MODEL_129cd2dd94e543d591322d434b40d922","value":"tf_model.h5: 100%"}},"5abecde0467441fa9673b12eddb92d0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fb6d0234041416c82b8d2305e09b9dd","max":565485600,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b29854a8ede48759da647f850117ecb","value":565485600}},"a5e1834b33744bd7a5498b2602bd1cc0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df32f0263a174e1da83507b8d01d89b1","placeholder":"​","style":"IPY_MODEL_2920a0c0f4744022bebd76ac000a66e6","value":" 565M/565M [00:07&lt;00:00, 134MB/s]"}},"eddd1c95fa53420a95959dc88fb13c1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e4f070abe3c47fd94ed700f419f0878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"129cd2dd94e543d591322d434b40d922":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fb6d0234041416c82b8d2305e09b9dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b29854a8ede48759da647f850117ecb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df32f0263a174e1da83507b8d01d89b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2920a0c0f4744022bebd76ac000a66e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# 2nd Run: to capture the detailed prediction per SMR for each of 5-Fold CV runs (1st run only saved for the last CV run)"],"metadata":{"id":"Ghb2R47PrrAt","executionInfo":{"status":"ok","timestamp":1699812012306,"user_tz":-60,"elapsed":13,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Credit: https://www.kaggle.com/code/harshpraharaj98/text-classification-using-bert-and-xlnet/notebook\n","# CV credit: https://www.kaggle.com/code/ravi02516/bert-training-5-fold-cross-validation"],"metadata":{"id":"RqCazhwjuXKV","executionInfo":{"status":"ok","timestamp":1699812016569,"user_tz":-60,"elapsed":292,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip uninstall -y transformers\n","!pip uninstall -y keras\n","!pip uninstall -y tensorflow\n","!pip install --upgrade keras==2.10.0\n","!pip install --upgrade tensorflow==2.10.0\n","!pip install --upgrade transformers==4.22.2\n","# !pip install --upgrade keras==2.6.0\n","# !pip install --upgrade tensorflow==2.6.0\n","# !pip install --upgrade transformers==4.16.2\n","!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DUrpgdtvmgY0","executionInfo":{"status":"ok","timestamp":1699812166761,"user_tz":-60,"elapsed":146674,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"9ddeb86a-578a-4a43-c6c2-7a006fbc1176"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: keras 2.12.0\n","Uninstalling keras-2.12.0:\n","  Successfully uninstalled keras-2.12.0\n","Found existing installation: tensorflow 2.12.0\n","Uninstalling tensorflow-2.12.0:\n","  Successfully uninstalled tensorflow-2.12.0\n","Collecting keras==2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras\n","Successfully installed keras-2.10.0\n","Collecting tensorflow==2.10.0\n","  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m891.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.59.2)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.9.0)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n","Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.0)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (16.0.6)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.2)\n","Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.0)\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n","Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.0)\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.34.0)\n","Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.0)\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.14.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.41.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.5.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.31.0)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n","Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, tensorboard, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.2\n","    Uninstalling tensorboard-data-server-0.7.2:\n","      Successfully uninstalled tensorboard-data-server-0.7.2\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.0\n","    Uninstalling tensorboard-2.12.0:\n","      Successfully uninstalled tensorboard-2.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","orbax-checkpoint 0.4.2 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\n","tensorflow-datasets 4.9.3 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.22.2\n","  Downloading transformers-4.22.2-py3-none-any.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (3.13.1)\n","Collecting huggingface-hub<1.0,>=0.9.0 (from transformers==4.22.2)\n","  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.22.2)\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.22.2) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.2) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers==4.22.2) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.22.2) (2023.7.22)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.19.0 tokenizers-0.12.1 transformers-4.22.2\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"05KBKr1FmWlU","executionInfo":{"status":"ok","timestamp":1699812174641,"user_tz":-60,"elapsed":7637,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","import transformers #huggingface transformers library\n","from transformers import TFAutoModel, AutoTokenizer\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import sklearn\n","from sklearn.metrics import confusion_matrix\n","\n","import re\n","from datetime import datetime as dt\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score"]},{"cell_type":"code","source":["# Detect hardware, return appropriate distribution strategy\n","try:\n","    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","    # set: this is always the case on Kaggle.\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    #strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","    strategy = tf.distribute.get_strategy()\n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y65we5OEmk9i","executionInfo":{"status":"ok","timestamp":1699812202144,"user_tz":-60,"elapsed":27511,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"4eb72217-c74d-40e0-f42d-adcbab8b6135"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU  grpc://10.88.13.18:8470\n","REPLICAS:  8\n"]}]},{"cell_type":"code","source":["# from google.colab import files\n","# import io\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","# drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qlq9f5tGmzRn","executionInfo":{"status":"ok","timestamp":1699812222854,"user_tz":-60,"elapsed":20723,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"ad74e607-4249-46e3-ca6d-1369573fb88a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["df_CoreCGT = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/CGTexpandedSMR_Data.csv', dtype='str', usecols=['TID', 'OrigTweet', 'InReplyTo'])\n","df_CoreGTr = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/GrounTruthBERT.csv', dtype='str', usecols=['TID', 'OrigTweet', 'InReplyTo'])\n","df_GTD_Rec = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/GTxM_Pass4/GTxM_Pass4_GTD_UpTodate.csv', dtype='str')\n"],"metadata":{"id":"HDE1yOAwqhNB","executionInfo":{"status":"ok","timestamp":1699812363266,"user_tz":-60,"elapsed":6981,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["df_Core = pd.concat([df_CoreGTr, df_CoreCGT], axis=0)\n","df_Core_Rec = df_Core[df_Core.InReplyTo.isna()]\n","df_Core_Sup = df_Core[df_Core.InReplyTo.notna()]"],"metadata":{"id":"Kbxr-YjEH1aZ","executionInfo":{"status":"ok","timestamp":1699812367532,"user_tz":-60,"elapsed":261,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["df_GTD_Rec.rename(columns={'RecID': 'TID'}, inplace=True)\n","df_Core_Rec = pd.merge(df_Core_Rec, df_GTD_Rec, on='TID')\n","\n","df_GTD_Rec.rename(columns={'TID': 'InReplyTo'}, inplace=True)\n","df_Core_Sup = pd.merge(df_Core_Sup, df_GTD_Rec, on='InReplyTo')\n","\n","df = pd.concat([df_Core_Rec, df_Core_Sup], axis=0)\n","df = df.sample(frac=1,axis=0,ignore_index=True)"],"metadata":{"id":"XbG8uXWUHzzK","executionInfo":{"status":"ok","timestamp":1699812369453,"user_tz":-60,"elapsed":273,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Remove unlabelled data\n","df = df[df.Target.notna()]\n","len(df)"],"metadata":{"id":"XhX1zrzReodt","executionInfo":{"status":"ok","timestamp":1699812372475,"user_tz":-60,"elapsed":252,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f483489-92af-4c86-db9b-d6e2bd8e749a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["213998"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# check the label distribution\n","df_RecTweets = df[df.InReplyTo.isna()]\n","df_RecTweets.groupby(['Label','Target']).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBlzfzmoJcp1","executionInfo":{"status":"ok","timestamp":1699812373663,"user_tz":-60,"elapsed":7,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"3727ee67-c4ce-45da-d00a-1915871f1006"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label           Target\n","Business        1          75\n","Entertainment   2         176\n","Environmental   3          55\n","Health          4          17\n","Human Rights    5         115\n","Law and Order   7          17\n","Obituary        9         148\n","Politics        6         608\n","Social Stories  10         59\n","Sports          11         84\n","dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Remove Label with low SMR counts and 'World Politics'\n","# df = df[df.Label != 'Social Stories']\n","df = df[df.Label != 'Law and Order']\n","# df = df[df.Label != 'Environmental']\n","df = df[df.Label != 'Health']\n","df = df[df.Label != 'World Politics']\n","len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9I4OmHOJWdD","executionInfo":{"status":"ok","timestamp":1699812378230,"user_tz":-60,"elapsed":250,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"26827099-13ab-49d7-f318-c9613c490be9"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["208727"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# convert Target to int - essential for Pandas .loc\n","df['Target'] = df['Target'].astype(int)"],"metadata":{"id":"3vcGLs0xyuoC","executionInfo":{"status":"ok","timestamp":1699812379845,"user_tz":-60,"elapsed":5,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def remove1stMent(text):\n","  if text[0] == '@':\n","      words = text.split()\n","      words = words[1:] # remove the @mention word\n","      text = \" \".join(words).lstrip()\n","  return(text)\n","\n","def removeSpecialChar(text):\n","  #old text = re.sub(r'\\W', ' ', text) #replace ALL non-word characters, including emojis with space\n","  # remove all non ASCII characters\n","\n","  # credit: https://stackoverflow.com/questions/2758921/regular-expression-that-finds-and-replaces-non-ascii-characters-with-python\n","  text = re.sub(r\"[\\u0080-\\uFFFF]\", \" \", text) #see ASCII list: https://www.asciitable.com/\n","  text = \" \".join(text.split()) # replace multiple spaces with a single space\n","  return(text)\n","\n","def removeDigits(text):\n","  text = re.sub(r'\\d', ' ', text) #replace digits with space\n","  return(text)\n","\n","def cleanColloquials(text):\n","  #replace this strange chars in the text with space\n","  text = text.replace(\"GCO\",\" \")\n","  text = text.replace(\"GY=n+\",\" \")\n","  text = text.replace(\"GCY\",\" \")\n","  text = text.replace(\"fcafc+\",\" \")\n","  text = text.replace(\"fAE+\",\" \")\n","  text = text.replace(\"#fAE\",\" \")\n","  text = text.replace(\"fnae\",\" \")\n","  text = text.replace(\"fye\",\" \")\n","\n","  #Replace common abbreviations and slangs\n","  text = text.replace(\" i m \",\" i am \")\n","  text = text.replace(\" i ve \",\" i have \")\n","  text = text.replace(\" i ll \",\" i will \")\n","  text = text.replace(\" i d \",\" i had \")\n","  text = text.replace(\" that s \",\" that is \")\n","  text = text.replace(\" isn t \",\" is not \")\n","  text = text.replace(\" it s \",\" it is \")\n","  text = text.replace(\" she s \",\" she is \")\n","  text = text.replace(\" he s \",\" he is \")\n","  text = text.replace(\" u \",\" you \")\n","  text = text.replace(\" ur \",\" your \")\n","  text = text.replace(\" b4 \",\" before \")\n","  text = text.replace(\" wasnt \",\" was not \")\n","  text = text.replace(\" wasn t \",\" was not \")\n","  text = text.replace(\" cant \",\" can not \")\n","  text = text.replace(\" can t \",\" can not \")\n","  text = text.replace(\" couldnt \",\" could not \")\n","  text = text.replace(\" couldn t \",\" could not \")\n","  text = text.replace(\" wouldnt \",\" would not \")\n","  text = text.replace(\" wouldn t \",\" would not \")\n","  text = text.replace(\" dont \",\" do not \")\n","  text = text.replace(\" don t \",\" do not \")\n","  text = text.replace(\" didnt \",\" did not \")\n","  text = text.replace(\" didn t \",\" did not \")\n","  text = text.replace(\" let s \",\" let us \")\n","  text = text.replace(\" i'm \",\" i am \")\n","  text = text.replace(\" i've \",\" i have \")\n","  text = text.replace(\" i'll \",\" i will \")\n","  text = text.replace(\" i'd \",\" i had \")\n","  text = text.replace(\" that's \",\" that is \")\n","  text = text.replace(\" isn't \",\" is not \")\n","  text = text.replace(\" it's \",\" it is \")\n","  text = text.replace(\" she's \",\" she is \")\n","  text = text.replace(\" he's \",\" he is \")\n","  text = text.replace(\" u \",\" you \")\n","  text = text.replace(\" ur \",\" your \")\n","  text = text.replace(\" b4 \",\" before \")\n","  text = text.replace(\" wasn't \",\" was not \")\n","  text = text.replace(\" can't \",\" can not \")\n","  text = text.replace(\" couldn't \",\" could not \")\n","  text = text.replace(\" wouldn't \",\" would not \")\n","  text = text.replace(\" don't \",\" do not \")\n","  text = text.replace(\" didn't \",\" did not \")\n","  text = text.replace(\" let's \",\" let us \")\n","  text = text.replace(\" luv \",\" love \")\n","  text = text.replace(\" true \",\" truth \")\n","  text = text.replace(\" ppl \",\" people \")\n","  text = text.replace(\" fb \",\" facebook \")\n","  text = text.replace(\" b day \",\" birthday \")\n","  text = text.replace(\" bday \",\" birthday \")\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeHashtags(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='#', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeMentions(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='@', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeHttpWeb(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='&', words)\n","  words = filter(lambda x:x[0:4]!='http', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n"],"metadata":{"id":"40ElLojg4bl0","executionInfo":{"status":"ok","timestamp":1699812381204,"user_tz":-60,"elapsed":250,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# CLEANUP FACTORY\n","def cleanup(text):\n","  #Scenario1:\n","  text = removeSpecialChar(text)\n","  text = remove1stMent(text)\n","  text = removeHttpWeb(text)\n","  text = cleanColloquials(text)\n","\n","  #Scenario2: remove1stMent, removeHttpWeb, removeSpecialChar, cleanColloquials\n","  #Scenario3: remove1stMent, removeHttpWeb, removeHashtags, removeSpecialChar, cleanColloquials\n","  return(text)"],"metadata":{"id":"IGIXmrPlBnyr","executionInfo":{"status":"ok","timestamp":1699812382820,"user_tz":-60,"elapsed":8,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["#df['CleanTweet'] = df['OrigTweet'].apply(remove1stMentNoSpecChar)\n","#remove1stMentNoSpecChar('@MarkSZaidEsq @tko From the evidence and more to co')\n","df['CleanTweet'] = df['OrigTweet'].apply(cleanup)"],"metadata":{"id":"i8X6B0l0rxUA","executionInfo":{"status":"ok","timestamp":1699812395476,"user_tz":-60,"elapsed":11587,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# check the label distribution\n","df_RecTweets = df[df.InReplyTo.isna()]\n","df_RecTweets.groupby(['Label','Target']).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YyhtX056Pevs","executionInfo":{"status":"ok","timestamp":1699812400472,"user_tz":-60,"elapsed":354,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"374cc75b-ab6e-4edf-8a48-358f667644d9"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label           Target\n","Business        1          75\n","Entertainment   2         176\n","Environmental   3          55\n","Human Rights    5         115\n","Obituary        9         148\n","Politics        6         608\n","Social Stories  10         59\n","Sports          11         84\n","dtype: int64"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["print(f\"The dataset contains { df.Target.nunique() } unique categories\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9ROhaMftWNn","executionInfo":{"status":"ok","timestamp":1699812406951,"user_tz":-60,"elapsed":255,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"47934bab-b4c6-4c5f-8a20-7ffb5c50d0a0"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["The dataset contains 8 unique categories\n"]}]},{"cell_type":"code","source":["# convert the tweets into lower case if uncased model.\n","#df['CleanTweet'] = df['CleanTweet'].apply(lambda x: str(x).lower())\n","# trim to 280 characters max\n","df['CleanTweet'] = df['CleanTweet'].str.slice(0,279)\n","# calculating the length of tweet\n","df['CleanTweet_len'] = df['CleanTweet'].apply(lambda x: len(str(x).split()))\n","# Remove tweets with less than 10 words\n","df = df.query('CleanTweet_len > 9')\n","len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1WFEkq8McZk","executionInfo":{"status":"ok","timestamp":1699812410029,"user_tz":-60,"elapsed":1286,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"733b2bfa-fa5b-4512-babd-23001609dc15"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["172877"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# check that the RecTweets are still all in the dataset after the cleansing\n","df_RecTweets = df[df.InReplyTo.isna()]\n","df_RecTweets.groupby(['Label','Target']).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5voRycn6oCp","executionInfo":{"status":"ok","timestamp":1699812411987,"user_tz":-60,"elapsed":7,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"0ce3f206-41b9-4f34-85c5-191d9dd9b537"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Label           Target\n","Business        1          67\n","Entertainment   2         160\n","Environmental   3          49\n","Human Rights    5         111\n","Obituary        9         139\n","Politics        6         583\n","Social Stories  10         54\n","Sports          11         66\n","dtype: int64"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["#Serialize the Targets for the encoder\n","df.loc[(df.Target == 1), 'Target'] = 0 # Business\n","df.loc[(df.Target == 2), 'Target'] = 1 # Entertainment\n","df.loc[(df.Target == 3), 'Target'] = 2 # Environmental\n","df.loc[(df.Target == 5), 'Target'] = 3 # Human Rights\n","df.loc[(df.Target == 6), 'Target'] = 4 # Politics\n","df.loc[(df.Target == 9), 'Target'] = 5 # Obituary\n","df.loc[(df.Target == 10), 'Target'] = 6 # Social Stories\n","df.loc[(df.Target == 11), 'Target'] = 7 # Sports"],"metadata":{"id":"RK3Z7_9LKarP","executionInfo":{"status":"ok","timestamp":1699812414266,"user_tz":-60,"elapsed":250,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# set index to TID (used later in the Training/Test Series)\n","df.index = df['TID']\n","df.index.rename('gt_idx', inplace=True)\n","df.head(2)"],"metadata":{"id":"OYthw-qqtN5r","executionInfo":{"status":"ok","timestamp":1699812416497,"user_tz":-60,"elapsed":284,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"colab":{"base_uri":"https://localhost:8080/","height":178},"outputId":"d35898e1-856c-44ae-b4b4-c4f325d1ae2d"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                     TID  \\\n","gt_idx                                     \n","1192830655060758529  1192830655060758529   \n","1216223678591119366  1216223678591119366   \n","\n","                                                             OrigTweet  \\\n","gt_idx                                                                   \n","1192830655060758529  @KFCSA @KFCSA Frankees is in this with you. We...   \n","1216223678591119366  @AlxThomp @SallyAlbright Do you have other re-...   \n","\n","                               InReplyTo           Label  Target  \\\n","gt_idx                                                             \n","1192830655060758529  1192359716955009024  Social Stories       6   \n","1216223678591119366  1216201562357424128        Politics       4   \n","\n","                                                            CleanTweet  \\\n","gt_idx                                                                   \n","1192830655060758529  @KFCSA Frankees is in this with you. We ll spo...   \n","1216223678591119366  @SallyAlbright Do you have other re-typed inst...   \n","\n","                     CleanTweet_len  \n","gt_idx                               \n","1192830655060758529              37  \n","1216223678591119366              40  "],"text/html":["\n","  <div id=\"df-7fd6f6c2-d87c-46d5-8c09-ad545d21cd17\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TID</th>\n","      <th>OrigTweet</th>\n","      <th>InReplyTo</th>\n","      <th>Label</th>\n","      <th>Target</th>\n","      <th>CleanTweet</th>\n","      <th>CleanTweet_len</th>\n","    </tr>\n","    <tr>\n","      <th>gt_idx</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1192830655060758529</th>\n","      <td>1192830655060758529</td>\n","      <td>@KFCSA @KFCSA Frankees is in this with you. We...</td>\n","      <td>1192359716955009024</td>\n","      <td>Social Stories</td>\n","      <td>6</td>\n","      <td>@KFCSA Frankees is in this with you. We ll spo...</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>1216223678591119366</th>\n","      <td>1216223678591119366</td>\n","      <td>@AlxThomp @SallyAlbright Do you have other re-...</td>\n","      <td>1216201562357424128</td>\n","      <td>Politics</td>\n","      <td>4</td>\n","      <td>@SallyAlbright Do you have other re-typed inst...</td>\n","      <td>40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fd6f6c2-d87c-46d5-8c09-ad545d21cd17')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7fd6f6c2-d87c-46d5-8c09-ad545d21cd17 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7fd6f6c2-d87c-46d5-8c09-ad545d21cd17');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-13be03b6-ac6b-4de5-93f9-213165d26f56\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13be03b6-ac6b-4de5-93f9-213165d26f56')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-13be03b6-ac6b-4de5-93f9-213165d26f56 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["#use XLNet base cased pretrained tokenizer\n","tokenizer = transformers.XLNetTokenizer.from_pretrained('xlnet-base-cased')"],"metadata":{"id":"PJfSoFfpuTVJ","executionInfo":{"status":"ok","timestamp":1699812427992,"user_tz":-60,"elapsed":776,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["defe0dc3f81f44079cb83f174ab92933","5f7ed67e2add46c6bd07455b11c17479","e61f841c849543c29670342810dcf871","52b675663ac249d68c4941fc33955e95","96a4043214d342aab2e526170e3ad1bc","9efc60aea09143ce8fc3d38105a71fd6","6ed4dc68f8fa44ac9f637ba5f2225eb2","704f61975a5f466e87a2c7ac12197aa9","904b298e58a149b8b9d78cc0f23eafb0","9c25110fd46d49b693dec97d230d8252","869ea5ff5dcf408aa9b7c7a0bef93a0c","bc6c804d39bc4e1ca9e6dff3def8dedc","6da4cfe6e480426d9b06ed23183c9a77","7230944f9cf740e7b5bd38df19caa9b1","e6bd47551d254f6ea4d2ca5bec6c47e3","bcd4770a2e26486fae47670c2d02d4ff","252b2f272e17413da9ed5307c5659255","8be9c279453443a3a3a0735087d0a186","c709121824cf4257a60ec39348a12442","f7d5b6db09c64f83a0ac2bb629fb4f0d","6287b0cda1a842ab8eaabe3b5c642c22","1352b5e828544341b0790e2210cbbead"]},"outputId":"84242cba-722b-45e8-be45-8f29e6d845d0"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["(…)net-base-cased/resolve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"defe0dc3f81f44079cb83f174ab92933"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["(…)lnet-base-cased/resolve/main/config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc6c804d39bc4e1ca9e6dff3def8dedc"}},"metadata":{}}]},{"cell_type":"code","source":["# NOTE: batch_encode_plus adds [CLS], [SEP] to the text\n","def regular_encode(texts, tokenizer, maxlen=512):\n","    enc_di = tokenizer.batch_encode_plus(\n","        texts,\n","        return_attention_mask=False,\n","        return_token_type_ids=False,\n","        pad_to_max_length=True,\n","        truncation=True,\n","        padding='longest',\n","        max_length=maxlen\n","    )\n","    return np.array(enc_di['input_ids'])"],"metadata":{"id":"SccLStPwuAnU","executionInfo":{"status":"ok","timestamp":1699812429862,"user_tz":-60,"elapsed":252,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# BUILD THE MODEL\n","no_of_classes = 8\n","# seed for environmental stability\n","# tf.random.set_seed(0)"],"metadata":{"id":"0leihuY3u0WB","executionInfo":{"status":"ok","timestamp":1699812431670,"user_tz":-60,"elapsed":501,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def build_model(transformer, loss='categorical_crossentropy', max_len=512):\n","    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n","    sequence_output = transformer(input_word_ids)[0]\n","    cls_token = sequence_output[:, 0, :]\n","    #adding dropout layer\n","    #x = tf.keras.layers.Dropout(0.3, seed=0)(cls_token)\n","    x = tf.keras.layers.Dropout(0.3, )(cls_token)\n","    #using a dense layer of 11 neurons as the number of unique categories is 11.\n","    #out = tf.keras.layers.Dense(11, activation='softmax')(x)\n","    out = tf.keras.layers.Dense(no_of_classes, activation='softmax')(x)\n","    model = tf.keras.Model(inputs=input_word_ids, outputs=out)\n","    #using categorical crossentropy as the loss as it is a multi-class classification problem\n","    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss=loss, metrics=['accuracy'])\n","    return model"],"metadata":{"id":"ZzmqJPxLu41m","executionInfo":{"status":"ok","timestamp":1699812433154,"user_tz":-60,"elapsed":6,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["#building the model on tpu\n","with strategy.scope():\n","    transformer_layer = transformers.TFXLNetModel.from_pretrained('xlnet-base-cased')\n","    model = build_model(transformer_layer, max_len=99)\n","model.summary()\n","# Save the initial Neural Net weights (to use for resetting the model in between cross validation runs)\n","init_weights = model.get_weights()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":850,"referenced_widgets":["39a520a23f45439dae02d008f0fb06f8","a22d1844c39e431ca9c475fc4a2ceda3","5abecde0467441fa9673b12eddb92d0e","a5e1834b33744bd7a5498b2602bd1cc0","eddd1c95fa53420a95959dc88fb13c1b","2e4f070abe3c47fd94ed700f419f0878","129cd2dd94e543d591322d434b40d922","4fb6d0234041416c82b8d2305e09b9dd","7b29854a8ede48759da647f850117ecb","df32f0263a174e1da83507b8d01d89b1","2920a0c0f4744022bebd76ac000a66e6"]},"id":"aQm4LSYbz6KD","outputId":"4ff2f352-f8c0-4baa-de2c-c3b81f3997a5","executionInfo":{"status":"ok","timestamp":1699812500404,"user_tz":-60,"elapsed":65885,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":["tf_model.h5:   0%|          | 0.00/565M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39a520a23f45439dae02d008f0fb06f8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n","  warnings.warn(\n","Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n","- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_word_ids (InputLayer)  [(None, 99)]             0         \n","                                                                 \n"," tfxl_net_model (TFXLNetMode  TFXLNetModelOutput(last_  116718336\n"," l)                          hidden_state=(None, 99,             \n","                             768),                               \n","                              mems=((99, None, 768),             \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768),                   \n","                              (99, None, 768)),                  \n","                              hidden_states=None, att            \n","                             entions=None)                       \n","                                                                 \n"," tf.__operators__.getitem (S  (None, 768)              0         \n"," licingOpLambda)                                                 \n","                                                                 \n"," dropout_37 (Dropout)        (None, 768)               0         \n","                                                                 \n"," dense (Dense)               (None, 8)                 6152      \n","                                                                 \n","=================================================================\n","Total params: 116,724,488\n","Trainable params: 116,724,488\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["#X_train,X_test ,y_train,y_test = train_test_split(df['CleanTweet'], df['Target'], random_state = 1, stratify=df['Target'], test_size = 0.2)\n","X_train = df['CleanTweet']\n","y_train = df['Target']"],"metadata":{"id":"18ZS-jzjuO5U","executionInfo":{"status":"ok","timestamp":1699812769584,"user_tz":-60,"elapsed":266,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# KO 12Nov23\n","passID = 'Pass4'\n","DL_algo = 'XLNet_CV_2ndRun'\n","runID = dt.today().strftime('%Y%m%d%H%M')"],"metadata":{"id":"FIL1O76SDqDO","executionInfo":{"status":"ok","timestamp":1699813032546,"user_tz":-60,"elapsed":271,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["runID = dt.today().strftime('%Y%m%d%H%M')\n","# 5-Fold Cross Validation\n","kf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n","# kf = StratifiedKFold(n_splits=5)\n","# kf = StratifiedKFold(n_splits=2, random_state=0, shuffle=True)\n","k=1\n","df_tr_hist = pd.DataFrame(columns=['RunID','PassID','Model','Loss','Accuracy'])\n","df_val_result = pd.DataFrame(columns=['ValID','ValType','Model','Accuracy','Precision','Recall','F1'])\n","for tr_idx, val_idx in kf.split(X_train, y_train):\n","  print(f\"\\nTraining for Cross Val: {k} \")\n","  print(f\"Indexes for tr {tr_idx} and val {val_idx}\")\n","  X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n","  y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n","  print(\"Encoding y_tr and y_val...\")\n","  ytr_encoded = tf.keras.utils.to_categorical(y_tr, num_classes=no_of_classes,dtype = 'int32')\n","  yval_encoded = tf.keras.utils.to_categorical(y_val, num_classes=no_of_classes,dtype = 'int32')\n","  print(\"Encoding X_tr and X_val...\")\n","  Xtr_encoded = regular_encode(X_tr.astype('str'), tokenizer, maxlen=99)\n","  Xval_encoded = regular_encode(X_val.astype('str'), tokenizer, maxlen=99)\n","  print(f\"Shapes for X_tr {Xtr_encoded.shape}, y_tr {ytr_encoded.shape}, X_val {Xval_encoded.shape} and y_val {yval_encoded.shape}\")\n","\n","  print(\"creating the tr and val datasets...\")\n","  BATCH_SIZE = 32*strategy.num_replicas_in_sync\n","  AUTO = tf.data.experimental.AUTOTUNE\n","  train_dataset = tf.data.Dataset.from_tensor_slices((Xtr_encoded, ytr_encoded))\n","  test_dataset = tf.data.Dataset.from_tensor_slices(Xval_encoded)\n","\n","  epochs_no = 10\n","  #creating the training and testing dataset.\n","  train_dataset = (\n","      tf.data.Dataset\n","      .from_tensor_slices((Xtr_encoded, ytr_encoded))\n","      .repeat()\n","      .shuffle(2048)\n","      .batch(BATCH_SIZE)\n","      .prefetch(AUTO)\n","  )\n","  test_dataset = (\n","      tf.data.Dataset\n","      .from_tensor_slices(Xval_encoded)\n","      .batch(BATCH_SIZE)\n","  )\n","\n","  #training for the epochs\n","  n_steps = Xtr_encoded.shape[0] // BATCH_SIZE\n","  train_history = model.fit(\n","      train_dataset,\n","      steps_per_epoch=n_steps,\n","      epochs=epochs_no\n","  )\n","\n","  #store the training history log\n","  df_tr_hist.loc[len(df_tr_hist)] = [runID, passID, DL_algo, train_history.history['loss'], train_history.history['accuracy']]\n","\n","  #Making predictions for val\n","  preds = model.predict(test_dataset,verbose = 1)\n","  pred_classes = np.argmax(preds, axis = 1)\n","\n","  #Mapping the encoded output to actual categories...\n","  # write result for decomposed SMR\n","  actual_category = np.argmax(yval_encoded, axis = 1)\n","  acc = sklearn.metrics.accuracy_score(actual_category,pred_classes)\n","  print(\"Generating decomposed SMR performance metrics ...\" )\n","  de_prec = precision_score(actual_category,pred_classes, average = 'weighted')\n","  de_recall = recall_score(actual_category,pred_classes, average = 'weighted')\n","  de_f1 = f1_score(actual_category,pred_classes, average = 'weighted')\n","\n","  print(f\"Decomposed SMR Acc: {acc*100}, Prec: {de_prec*100}, Recall: {de_recall*100}, F1 {de_f1*100}\")\n","  df_val_result.loc[len(df_val_result)] = [k, 'Decomposed', 'XLNet', acc*100, de_prec*100, de_recall*100, de_f1*100]\n","\n","  # p_r_f1 = precision_recall_fscore_support(actual_category, pred_classes, average = 'weighted')\n","  # print(f\"Decomposed SMR Acc: {acc*100}, Prec: {p_r_f1[0]*100}, Recall: {p_r_f1[1]*100}, F1 {p_r_f1[2]*100}\")\n","  # df_val_result.loc[len(df_val_result)] = [k, 'Decomposed', 'XLNet', acc*100, p_r_f1[0]*100, p_r_f1[1]*100, p_r_f1[2]*100]\n","\n","  print(\"Generating recomposed SMR accuracy...\")\n","  list_X_val_idx = X_val.index.tolist()\n","  result_df = pd.DataFrame({'idx':list_X_val_idx, 'actual_category':actual_category, 'predicted_category':pred_classes})\n","  df_sup_result = result_df.merge(df, left_on='idx', right_on='TID')\n","  df_sup_agg_result = df_sup_result.groupby(['InReplyTo','predicted_category']).size().reset_index(name='counts').sort_values(['InReplyTo','counts'], ascending=[True,False])\n","  df_rec = df[df.InReplyTo.isna()]\n","\n","  # Recompose the SMR based on the count of aggregated supporting tweet predictions\n","  df_rec_result = pd.DataFrame(columns=['TID','Actual','Predicted'])\n","  for i in range(0,len(df_rec)):\n","    rec_TID = df_rec.iloc[i]['TID']\n","    rec_cat = int(df_rec.iloc[i]['Target'])\n","    df_temp = df_sup_agg_result[df_sup_agg_result.InReplyTo == rec_TID].sort_values('counts',ascending=False)\n","    if len(df_temp) > 0:\n","      rec_pred = int(np.squeeze(df_temp[:1]['predicted_category'].values)) # np.squeeze to resolve the Conversion of an array with ndim > 0 to a scalar is deprecated error warning\n","      df_rec_result.loc[len(df_rec_result)] = [rec_TID,rec_cat,rec_pred]\n","\n","  # write result for recomposed SMR\n","  rec_actual = df_rec_result['Actual'].to_numpy().astype(int)\n","  rec_pred = df_rec_result['Predicted'].to_numpy().astype(int)\n","  rec_acc = sklearn.metrics.accuracy_score(rec_actual, rec_pred)\n","  rec_prec = precision_score(rec_actual, rec_pred, average = 'weighted')\n","  rec_recall = recall_score(rec_actual, rec_pred, average = 'weighted')\n","  rec_f1 = f1_score(rec_actual, rec_pred, average = 'weighted')\n","\n","  print(f\"Recomposed SMR Acc: {rec_acc*100}, Prec: {rec_prec*100}, Recall: {rec_recall*100}, F1 {rec_f1*100}\")\n","  df_val_result.loc[len(df_val_result)] = [k, 'Recomposed', 'XLNet', rec_acc*100, rec_prec*100, rec_recall*100, rec_f1*100]\n","\n","  # print(f\"Recomposed SMR Acc: {rec_acc*100}, Prec: {rec_p_r_f1[0]*100}, Recall: {rec_p_r_f1[1]*100}, F1 {rec_p_r_f1[2]*100}\")\n","  # df_val_result.loc[len(df_val_result)] = [k, 'Recomposed', 'XLNet', rec_acc*100, rec_p_r_f1[0]*100, rec_p_r_f1[1]*100, rec_p_r_f1[2]*100]\n","\n","  # Generate confusion matrix\n","  rec_cm = confusion_matrix(rec_actual, rec_pred)\n","  df_rec_cm = pd.DataFrame(rec_cm)\n","  df_rec_cm.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_CM_\" + str(k) + \" \" + runID +\".csv\")\n","\n","  #KO 12Nov23\n","  # Save the verbose actual and pred for each SMR, for each CV run\n","  df_rec_result.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_CV_\"  + str(k) + \"_rec_result_\" + runID +\".csv\")\n","\n","  # Reset the model by restoring the initital model weights to prevent overtraining\n","  model.set_weights(init_weights)\n","  k=k+1\n","\n","# Save the training history result\n","# df_tr_hist.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/XLNet_GTr_TrainHist_\" + runID +\".csv\")\n","\n","# Save the cross validation result\n","df_val_result = df_val_result.round(decimals=2)\n","df_val_result.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_CV_\" + runID +\".csv\")\n","\n","# Save RunID,Model,Accuracy,Precision,Recall,F1 for the Recomposed SMR\n","df_re_val_result = df_val_result[df_val_result.ValType=='Recomposed']\n","no_of_runs = len(df_re_val_result)\n","df_GTxM_Clf_CV_results = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_Clf_CV_results.csv\")\n","avg_Accuracy = np.sum(df_re_val_result['Accuracy']) / no_of_runs\n","avg_Precision = np.sum(df_re_val_result['Precision']) / no_of_runs\n","avg_Recall = np.sum(df_re_val_result['Recall']) / no_of_runs\n","avg_F1 = np.sum(df_re_val_result['F1']) / no_of_runs\n","#KO 12Nov23\n","df_GTxM_Clf_CV_results.loc[len(df_GTxM_Clf_CV_results)] = [runID, passID+\" \"+DL_algo, avg_Accuracy, avg_Precision, avg_Recall, avg_F1]\n","df_GTxM_Clf_CV_results.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_Clf_CV_results.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkzVZhP3vEQ-","outputId":"cf8aaf65-7c05-48b1-bfc1-901bdb8efa59","executionInfo":{"status":"ok","timestamp":1699821632259,"user_tz":-60,"elapsed":8597998,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training for Cross Val: 1 \n","Indexes for tr [     1      2      4 ... 172871 172875 172876] and val [     0      3      6 ... 172872 172873 172874]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (138301, 99), y_tr (138301, 8), X_val (34576, 99) and y_val (34576, 8)\n","creating the tr and val datasets...\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n","WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_model/transformer/mask_emb:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_model/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"]},{"output_type":"stream","name":"stdout","text":["540/540 [==============================] - 244s 294ms/step - loss: 1.0346 - accuracy: 0.6860\n","Epoch 2/10\n","540/540 [==============================] - 160s 295ms/step - loss: 0.5609 - accuracy: 0.8243\n","Epoch 3/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.4485 - accuracy: 0.8589\n","Epoch 4/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.3674 - accuracy: 0.8836\n","Epoch 5/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.3039 - accuracy: 0.9024\n","Epoch 6/10\n","540/540 [==============================] - 158s 293ms/step - loss: 0.2487 - accuracy: 0.9200\n","Epoch 7/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.1990 - accuracy: 0.9356\n","Epoch 8/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.1530 - accuracy: 0.9499\n","Epoch 9/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.1242 - accuracy: 0.9589\n","Epoch 10/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.0972 - accuracy: 0.9676\n","136/136 [==============================] - 32s 205ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 87.32646922720963, Prec: 87.55063149921543, Recall: 87.32646922720963, F1 87.38062797520685\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 93.0116472545757, Prec: 93.027421280605, Recall: 93.0116472545757, F1 92.9851781356212\n","\n","Training for Cross Val: 2 \n","Indexes for tr [     0      1      3 ... 172874 172875 172876] and val [     2     11     23 ... 172846 172849 172862]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (138301, 99), y_tr (138301, 8), X_val (34576, 99) and y_val (34576, 8)\n","creating the tr and val datasets...\n","Epoch 1/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.9755 - accuracy: 0.7011\n","Epoch 2/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.5528 - accuracy: 0.8251\n","Epoch 3/10\n","540/540 [==============================] - 158s 293ms/step - loss: 0.4426 - accuracy: 0.8594\n","Epoch 4/10\n","540/540 [==============================] - 158s 293ms/step - loss: 0.3648 - accuracy: 0.8836\n","Epoch 5/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.3022 - accuracy: 0.9028\n","Epoch 6/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.2462 - accuracy: 0.9201\n","Epoch 7/10\n","540/540 [==============================] - 158s 293ms/step - loss: 0.1950 - accuracy: 0.9366\n","Epoch 8/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.1548 - accuracy: 0.9484\n","Epoch 9/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.1185 - accuracy: 0.9605\n","Epoch 10/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.0921 - accuracy: 0.9689\n","136/136 [==============================] - 16s 111ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 87.7805414160111, Prec: 87.79810200426721, Recall: 87.7805414160111, F1 87.72132254341113\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 92.84511784511784, Prec: 92.97509039558172, Recall: 92.84511784511784, F1 92.76304387330985\n","\n","Training for Cross Val: 3 \n","Indexes for tr [     0      1      2 ... 172873 172874 172876] and val [     5     12     22 ... 172870 172871 172875]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (138302, 99), y_tr (138302, 8), X_val (34575, 99) and y_val (34575, 8)\n","creating the tr and val datasets...\n","Epoch 1/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.9772 - accuracy: 0.7007\n","Epoch 2/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.5539 - accuracy: 0.8259\n","Epoch 3/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.4436 - accuracy: 0.8597\n","Epoch 4/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.3663 - accuracy: 0.8833\n","Epoch 5/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.3043 - accuracy: 0.9021\n","Epoch 6/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.2446 - accuracy: 0.9213\n","Epoch 7/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.2009 - accuracy: 0.9346\n","Epoch 8/10\n","540/540 [==============================] - 158s 293ms/step - loss: 0.1583 - accuracy: 0.9479\n","Epoch 9/10\n","540/540 [==============================] - 159s 295ms/step - loss: 0.1216 - accuracy: 0.9598\n","Epoch 10/10\n","540/540 [==============================] - 160s 296ms/step - loss: 0.0970 - accuracy: 0.9679\n","136/136 [==============================] - 16s 111ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 87.14389009399855, Prec: 87.31206876052464, Recall: 87.14389009399855, F1 87.17678639143088\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 93.82303839732889, Prec: 93.84489830165325, Recall: 93.82303839732889, F1 93.71436187604986\n","\n","Training for Cross Val: 4 \n","Indexes for tr [     0      1      2 ... 172874 172875 172876] and val [     7     16     17 ... 172863 172865 172867]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (138302, 99), y_tr (138302, 8), X_val (34575, 99) and y_val (34575, 8)\n","creating the tr and val datasets...\n","Epoch 1/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.9673 - accuracy: 0.7054\n","Epoch 2/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.5439 - accuracy: 0.8288\n","Epoch 3/10\n","540/540 [==============================] - 159s 295ms/step - loss: 0.4354 - accuracy: 0.8613\n","Epoch 4/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.3580 - accuracy: 0.8855\n","Epoch 5/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.2973 - accuracy: 0.9046\n","Epoch 6/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.2395 - accuracy: 0.9227\n","Epoch 7/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.1895 - accuracy: 0.9376\n","Epoch 8/10\n","540/540 [==============================] - 158s 293ms/step - loss: 0.1485 - accuracy: 0.9515\n","Epoch 9/10\n","540/540 [==============================] - 158s 293ms/step - loss: 0.1167 - accuracy: 0.9616\n","Epoch 10/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.0880 - accuracy: 0.9703\n","136/136 [==============================] - 16s 110ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 87.69631236442517, Prec: 87.52160932775523, Recall: 87.69631236442517, F1 87.47366409378115\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 92.9471032745592, Prec: 93.05129862347077, Recall: 92.9471032745592, F1 92.75376879598039\n","\n","Training for Cross Val: 5 \n","Indexes for tr [     0      2      3 ... 172873 172874 172875] and val [     1      4      8 ... 172864 172866 172876]\n","Encoding y_tr and y_val...\n","Encoding X_tr and X_val...\n","Shapes for X_tr (138302, 99), y_tr (138302, 8), X_val (34575, 99) and y_val (34575, 8)\n","creating the tr and val datasets...\n","Epoch 1/10\n","540/540 [==============================] - 159s 294ms/step - loss: 1.2924 - accuracy: 0.6014\n","Epoch 2/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.6357 - accuracy: 0.8006\n","Epoch 3/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.4896 - accuracy: 0.8445\n","Epoch 4/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.4062 - accuracy: 0.8703\n","Epoch 5/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.3392 - accuracy: 0.8910\n","Epoch 6/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.2811 - accuracy: 0.9094\n","Epoch 7/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.2327 - accuracy: 0.9249\n","Epoch 8/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.1842 - accuracy: 0.9395\n","Epoch 9/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.1451 - accuracy: 0.9522\n","Epoch 10/10\n","540/540 [==============================] - 159s 294ms/step - loss: 0.1159 - accuracy: 0.9615\n","136/136 [==============================] - 16s 111ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 87.14389009399855, Prec: 87.28663756439498, Recall: 87.14389009399855, F1 87.1692991024843\n","Generating recomposed SMR accuracy...\n","Recomposed SMR Acc: 93.24894514767934, Prec: 93.31480896093187, Recall: 93.24894514767934, F1 93.15731412159342\n"]}]},{"cell_type":"code","source":["# old\n","#df_rec_result.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_\"+passID+\"/\"+passID+\"_\"+DL_algo+\"_last_CV_rec_result_\" + runID +\".csv\")"],"metadata":{"id":"MAPsj_yfCRbP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model.save(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/SavedModels/XLNet_Model_\" + runID +\".h5\")"],"metadata":{"id":"qt-SWSSaMCrc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RUfeKrImmHuI"},"execution_count":null,"outputs":[]}]}