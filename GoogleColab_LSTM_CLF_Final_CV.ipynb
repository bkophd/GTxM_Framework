{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KtKS324EtFJ_pq1_v5An9kxJW0cjBDr0","timestamp":1654086943717},{"file_id":"1xIYU2pqMn3WbMEzfs5GsEWo8iUH8MeDD","timestamp":1644609098344},{"file_id":"13aLb_dvWhy8cgjtkUsY63FFz9Nrj39vE","timestamp":1641762890771},{"file_id":"1HMNUAtNAj9VQIwM4AEdpsBH9rjTii3Yg","timestamp":1641749303952}],"mount_file_id":"1HMNUAtNAj9VQIwM4AEdpsBH9rjTii3Yg","authorship_tag":"ABX9TyPp+jq9OTUNHlhudt1wx4CX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["#Credit: https://www.kaggle.com/code/ngyptr/multi-class-classification-with-lstm/notebook"],"metadata":{"id":"RqCazhwjuXKV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall -y keras\n","!pip uninstall -y tensorflow\n","!pip install --upgrade keras==2.10.0\n","!pip install --upgrade tensorflow==2.10.0\n","!pip install unidecode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3eoNCkUXzlxm","executionInfo":{"status":"ok","timestamp":1684057691715,"user_tz":-120,"elapsed":101714,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"7b45f49c-9862-4fe9-ac54-755ef4f067a3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: keras 2.12.0\n","Uninstalling keras-2.12.0:\n","  Successfully uninstalled keras-2.12.0\n","Found existing installation: tensorflow 2.12.0\n","Uninstalling tensorflow-2.12.0:\n","  Successfully uninstalled tensorflow-2.12.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras==2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras\n","Successfully installed keras-2.10.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==2.10.0\n","  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.8.0)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n","Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.0)\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (16.0.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.24.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.1)\n","Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.0)\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n","Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.0)\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.32.0)\n","Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.0)\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.14.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.40.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.17.3)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.27.1)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n","Installing collected packages: tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.0\n","    Uninstalling tensorboard-data-server-0.7.0:\n","      Successfully uninstalled tensorboard-data-server-0.7.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.0.0\n","    Uninstalling google-auth-oauthlib-1.0.0:\n","      Successfully uninstalled google-auth-oauthlib-1.0.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.2\n","    Uninstalling tensorboard-2.12.2:\n","      Successfully uninstalled tensorboard-2.12.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting unidecode\n","  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.3.6\n"]}]},{"cell_type":"code","source":["!pip install keras_self_attention"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iubWTSItqkTm","executionInfo":{"status":"ok","timestamp":1684057785918,"user_tz":-120,"elapsed":8841,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"293d0dd5-ceb0-4882-d4c6-b0d225657a87"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras_self_attention\n","  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_self_attention) (1.24.3)\n","Building wheels for collected packages: keras_self_attention\n","  Building wheel for keras_self_attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras_self_attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=6a3643f18ac3690e22e145b6784e547334c6c5ea761bd0b4784caa64148a9122\n","  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n","Successfully built keras_self_attention\n","Installing collected packages: keras_self_attention\n","Successfully installed keras_self_attention-0.51.0\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Attention\n","from keras.models import Sequential\n","from keras.preprocessing.text import Tokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","from keras.utils.np_utils import to_categorical\n","from keras.callbacks import EarlyStopping\n","from keras_self_attention import SeqWeightedAttention\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","import sklearn\n","from sklearn.metrics import confusion_matrix\n","\n","import re\n","from unidecode import unidecode\n","from datetime import datetime as dt\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score"],"metadata":{"id":"DUrpgdtvmgY0","executionInfo":{"status":"ok","timestamp":1684057792680,"user_tz":-120,"elapsed":2394,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Detect hardware, return appropriate distribution strategy\n","try:\n","    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n","    # set: this is always the case on Kaggle.\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    #strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","    strategy = tf.distribute.TPUStrategy(tpu)\n","else:\n","    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n","    strategy = tf.distribute.get_strategy()\n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1BsVTjBU4nXV","executionInfo":{"status":"ok","timestamp":1684057859077,"user_tz":-120,"elapsed":61695,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"7e5d297c-b9a8-4550-8142-f6197c30af43"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU  grpc://10.6.230.106:8470\n","REPLICAS:  8\n"]}]},{"cell_type":"code","source":["from google.colab import drive \n","drive.mount(\"/content/drive\", force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qlq9f5tGmzRn","executionInfo":{"status":"ok","timestamp":1684057877319,"user_tz":-120,"elapsed":18254,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"e8f9ed14-2349-4e6b-c022-8ba83500ebf2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/reGroundTruthBERT.csv', dtype='str')\n","#df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/CGT_ReGTR_BERT_Input.csv', dtype='str')\n","df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/GrounTruthBERT.csv', dtype='str', usecols=['TID', 'OrigTweet', 'InReplyTo', 'Target', 'Label'])\n","#df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/data/GrounTruthBERT.csv', dtype='str', usecols=['TID', 'CleanTweetNoHttp', 'InReplyTo', 'Target', 'Label'])\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"HDE1yOAwqhNB","executionInfo":{"status":"ok","timestamp":1684057888797,"user_tz":-120,"elapsed":3751,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"4160d785-6568-4517-baf0-f474984269e7"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   TID                                          OrigTweet  \\\n","0   826262311560216578  #coup has started. First of many steps. #rebel...   \n","1  1193437298303438858  @MarkSZaidEsq @jody_prichard Funny you want to...   \n","2  1194280882540036098  @MarkSZaidEsq at THAT time, the only \"stepping...   \n","3  1194635634960478208  @MarkSZaidEsq It's not a coup.  It's a Constit...   \n","4  1194636052096413696  @MarkSZaidEsq BTW, I've read your client HOSTE...   \n","\n","            InReplyTo Target     Label  \n","0                 NaN     10  Politics  \n","1  826262311560216578     10  Politics  \n","2  826262311560216578     10  Politics  \n","3  826262311560216578     10  Politics  \n","4  826262311560216578     10  Politics  "],"text/html":["\n","  <div id=\"df-b1a06ff2-4280-44fd-9d5e-e054bacd27a9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TID</th>\n","      <th>OrigTweet</th>\n","      <th>InReplyTo</th>\n","      <th>Target</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>826262311560216578</td>\n","      <td>#coup has started. First of many steps. #rebel...</td>\n","      <td>NaN</td>\n","      <td>10</td>\n","      <td>Politics</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1193437298303438858</td>\n","      <td>@MarkSZaidEsq @jody_prichard Funny you want to...</td>\n","      <td>826262311560216578</td>\n","      <td>10</td>\n","      <td>Politics</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1194280882540036098</td>\n","      <td>@MarkSZaidEsq at THAT time, the only \"stepping...</td>\n","      <td>826262311560216578</td>\n","      <td>10</td>\n","      <td>Politics</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1194635634960478208</td>\n","      <td>@MarkSZaidEsq It's not a coup.  It's a Constit...</td>\n","      <td>826262311560216578</td>\n","      <td>10</td>\n","      <td>Politics</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1194636052096413696</td>\n","      <td>@MarkSZaidEsq BTW, I've read your client HOSTE...</td>\n","      <td>826262311560216578</td>\n","      <td>10</td>\n","      <td>Politics</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1a06ff2-4280-44fd-9d5e-e054bacd27a9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b1a06ff2-4280-44fd-9d5e-e054bacd27a9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b1a06ff2-4280-44fd-9d5e-e054bacd27a9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["df = df[df.Target.notna()]"],"metadata":{"id":"XhX1zrzReodt","executionInfo":{"status":"ok","timestamp":1684057890529,"user_tz":-120,"elapsed":310,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sj-gOhNk_APf","executionInfo":{"status":"ok","timestamp":1684057891293,"user_tz":-120,"elapsed":10,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"445cfc48-eb05-4501-85ff-216329aa7065"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["124977"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# convert some columns to int\n","#df['CountReplyTweets'] = df['CountReplyTweets'].astype(float)\n","#df['CountReplyWords'] = df['CountReplyWords'].astype(float)\n","#df['CountReplyChars'] = df['CountReplyChars'].astype(float)\n","df['Target'] = df['Target'].astype(int)"],"metadata":{"id":"3vcGLs0xyuoC","executionInfo":{"status":"ok","timestamp":1684057892278,"user_tz":-120,"elapsed":5,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def remove1stMent(text):\n","  if text[0] == '@':\n","      words = text.split()\n","      words = words[1:] # remove the @mention word\n","      text = \" \".join(words).lstrip()\n","  return(text)\n","\n","def removeSpecialChar(text):\n","  #old text = re.sub(r'\\W', ' ', text) #replace ALL non-word characters, including emojis with space\n","  # remove all non ASCII characters \n","\n","  # credit: https://stackoverflow.com/questions/2758921/regular-expression-that-finds-and-replaces-non-ascii-characters-with-python\n","  text = re.sub(r\"[\\u0080-\\uFFFF]\", \" \", text) #see ASCII list: https://www.asciitable.com/\n","  text = \" \".join(text.split()) # replace multiple spaces with a single space\n","  return(text)\n","\n","def removeDigits(text):\n","  text = re.sub(r'\\d', ' ', text) #replace digits with space\n","  return(text)\n","\n","def cleanColloquials(text):\n","  #replace this strange chars in the text with space\n","  text = text.replace(\"GCO\",\" \")\n","  text = text.replace(\"GY=n+\",\" \")\n","  text = text.replace(\"GCY\",\" \")\n","  text = text.replace(\"fcafc+\",\" \")\n","  text = text.replace(\"fAE+\",\" \")\n","  text = text.replace(\"#fAE\",\" \")\n","  text = text.replace(\"fnae\",\" \")\n","  text = text.replace(\"fye\",\" \")\n","\n","  #Replace common abbreviations and slangs\n","  text = text.replace(\" i m \",\" i am \")\n","  text = text.replace(\" i ve \",\" i have \")\n","  text = text.replace(\" i ll \",\" i will \")\n","  text = text.replace(\" i d \",\" i had \")\n","  text = text.replace(\" that s \",\" that is \")\n","  text = text.replace(\" isn t \",\" is not \")\n","  text = text.replace(\" it s \",\" it is \")\n","  text = text.replace(\" she s \",\" she is \")\n","  text = text.replace(\" he s \",\" he is \")\n","  text = text.replace(\" u \",\" you \")\n","  text = text.replace(\" ur \",\" your \")\n","  text = text.replace(\" b4 \",\" before \")\n","  text = text.replace(\" wasnt \",\" was not \")\n","  text = text.replace(\" wasn t \",\" was not \")\n","  text = text.replace(\" cant \",\" can not \")\n","  text = text.replace(\" can t \",\" can not \")\n","  text = text.replace(\" couldnt \",\" could not \")\n","  text = text.replace(\" couldn t \",\" could not \")\n","  text = text.replace(\" wouldnt \",\" would not \")\n","  text = text.replace(\" wouldn t \",\" would not \")\n","  text = text.replace(\" dont \",\" do not \")\n","  text = text.replace(\" don t \",\" do not \")\n","  text = text.replace(\" didnt \",\" did not \")\n","  text = text.replace(\" didn t \",\" did not \")\n","  text = text.replace(\" let s \",\" let us \")\n","  text = text.replace(\" i'm \",\" i am \")\n","  text = text.replace(\" i've \",\" i have \")\n","  text = text.replace(\" i'll \",\" i will \")\n","  text = text.replace(\" i'd \",\" i had \")\n","  text = text.replace(\" that's \",\" that is \")\n","  text = text.replace(\" isn't \",\" is not \")\n","  text = text.replace(\" it's \",\" it is \")\n","  text = text.replace(\" she's \",\" she is \")\n","  text = text.replace(\" he's \",\" he is \")\n","  text = text.replace(\" u \",\" you \")\n","  text = text.replace(\" ur \",\" your \")\n","  text = text.replace(\" b4 \",\" before \")\n","  text = text.replace(\" wasn't \",\" was not \")\n","  text = text.replace(\" can't \",\" can not \")\n","  text = text.replace(\" couldn't \",\" could not \")\n","  text = text.replace(\" wouldn't \",\" would not \")\n","  text = text.replace(\" don't \",\" do not \")\n","  text = text.replace(\" didn't \",\" did not \")\n","  text = text.replace(\" let's \",\" let us \")\n","  text = text.replace(\" luv \",\" love \")\n","  text = text.replace(\" true \",\" truth \")\n","  text = text.replace(\" ppl \",\" people \")\n","  text = text.replace(\" fb \",\" facebook \")\n","  text = text.replace(\" b day \",\" birthday \")\n","  text = text.replace(\" bday \",\" birthday \")\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeHashtags(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='#', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeMentions(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='@', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n","\n","def removeHttpWeb(text):\n","  words = text.split()\n","  words = filter(lambda x:x[0]!='&', words)\n","  words = filter(lambda x:x[0:4]!='http', words)\n","  text = \" \".join(words)\n","  if (len(text.strip())  == 0):\n","      text = ' ' #replace None with a single space\n","  return(text)\n"],"metadata":{"id":"40ElLojg4bl0","executionInfo":{"status":"ok","timestamp":1684057893040,"user_tz":-120,"elapsed":9,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# CLEANUP FACTORY\n","def cleanup(text):\n","  #Scenario1: \n","  text = removeSpecialChar(text)\n","  text = remove1stMent(text)\n","  text = removeHttpWeb(text)\n","  text = cleanColloquials(text)\n","\n","  #Scenario2: remove1stMent, removeHttpWeb, removeSpecialChar, cleanColloquials\n","  #Scenario3: remove1stMent, removeHttpWeb, removeHashtags, removeSpecialChar, cleanColloquials\n","  return(text)"],"metadata":{"id":"JVpi97-E2Y5F","executionInfo":{"status":"ok","timestamp":1684057894411,"user_tz":-120,"elapsed":354,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#df['CleanTweet'] = df['OrigTweet'].apply(remove1stMentNoSpecChar)\n","#remove1stMentNoSpecChar('@MarkSZaidEsq @tko From the evidence and more to co')\n","df['CleanTweet'] = df['OrigTweet'].apply(cleanup)"],"metadata":{"id":"or4-FaPT2c2l","executionInfo":{"status":"ok","timestamp":1684057900187,"user_tz":-120,"elapsed":5245,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["print(f\"The dataset contains { df.Target.nunique() } unique categories\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-9ROhaMftWNn","executionInfo":{"status":"ok","timestamp":1684057902020,"user_tz":-120,"elapsed":293,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"f861256c-0cd4-4ddd-9b3b-7d4e3ef906b1"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["The dataset contains 5 unique categories\n"]}]},{"cell_type":"code","source":["# convert the tweets into lower case if uncased model.\n","#df['CleanTweet'] = df['CleanTweet'].apply(lambda x: str(x).lower())\n","# trim to 280 characters max\n","df['CleanTweet'] = df['CleanTweet'].str.slice(0,279)\n","# calculating the length of tweet\n","df['CleanTweet_len'] = df['CleanTweet'].apply(lambda x: len(str(x).split()))\n","# Remove tweets with less than 10 words\n","df = df.query('CleanTweet_len > 9')\n","len(df)"],"metadata":{"id":"1CMjgw3Htctu","executionInfo":{"status":"ok","timestamp":1684057903758,"user_tz":-120,"elapsed":445,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"13646db4-44ba-47d2-b4fd-de61e8f1d518"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["101245"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["df['Label'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z5voRycn6oCp","executionInfo":{"status":"ok","timestamp":1684057905694,"user_tz":-120,"elapsed":233,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"88bab506-3335-42ab-cfa0-f403f7d3e04e"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Politics', 'Entertainment', 'Business', 'Sports', 'Technology'],\n","      dtype=object)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["df['Target'].unique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSJaAglDFSHB","executionInfo":{"status":"ok","timestamp":1684057907017,"user_tz":-120,"elapsed":5,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"d98eda24-86c0-41b8-a64c-a9d9a7a19ebf"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([10,  6,  3, 11, 12])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["#For the initial Ground Truth:\n","df.loc[(df.Target == 10), 'Target'] = 0\n","df.loc[(df.Target == 6), 'Target'] = 1\n","df.loc[(df.Target == 3), 'Target'] = 2\n","df.loc[(df.Target == 11), 'Target'] = 3\n","df.loc[(df.Target == 12), 'Target'] = 4\n"],"metadata":{"id":"RK3Z7_9LKarP","executionInfo":{"status":"ok","timestamp":1684057913050,"user_tz":-120,"elapsed":441,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# set index to TID (used later in the Training/Test Series)\n","df.index = df['TID']\n","df.index.rename('gt_idx', inplace=True)"],"metadata":{"id":"OYthw-qqtN5r","executionInfo":{"status":"ok","timestamp":1684057918240,"user_tz":-120,"elapsed":234,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":385},"id":"T1pFK_qBtMSV","executionInfo":{"status":"ok","timestamp":1684057919828,"user_tz":-120,"elapsed":234,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"bc9bd671-e6a5-4688-d5a7-45ecf8da7e27"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                     TID  \\\n","gt_idx                                     \n","826262311560216578    826262311560216578   \n","1193437298303438858  1193437298303438858   \n","1194280882540036098  1194280882540036098   \n","1194635634960478208  1194635634960478208   \n","1194636052096413696  1194636052096413696   \n","\n","                                                             OrigTweet  \\\n","gt_idx                                                                   \n","826262311560216578   #coup has started. First of many steps. #rebel...   \n","1193437298303438858  @MarkSZaidEsq @jody_prichard Funny you want to...   \n","1194280882540036098  @MarkSZaidEsq at THAT time, the only \"stepping...   \n","1194635634960478208  @MarkSZaidEsq It's not a coup.  It's a Constit...   \n","1194636052096413696  @MarkSZaidEsq BTW, I've read your client HOSTE...   \n","\n","                              InReplyTo  Target     Label  \\\n","gt_idx                                                      \n","826262311560216578                  NaN       0  Politics   \n","1193437298303438858  826262311560216578       0  Politics   \n","1194280882540036098  826262311560216578       0  Politics   \n","1194635634960478208  826262311560216578       0  Politics   \n","1194636052096413696  826262311560216578       0  Politics   \n","\n","                                                            CleanTweet  \\\n","gt_idx                                                                   \n","826262311560216578   #coup has started. First of many steps. #rebel...   \n","1193437298303438858  @jody_prichard Funny you want to discriminate ...   \n","1194280882540036098  at THAT time, the only \"stepping over the line...   \n","1194635634960478208  It's not a coup. It's a Constitutional procedu...   \n","1194636052096413696  BTW, I've read your client HOSTED (and was in)...   \n","\n","                     CleanTweet_len  \n","gt_idx                               \n","826262311560216578               13  \n","1193437298303438858              47  \n","1194280882540036098              54  \n","1194635634960478208              47  \n","1194636052096413696              45  "],"text/html":["\n","  <div id=\"df-81bca8ea-e77d-4257-8ed6-989b092a6963\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TID</th>\n","      <th>OrigTweet</th>\n","      <th>InReplyTo</th>\n","      <th>Target</th>\n","      <th>Label</th>\n","      <th>CleanTweet</th>\n","      <th>CleanTweet_len</th>\n","    </tr>\n","    <tr>\n","      <th>gt_idx</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>826262311560216578</th>\n","      <td>826262311560216578</td>\n","      <td>#coup has started. First of many steps. #rebel...</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>Politics</td>\n","      <td>#coup has started. First of many steps. #rebel...</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>1193437298303438858</th>\n","      <td>1193437298303438858</td>\n","      <td>@MarkSZaidEsq @jody_prichard Funny you want to...</td>\n","      <td>826262311560216578</td>\n","      <td>0</td>\n","      <td>Politics</td>\n","      <td>@jody_prichard Funny you want to discriminate ...</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>1194280882540036098</th>\n","      <td>1194280882540036098</td>\n","      <td>@MarkSZaidEsq at THAT time, the only \"stepping...</td>\n","      <td>826262311560216578</td>\n","      <td>0</td>\n","      <td>Politics</td>\n","      <td>at THAT time, the only \"stepping over the line...</td>\n","      <td>54</td>\n","    </tr>\n","    <tr>\n","      <th>1194635634960478208</th>\n","      <td>1194635634960478208</td>\n","      <td>@MarkSZaidEsq It's not a coup.  It's a Constit...</td>\n","      <td>826262311560216578</td>\n","      <td>0</td>\n","      <td>Politics</td>\n","      <td>It's not a coup. It's a Constitutional procedu...</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>1194636052096413696</th>\n","      <td>1194636052096413696</td>\n","      <td>@MarkSZaidEsq BTW, I've read your client HOSTE...</td>\n","      <td>826262311560216578</td>\n","      <td>0</td>\n","      <td>Politics</td>\n","      <td>BTW, I've read your client HOSTED (and was in)...</td>\n","      <td>45</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81bca8ea-e77d-4257-8ed6-989b092a6963')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-81bca8ea-e77d-4257-8ed6-989b092a6963 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-81bca8ea-e77d-4257-8ed6-989b092a6963');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# BUILD THE MODEL\n","no_of_classes = 5\n","# seed for environmental stability \n","# tf.random.set_seed(0) "],"metadata":{"id":"0leihuY3u0WB","executionInfo":{"status":"ok","timestamp":1684057924625,"user_tz":-120,"elapsed":227,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#LSTM tokenizer setup\n","emb_dim = 128\n","n_most_common_words = 80000\n","max_len = 99\n","tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n","tokenizer.fit_on_texts(df['CleanTweet'].values)\n","sequences = tokenizer.texts_to_sequences(df['CleanTweet'].values)\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))\n","\n","X = pad_sequences(sequences, maxlen=max_len)"],"metadata":{"id":"xonhSJMzn4Cq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684057935001,"user_tz":-120,"elapsed":7209,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"93f7ec28-68fa-4413-be40-6bc59653fb35"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 74960 unique tokens.\n"]}]},{"cell_type":"code","source":["#build the model on tpu\n","with strategy.scope():\n","  model = Sequential()\n","  model.add(Embedding(n_most_common_words, emb_dim, input_length=99))\n","  model.add(SpatialDropout1D(0.3))\n","  #model.add(Bidirectional(LSTM(64, dropout=0.3, recurrent_dropout=0.3))) # for BiDirectional LSTM\n","  model.add(Bidirectional(LSTM(64, dropout=0.3, recurrent_dropout=0.3, return_sequences=True))) # for BiDirectional LSTM\n","  model.add(SeqWeightedAttention()) # add attention layer\n","  model.add(Dense(no_of_classes, activation='softmax'))\n","  model.compile(optimizer=tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n","print(model.summary())\n","# Save the initial Neural Net weights (to use for resetting the model in between cross validation runs)\n","init_weights = model.get_weights()"],"metadata":{"id":"ZzmqJPxLu41m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684057946780,"user_tz":-120,"elapsed":3720,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"6631dd62-1f11-41c7-875c-ea41662c43eb"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 99, 128)           10240000  \n","                                                                 \n"," spatial_dropout1d (SpatialD  (None, 99, 128)          0         \n"," ropout1D)                                                       \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 99, 128)          98816     \n"," l)                                                              \n","                                                                 \n"," seq_weighted_attention (Seq  (None, 128)              129       \n"," WeightedAttention)                                              \n","                                                                 \n"," dense (Dense)               (None, 5)                 645       \n","                                                                 \n","=================================================================\n","Total params: 10,339,590\n","Trainable params: 10,339,590\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"code","source":["#X_train,X_test ,y_train,y_test = train_test_split(df['CleanTweet'], df['Target'], random_state = 1, stratify=df['Target'], test_size = 0.2)\n","# X_train = df['CleanTweet']\n","y = df['Target']"],"metadata":{"id":"YEA9NRY-3gXz","executionInfo":{"status":"ok","timestamp":1684057970054,"user_tz":-120,"elapsed":244,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["runTweak = \"Mini cleanup, remove 1st mention, finetune LSTM\""],"metadata":{"id":"r6Cinfd23oeU","executionInfo":{"status":"ok","timestamp":1684057971929,"user_tz":-120,"elapsed":214,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# TRAIN THE MODEL"],"metadata":{"id":"7o0jz-ngz977","executionInfo":{"status":"ok","timestamp":1684057973811,"user_tz":-120,"elapsed":220,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# run_functions_eagerly command executed to prevent\"ValueError: Creating variables on a non-first call to a function decorated with tf.function\" error\n","# Resolution from: https://stackoverflow.com/questions/58352326/running-the-tensorflow-2-0-code-gives-valueerror-tf-function-decorated-functio\n","# tf.config.run_functions_eagerly(True)"],"metadata":{"id":"I8-8_xZn4BPx","executionInfo":{"status":"ok","timestamp":1684057979391,"user_tz":-120,"elapsed":219,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["runID = dt.today().strftime('%Y%m%d%H%M')\n","# 5-Fold Cross Validation\n","kf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n","# kf = StratifiedKFold(n_splits=2, random_state=0, shuffle=True)\n","# kf = StratifiedKFold(n_splits=2)\n","k=1\n","df_tr_hist = pd.DataFrame(columns=['RunID','RunTweak','Model','Loss','Accuracy'])\n","df_val_result = pd.DataFrame(columns=['ValID','ValType','Model','Accuracy','Precision','Recall','F1'])\n","for tr_idx, val_idx in kf.split(X, y):\n","  print(f\"\\nTraining for Cross Val: {k} \")\n","  print(f\"Indexes for tr {tr_idx} and val {val_idx}\")\n","\n","  # create training and validation datasets\n","  X_tr, X_val = X[tr_idx], X[val_idx]\n","  y_tr, y_val = y[tr_idx], y[val_idx]\n","  \n","  # Encode y_tr and y_val\n","  ytr_encoded = tf.keras.utils.to_categorical(y_tr, num_classes=no_of_classes,dtype = 'int32')\n","  yval_encoded = tf.keras.utils.to_categorical(y_val, num_classes=no_of_classes,dtype = 'int32')\n","\n","  # Encode X_tr and X_val -- ALREADY ENCODED IN X\n","\n","  #training for the epochs\n","  train_history = model.fit(\n","      x=X_tr, y=ytr_encoded,\n","      # steps_per_epoch = n_steps,\n","      batch_size=128,\n","      epochs=10,\n","      # validation_split=0.2,\n","      callbacks=[EarlyStopping(monitor='loss',patience=7, min_delta=0.0001)]\n","      )\n","\n","  #store the training history log\n","  df_tr_hist.loc[len(df_tr_hist)] = [runID, runTweak, 'LSTM', train_history.history['loss'], train_history.history['accuracy']]\n","\n","  #Making predictions for val\n","  preds = model.predict(X_val,verbose = 1)\n","  pred_classes = np.argmax(preds, axis = 1)\n","  \n","  #Mapping the encoded output to actual categories...\n","  # write result for decomposed SMR\n","  actual_category = np.argmax(yval_encoded, axis = 1) \n","  acc = sklearn.metrics.accuracy_score(actual_category,pred_classes)\n","  print(\"Generating decomposed SMR performance metrics ...\" )\n","  de_prec = precision_score(actual_category,pred_classes, average = 'weighted')\n","  de_recall = recall_score(actual_category,pred_classes, average = 'weighted')\n","  de_f1 = f1_score(actual_category,pred_classes, average = 'weighted')\n","  print(f\"Decomposed SMR Acc: {acc*100}, Prec: {de_prec*100}, Recall: {de_recall*100}, F1 {de_f1*100}\")\n","  df_val_result.loc[len(df_val_result)] = [k, 'Decomposed', 'LSTM', acc*100, de_prec*100, de_recall*100, de_f1*100]\n","\n","  # p_r_f1 = precision_recall_fscore_support(actual_category, pred_classes, average = 'weighted')\n","  # print(f\"Decomposed SMR Acc: {acc*100}, Prec: {p_r_f1[0]*100}, Recall: {p_r_f1[1]*100}, F1 {p_r_f1[2]*100}\")\n","  # df_val_result.loc[len(df_val_result)] = [k, 'Decomposed', 'LSTM', acc*100, p_r_f1[0]*100, p_r_f1[1]*100, p_r_f1[2]*100]\n","\n","  print(\"Generating recomposed SMR accuracy...\")\n","  list_y_val_idx = y_val.index.tolist()\n","  result_df = pd.DataFrame({'idx':list_y_val_idx, 'actual_category':actual_category, 'predicted_category':pred_classes})\n","  df_sup_result = result_df.merge(df, left_on='idx', right_on='TID')\n","  df_sup_agg_result = df_sup_result.groupby(['InReplyTo','predicted_category']).size().reset_index(name='counts').sort_values(['InReplyTo','counts'], ascending=[True,False])\n","  df_rec = df[df.InReplyTo.isna()]\n","\n","  # Recompose the SMR based on the count of aggregated supporting tweet predictions\n","  df_rec_result = pd.DataFrame(columns=['TID','Actual','Predicted'])\n","  for i in range(0,len(df_rec)):\n","    rec_TID = df_rec.iloc[i]['TID']\n","    rec_cat = int(df_rec.iloc[i]['Target'])\n","    df_temp = df_sup_agg_result[df_sup_agg_result.InReplyTo == rec_TID].sort_values('counts',ascending=False)\n","    if len(df_temp) > 0:\n","      rec_pred = int(df_temp[:1]['predicted_category'].values)\n","      df_rec_result.loc[len(df_rec_result)] = [rec_TID,rec_cat,rec_pred]\n","\n","  # write result for recomposed SMR\n","  rec_actual = df_rec_result['Actual'].to_numpy().astype(int)\n","  rec_pred = df_rec_result['Predicted'].to_numpy().astype(int)\n","  rec_acc = sklearn.metrics.accuracy_score(rec_actual, rec_pred)\n","  rec_prec = precision_score(rec_actual, rec_pred, average = 'weighted')\n","  rec_recall = recall_score(rec_actual, rec_pred, average = 'weighted')\n","  rec_f1 = f1_score(rec_actual, rec_pred, average = 'weighted')\n","  print(f\"Recomposed SMR Acc: {rec_acc*100}, Prec: {rec_prec*100}, Recall: {rec_recall*100}, F1 {rec_f1*100}\")\n","  df_val_result.loc[len(df_val_result)] = [k, 'Recomposed', 'LSTM', rec_acc*100, rec_prec*100, rec_recall*100, rec_f1*100]\n","\n","  # rec_p_r_f1 = precision_recall_fscore_support(rec_actual, rec_pred, average = 'weighted')\n","  # print(f\"Recomposed SMR Acc: {rec_acc*100}, Prec: {rec_p_r_f1[0]*100}, Recall: {rec_p_r_f1[1]*100}, F1 {rec_p_r_f1[2]*100}\")\n","  # df_val_result.loc[len(df_val_result)] = [k, 'Recomposed', 'LSTM', rec_acc*100, rec_p_r_f1[0]*100, rec_p_r_f1[1]*100, rec_p_r_f1[2]*100]\n","\n","  # Generate confusion matrix\n","  rec_cm = confusion_matrix(rec_actual, rec_pred)\n","  df_rec_cm = pd.DataFrame(rec_cm)\n","  df_rec_cm.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/LSTM_GTr_CM_\" + str(k) + \" \" + runID +\".csv\")\n","\n","  # Reset the model by restoring the initital model weights to prevent overtraining\n","  model.set_weights(init_weights)\n","  k=k+1\n","\n","# Save the training history result\n","df_tr_hist.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/LSTM_GTr_TrainHist_\" + runID +\".csv\")\n","\n","# Save the cross validation result\n","df_val_result = df_val_result.round(decimals=2)\n","df_val_result.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/LSTM_GTr_CV_\" + runID +\".csv\")\n","\n","# Save RunID,Model,Accuracy,Precision,Recall,F1 for the Recomposed SMR\n","df_re_val_result = df_val_result[df_val_result.ValType=='Recomposed']\n","no_of_runs = len(df_re_val_result)\n","df_GTxM_Clf_CV_results = pd.read_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_Clf_CV_results.csv\")\n","avg_Accuracy = np.sum(df_re_val_result['Accuracy']) / no_of_runs\n","avg_Precision = np.sum(df_re_val_result['Precision']) / no_of_runs\n","avg_Recall = np.sum(df_re_val_result['Recall']) / no_of_runs\n","avg_F1 = np.sum(df_re_val_result['F1']) / no_of_runs\n","df_GTxM_Clf_CV_results.loc[len(df_GTxM_Clf_CV_results)] = [runID, 'LSTM', avg_Accuracy, avg_Precision, avg_Recall, avg_F1]\n","df_GTxM_Clf_CV_results.to_csv(\"/content/drive/MyDrive/ColabNotebooks/SMRM/IMPL/results/GTxM_Clf_CV_results.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ywFtGK23xyE","executionInfo":{"status":"ok","timestamp":1684059478628,"user_tz":-120,"elapsed":1496184,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"00462fd9-99f5-461e-aee1-5c6266fdf334"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training for Cross Val: 1 \n","Indexes for tr [     0      1      2 ... 101241 101242 101243] and val [     5      8     16 ... 101218 101220 101244]\n","Epoch 1/10\n","633/633 [==============================] - 53s 57ms/step - loss: 1.4242 - accuracy: 0.4931\n","Epoch 2/10\n","633/633 [==============================] - 29s 46ms/step - loss: 1.3031 - accuracy: 0.4965\n","Epoch 3/10\n","633/633 [==============================] - 29s 45ms/step - loss: 1.2282 - accuracy: 0.5311\n","Epoch 4/10\n","633/633 [==============================] - 27s 43ms/step - loss: 1.0415 - accuracy: 0.6324\n","Epoch 5/10\n","633/633 [==============================] - 27s 43ms/step - loss: 0.9916 - accuracy: 0.6525\n","Epoch 6/10\n","633/633 [==============================] - 28s 44ms/step - loss: 0.9617 - accuracy: 0.6641\n","Epoch 7/10\n","633/633 [==============================] - 27s 43ms/step - loss: 0.9377 - accuracy: 0.6728\n","Epoch 8/10\n","633/633 [==============================] - 27s 43ms/step - loss: 0.9177 - accuracy: 0.6789\n","Epoch 9/10\n","633/633 [==============================] - 27s 43ms/step - loss: 0.9005 - accuracy: 0.6843\n","Epoch 10/10\n","633/633 [==============================] - 27s 43ms/step - loss: 0.8871 - accuracy: 0.6883\n","633/633 [==============================] - 11s 15ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 69.08489308113981, Prec: 54.236492148747416, Recall: 69.08489308113981, F1 60.396344370432296\n","Generating recomposed SMR accuracy...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Recomposed SMR Acc: 72.86821705426357, Prec: 58.26271455689576, Recall: 72.86821705426357, F1 64.23403916545351\n","\n","Training for Cross Val: 2 \n","Indexes for tr [     0      2      5 ... 101242 101243 101244] and val [     1      3      4 ... 101230 101233 101234]\n","Epoch 1/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.4635 - accuracy: 0.4917\n","Epoch 2/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.3076 - accuracy: 0.4965\n","Epoch 3/10\n","633/633 [==============================] - 28s 43ms/step - loss: 1.3023 - accuracy: 0.4965\n","Epoch 4/10\n","633/633 [==============================] - 28s 45ms/step - loss: 1.2997 - accuracy: 0.4965\n","Epoch 5/10\n","633/633 [==============================] - 28s 43ms/step - loss: 1.2963 - accuracy: 0.4965\n","Epoch 6/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.2899 - accuracy: 0.4965\n","Epoch 7/10\n","633/633 [==============================] - 27s 43ms/step - loss: 1.2806 - accuracy: 0.4976\n","Epoch 8/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.2665 - accuracy: 0.5015\n","Epoch 9/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.2195 - accuracy: 0.5197\n","Epoch 10/10\n","633/633 [==============================] - 28s 43ms/step - loss: 1.1434 - accuracy: 0.5693\n","633/633 [==============================] - 9s 13ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 61.064743937972246, Prec: 50.45125590081889, Recall: 61.064743937972246, F1 54.01782583164656\n","Generating recomposed SMR accuracy...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Recomposed SMR Acc: 61.65605095541401, Prec: 54.71452742369277, Recall: 61.65605095541401, F1 55.13832027844767\n","\n","Training for Cross Val: 3 \n","Indexes for tr [     0      1      3 ... 101242 101243 101244] and val [     2      7     22 ... 101225 101236 101240]\n","Epoch 1/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.3943 - accuracy: 0.4930\n","Epoch 2/10\n","633/633 [==============================] - 27s 43ms/step - loss: 1.3043 - accuracy: 0.4965\n","Epoch 3/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.2993 - accuracy: 0.4965\n","Epoch 4/10\n","633/633 [==============================] - 28s 43ms/step - loss: 1.2829 - accuracy: 0.4969\n","Epoch 5/10\n","633/633 [==============================] - 27s 43ms/step - loss: 1.1909 - accuracy: 0.5368\n","Epoch 6/10\n","633/633 [==============================] - 27s 43ms/step - loss: 1.1298 - accuracy: 0.5736\n","Epoch 7/10\n","633/633 [==============================] - 27s 43ms/step - loss: 1.0939 - accuracy: 0.5976\n","Epoch 8/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.0621 - accuracy: 0.6159\n","Epoch 9/10\n","633/633 [==============================] - 28s 43ms/step - loss: 1.0303 - accuracy: 0.6319\n","Epoch 10/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.0020 - accuracy: 0.6411\n","633/633 [==============================] - 9s 13ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 66.2946318336708, Prec: 55.062917910913235, Recall: 66.2946318336708, F1 58.88744201347503\n","Generating recomposed SMR accuracy...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Recomposed SMR Acc: 70.03891050583657, Prec: 58.23284071339009, Recall: 70.03891050583657, F1 62.27118167537391\n","\n","Training for Cross Val: 4 \n","Indexes for tr [     0      1      2 ... 101242 101243 101244] and val [    14     15     19 ... 101231 101238 101239]\n","Epoch 1/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.4004 - accuracy: 0.4906\n","Epoch 2/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.3026 - accuracy: 0.4965\n","Epoch 3/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.2984 - accuracy: 0.4965\n","Epoch 4/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.2915 - accuracy: 0.4965\n","Epoch 5/10\n","633/633 [==============================] - 28s 45ms/step - loss: 1.2846 - accuracy: 0.4965\n","Epoch 6/10\n","633/633 [==============================] - 27s 43ms/step - loss: 1.2795 - accuracy: 0.4979\n","Epoch 7/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.2738 - accuracy: 0.5003\n","Epoch 8/10\n","633/633 [==============================] - 27s 43ms/step - loss: 1.2578 - accuracy: 0.5048\n","Epoch 9/10\n","633/633 [==============================] - 28s 43ms/step - loss: 1.2105 - accuracy: 0.5239\n","Epoch 10/10\n","633/633 [==============================] - 28s 43ms/step - loss: 1.1447 - accuracy: 0.5744\n","633/633 [==============================] - 9s 13ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 60.511630203960685, Prec: 50.91785375621456, Recall: 60.511630203960685, F1 53.72457391479607\n","Generating recomposed SMR accuracy...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Recomposed SMR Acc: 63.0012936610608, Prec: 54.982376259439405, Recall: 63.0012936610608, F1 56.11726853633648\n","\n","Training for Cross Val: 5 \n","Indexes for tr [     1      2      3 ... 101239 101240 101244] and val [     0      6      9 ... 101241 101242 101243]\n","Epoch 1/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.4002 - accuracy: 0.4931\n","Epoch 2/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.3050 - accuracy: 0.4965\n","Epoch 3/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.3002 - accuracy: 0.4965\n","Epoch 4/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.2941 - accuracy: 0.4965\n","Epoch 5/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.2400 - accuracy: 0.5097\n","Epoch 6/10\n","633/633 [==============================] - 28s 43ms/step - loss: 1.1446 - accuracy: 0.5682\n","Epoch 7/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.1037 - accuracy: 0.5881\n","Epoch 8/10\n","633/633 [==============================] - 28s 44ms/step - loss: 1.0837 - accuracy: 0.5914\n","Epoch 9/10\n","633/633 [==============================] - 28s 43ms/step - loss: 1.0596 - accuracy: 0.6172\n","Epoch 10/10\n","633/633 [==============================] - 28s 43ms/step - loss: 1.0429 - accuracy: 0.6203\n","633/633 [==============================] - 9s 13ms/step\n","Generating decomposed SMR performance metrics ...\n","Decomposed SMR Acc: 62.94631833670798, Prec: 54.46608743685476, Recall: 62.94631833670798, F1 56.43899838631504\n","Generating recomposed SMR accuracy...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Recomposed SMR Acc: 67.31770833333334, Prec: 58.45250808001398, Recall: 67.31770833333334, F1 60.37741047282087\n"]}]},{"cell_type":"code","source":["len(df_rec)"],"metadata":{"id":"hDL8x7BH3xny","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684059487163,"user_tz":-120,"elapsed":216,"user":{"displayName":"Kaz Olad","userId":"18132397273387958983"}},"outputId":"9b70ffac-de44-4b17-9d15-b11006468fb0"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["806"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":[],"metadata":{"id":"xWEI1fo6tUFz"},"execution_count":null,"outputs":[]}]}